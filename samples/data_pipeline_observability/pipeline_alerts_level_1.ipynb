{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "name": "TITLE",
    "collapsed": false,
    "resultHeight": 218
   },
   "source": "## Setting up Pipeline Alerts\n\n# Level 1 (Beginner)\n\nTo start with we will explore different option to monitor the **health** of **Tasks, Pipes and Dynamic Tables**. \n\nWe can apply checks to either individiual objects or all objects within a Schema or Database. The latter is recommended as it automatically includes any future objects."
  },
  {
   "cell_type": "markdown",
   "id": "8408e6d7-aed6-4f50-a18c-e4e284b338ac",
   "metadata": {
    "name": "PART_1_Setup",
    "collapsed": false,
    "resultHeight": 169
   },
   "source": "## 1. Setting up message destinations\n\nTo send out notifications from Snowflake we first need a **Notification Integration** for each destination.\n\nFor this demo we will use **email** (only works for verified user emails!) and a **Slack webhook** (https://api.slack.com/messaging/webhooks) (you can also use MS Teams or PagerDuty):"
  },
  {
   "cell_type": "code",
   "id": "8c8a2602-320b-4e6e-b329-321422fc9f38",
   "metadata": {
    "language": "python",
    "name": "parameter_input",
    "collapsed": false,
    "resultHeight": 457
   },
   "outputs": [],
   "source": "#this cell is not needed to run the demo. it is just convenient as a UI for your credentials\n\nimport streamlit as st\nfrom snowflake.snowpark.context import get_active_session\nsession = get_active_session()\n\nst.divider()\ncol1, col2 = st.columns([1,1])\nMY_DEMO_SLACK_SECRET = col1.text_input(\"Enter your slack webhook secret\")\nMY_DEMO_EMAIL = col1.text_input(\"Enter your verified user email\")\nif MY_DEMO_SLACK_SECRET == \"\" or MY_DEMO_EMAIL == \"\":\n    raise Exception(\"Webhook string and Email needed to configure notifications below\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b561cd1c-ba63-43db-8cc4-b679ea81ddde",
   "metadata": {
    "language": "sql",
    "name": "create_email_integration",
    "collapsed": false,
    "codeCollapsed": false,
    "resultHeight": 112
   },
   "outputs": [],
   "source": "--- setting email notification integration as destination for our Alert messages\n\ncreate or replace notification integration DEMO_EMAIL_NOTIFICATIONS\n  type = email\n  enabled = true\n;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6203b0bc-94e7-4d41-b327-c22224b5a3d4",
   "metadata": {
    "language": "sql",
    "name": "test_email_notification",
    "collapsed": false,
    "resultHeight": 112
   },
   "outputs": [],
   "source": "call SYSTEM$SEND_SNOWFLAKE_NOTIFICATION(\n    SNOWFLAKE.NOTIFICATION.TEXT_PLAIN(\n        'Hello from Snowflake'                          -- my message\n        ),\n    SNOWFLAKE.NOTIFICATION.EMAIL_INTEGRATION_CONFIG(\n        'DEMO_EMAIL_NOTIFICATIONS',                     -- notification integration\n        'Snowflake DEMO Pipeline Alert',                -- email header\n        ARRAY_CONSTRUCT('{{MY_DEMO_EMAIL}}'),           -- emails\n        NULL,                                           -- no CC emails\n        NULL                                            -- no BCC emails\n        )\n    )\n;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "228aa24d-edae-4fa0-afcc-91c1f76182f2",
   "metadata": {
    "language": "sql",
    "name": "create_slack_secret",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "--- getting secret from your Slack channel\n--- see Slack documentation for details\n\ncreate or replace secret DEMO_SLACK_WEBHOOK\n    type = GENERIC_STRING\n    secret_string = '{{MY_DEMO_SLACK_SECRET}}'\n;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "01dfdf99-a305-4eaf-99ed-912ac4deed8d",
   "metadata": {
    "language": "sql",
    "name": "create_slack_integration",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "--- setting Slack notificaiton integration as destination for our Alert messages\n--- https://docs.snowflake.com/sql-reference/sql/create-notification-integration-webhooks\n\ncreate or replace notification integration SLACK_CHANNEL_PIPELINE_ALERTS\n    type = WEBHOOK\n    enabled = TRUE\n    webhook_url = 'https://hooks.slack.com/services/SNOWFLAKE_WEBHOOK_SECRET'\n    webhook_secret = DEX_DB.DEMO.DEMO_SLACK_WEBHOOK\n    webhook_body_template = '{\"text\": \"SNOWFLAKE_WEBHOOK_MESSAGE\"}'\n    webhook_headers = ('Content-Type'='text/json')\n    comment = 'posting to Demo Slack workspace in channel PIPELINE_ALERTS'\n;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8e782f20-cbe4-4483-a1ed-0453fdaf1ed4",
   "metadata": {
    "language": "sql",
    "name": "slack_test",
    "collapsed": false,
    "codeCollapsed": false,
    "resultHeight": 112
   },
   "outputs": [],
   "source": "call SYSTEM$SEND_SNOWFLAKE_NOTIFICATION(\n  SNOWFLAKE.NOTIFICATION.APPLICATION_JSON('Hello from Snowflake'),\n  SNOWFLAKE.NOTIFICATION.INTEGRATION('SLACK_CHANNEL_PIPELINE_ALERTS')\n);",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "283c5292-8bec-4f42-9965-659cdc9a29aa",
   "metadata": {
    "language": "sql",
    "name": "multiple_message_destinations",
    "collapsed": false
   },
   "outputs": [],
   "source": "-- testing multiple destinations with a sample message\n\ncall SYSTEM$SEND_SNOWFLAKE_NOTIFICATION(\n    array_construct(                                              -- providing multiple message formats\n            SNOWFLAKE.NOTIFICATION.APPLICATION_JSON(\n                'Hello from Snowflake'                            -- my json message for slack\n                ),\n            SNOWFLAKE.NOTIFICATION.TEXT_HTML(\n                '<b>Hello from Snowflake!</b>'                    -- my html message for emails\n                )\n    ),\n    array_construct(                                              -- multiple destinations\n            SNOWFLAKE.NOTIFICATION.INTEGRATION(\n                'SLACK_CHANNEL_PIPELINE_ALERTS'                   -- slack integration\n                ),\n            SNOWFLAKE.NOTIFICATION.EMAIL_INTEGRATION_CONFIG(\n                'DEMO_EMAIL_NOTIFICATIONS',                       -- email integration\n                'Snowflake DEMO Pipeline Alert',                  -- email header\n                ARRAY_CONSTRUCT('{{MY_DEMO_EMAIL}}')              -- validated user email addresses\n            )\n    )\n);",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b93de1e4-4087-4f68-8769-410096d21a46",
   "metadata": {
    "name": "PART_2_Task_alert",
    "collapsed": false,
    "resultHeight": 143
   },
   "source": "## 2. Failed Task Run alert\n\nKeep in mind that all following Alert objects will be created in the Schema of this notebook.\n\n(you can also just add your database or schema to the object names below)"
  },
  {
   "cell_type": "code",
   "id": "5aab3ba3-656c-4910-b0fc-e536e084d723",
   "metadata": {
    "language": "sql",
    "name": "show_current_schema",
    "collapsed": false,
    "resultHeight": 112
   },
   "outputs": [],
   "source": "-- schema context for creating Alert objects\n\nselect \n    current_database(), \n    current_schema();",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2316f4d2-74ca-4e94-b0e1-7d641d6b6b37",
   "metadata": {
    "name": "descripton_1",
    "collapsed": false,
    "resultHeight": 108
   },
   "source": "We start by setting up an alert for any failed Task run within out Database by checking INFORMATION_SCHEMA.TASK_HISTORY for any entries with \"FAILED\" or \"FAILED_AND_AUTO_SUSPENDED\" state.\n\nLet's first test run our condition:"
  },
  {
   "cell_type": "code",
   "id": "32e9aba3-853f-48fa-8ebd-21d82692426e",
   "metadata": {
    "language": "sql",
    "name": "testing_task_history",
    "collapsed": false,
    "resultHeight": 112
   },
   "outputs": [],
   "source": "select \n    distinct SCHEMA_NAME||'.'||NAME as TASK\nfrom \n    table(INFORMATION_SCHEMA.TASK_HISTORY(\n        SCHEDULED_TIME_RANGE_START => timeadd('DAY', -1, current_timestamp),\n        SCHEDULED_TIME_RANGE_END => current_timestamp,\n        ERROR_ONLY => True\n    )) \n;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c2e58d29-bdce-4c1f-bcd2-f08d6386eeb8",
   "metadata": {
    "name": "description",
    "collapsed": false,
    "resultHeight": 41
   },
   "source": "now we can create an alert that lists all the names of Tasks that had at least one failed run since the last check and send this as a message to our Slack channel."
  },
  {
   "cell_type": "code",
   "id": "8614809c-1c5a-4abb-becb-4fdeb8bb7367",
   "metadata": {
    "language": "sql",
    "name": "create_Task_Failure_Alert",
    "collapsed": false,
    "resultHeight": 112
   },
   "outputs": [],
   "source": "create or replace alert FAILED_TASK_ALERT\n--- no warehouse selected to run serverless\nschedule='using CRON 0 8 08 * MON-FRI UTC'          -- adjust to your timezone or preferred frequency\nif (exists (\n    select \n        NAME\n    from \n        table(INFORMATION_SCHEMA.TASK_HISTORY(\n            SCHEDULED_TIME_RANGE_START => (greatest(timeadd('DAY', -7, current_timestamp),  SNOWFLAKE.ALERT.LAST_SUCCESSFUL_SCHEDULED_TIME())),     -- if last check is beyond history retention period then use last week instead\n            SCHEDULED_TIME_RANGE_END => SNOWFLAKE.ALERT.SCHEDULED_TIME(),\n            ERROR_ONLY => True)) \n        )\n    ) \nthen          \n    declare\n        TASK_NAMES string;\n    begin\n        TASK_NAMES := (\n            select\n                listagg(distinct(SCHEMA_NAME||'.'||NAME),', ') as FAILED_TASKS\n            from \n                table(INFORMATION_SCHEMA.TASK_HISTORY(\n                    SCHEDULED_TIME_RANGE_START => (greatest(timeadd('DAY', -7, current_timestamp),  SNOWFLAKE.ALERT.LAST_SUCCESSFUL_SCHEDULED_TIME())),     -- if last check is beyond history retention period then use last week instead\n                    SCHEDULED_TIME_RANGE_END => SNOWFLAKE.ALERT.SCHEDULED_TIME(),\n                    ERROR_ONLY => True))\n        );\n          \n        call SYSTEM$SEND_SNOWFLAKE_NOTIFICATION(\n                    SNOWFLAKE.NOTIFICATION.APPLICATION_JSON(\n                        'Tasks '||:TASK_NAMES ||' failed since '||(greatest(timeadd('DAY', -7, current_timestamp), SNOWFLAKE.ALERT.LAST_SUCCESSFUL_SCHEDULED_TIME()))        -- my json message for slack\n                        ),                                               \n                    SNOWFLAKE.NOTIFICATION.INTEGRATION(\n                        'SLACK_CHANNEL_PIPELINE_ALERTS'                                -- slack integration\n                        )           \n        );\n     end;\n;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "46fd2c71-65d1-45f0-9834-8d82371cb8e4",
   "metadata": {
    "language": "sql",
    "name": "activate_Task_Alert",
    "collapsed": false,
    "resultHeight": 112
   },
   "outputs": [],
   "source": "alter alert FAILED_TASK_ALERT resume;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "dada199d-e642-4ed0-9524-01e512a77acf",
   "metadata": {
    "language": "sql",
    "name": "test_run_alert",
    "collapsed": false,
    "resultHeight": 112
   },
   "outputs": [],
   "source": "execute alert FAILED_TASK_ALERT;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "853e1404-dbd5-4699-b8e5-b892c370cbad",
   "metadata": {
    "name": "PART_3_Pipe_alert",
    "collapsed": false,
    "resultHeight": 102
   },
   "source": "## 3. Pipe Alert setup\n\nNow we set up a similar alert but for a specific Pipe by checking INFORMATION_SCHEMA.COPY_HISTORY for failed copies:"
  },
  {
   "cell_type": "code",
   "id": "f019f49c-a54f-43b2-9685-56878f0dce18",
   "metadata": {
    "language": "sql",
    "name": "testing_copy_history",
    "collapsed": false,
    "resultHeight": 427
   },
   "outputs": [],
   "source": "select \n    STATUS,\n    to_char(convert_timezone('Europe/Berlin', PIPE_RECEIVED_TIME), 'YYYY-MM-DD at HH:MI:SS') as PIPE_RECEIVED_TIME\nfrom\n    table(INFORMATION_SCHEMA.COPY_HISTORY(\n        TABLE_NAME => 'IMPORTED_WEATHER',\n        START_TIME => timeadd('day', -1, current_timestamp)\n        )\n    )\nwhere\n    PIPE_NAME = 'LOAD_DAILY_WEATHER' and   \n    upper(STATUS) != 'LOADED'\norder by\n    PIPE_RECEIVED_TIME desc\n;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "17a9e1e4-39f1-4f66-8ef0-e17c1fb64013",
   "metadata": {
    "name": "desription_2",
    "collapsed": false,
    "resultHeight": 41
   },
   "source": "this time we send the message to our email address:"
  },
  {
   "cell_type": "code",
   "id": "d70747cc-d722-4c4a-84d1-9f81548313b2",
   "metadata": {
    "language": "sql",
    "name": "create_pipe_alert",
    "collapsed": false,
    "resultHeight": 112
   },
   "outputs": [],
   "source": "create or replace alert DAILY_WEATHER_PIPE_INCIDENT\n--- no warehouse selected to run serverless\nschedule = '60 minutes'\nif (exists(\n    select \n        PIPE_RECEIVED_TIME\n    from\n        table(INFORMATION_SCHEMA.COPY_HISTORY(\n            TABLE_NAME => 'IMPORTED_WEATHER',\n            START_TIME => SNOWFLAKE.ALERT.LAST_SUCCESSFUL_SCHEDULED_TIME(),     -- check since last alert run\n            END_TIME => SNOWFLAKE.ALERT.SCHEDULED_TIME()                        -- avoiding overlap or gaps\n            )\n        )\n    where\n        PIPE_NAME = 'LOAD_DAILY_WEATHER'\n        and upper(STATUS) != 'LOADED'\n    ))\n    \nthen\n    declare\n        COPY_ISSUES string;\n    begin\n        COPY_ISSUES := (\n            select \n                count(PIPE_RECEIVED_TIME)\n            from\n                table(INFORMATION_SCHEMA.COPY_HISTORY(\n                    TABLE_NAME => 'IMPORTED_WEATHER',\n                    START_TIME => SNOWFLAKE.ALERT.LAST_SUCCESSFUL_SCHEDULED_TIME(),\n                    END_TIME => SNOWFLAKE.ALERT.SCHEDULED_TIME()\n                    )\n                )\n            where\n                PIPE_NAME = 'LOAD_DAILY_WEATHER'\n                and upper(STATUS) != 'LOADED'\n             );\n             \n        call SYSTEM$SEND_SNOWFLAKE_NOTIFICATION(\n            SNOWFLAKE.NOTIFICATION.TEXT_HTML(\n                'Pipe LOAD_DAILY_WEATHER had '||:COPY_ISSUES||' failed or partial copies!'        -- my html message for emails\n                ),\n            SNOWFLAKE.NOTIFICATION.EMAIL_INTEGRATION_CONFIG(\n                'DEMO_EMAIL_NOTIFICATIONS',                       -- email integration\n                'Snowflake DEMO Pipeline Alert',                  -- email header\n                array_construct('{{MY_DEMO_EMAIL}}')              -- validated user email addresses\n                )\n        );\n    end;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6b93a46b-4c90-4186-8dff-50a7d861e896",
   "metadata": {
    "language": "sql",
    "name": "activate_Pipe_alert",
    "collapsed": false,
    "codeCollapsed": false,
    "resultHeight": 112
   },
   "outputs": [],
   "source": "alter alert DAILY_WEATHER_PIPE_INCIDENT resume;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b836fb09-4261-4692-82fc-6b10fae2b7c8",
   "metadata": {
    "language": "sql",
    "name": "test_run_Pipe_alert",
    "collapsed": false,
    "codeCollapsed": false,
    "resultHeight": 112
   },
   "outputs": [],
   "source": "execute alert DAILY_WEATHER_PIPE_INCIDENT;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "05ab72e9-024a-4bc6-a443-a0c55905ae64",
   "metadata": {
    "name": "PART_4_DT_alert",
    "collapsed": false,
    "resultHeight": 169
   },
   "source": "## 4. Dynamic Tables Alert setup\n\nFor Dynamic Tables we set up an alert not just for failed refreshes but more generally when the data lag (freshness) of any Dynamic Table in our database is above the target for more than 90% of the last 24 hours.\n\nHere we send notification to both email and Slack channel:"
  },
  {
   "cell_type": "code",
   "id": "15618f40-d3c2-48b2-9ca4-b600480955ac",
   "metadata": {
    "language": "sql",
    "name": "create_DT_Alert",
    "collapsed": false,
    "resultHeight": 112
   },
   "outputs": [],
   "source": "create or replace alert DT_LAGGING\n--- no warehouse selected to run serverless\nschedule='using CRON 0 8 05 * MON-FRI UTC'\nif (exists (\n    select \n        NAME\n    from \n        table(INFORMATION_SCHEMA.DYNAMIC_TABLES(\n                REFRESH_DATA_TIMESTAMP_START => SNOWFLAKE.ALERT.LAST_SUCCESSFUL_SCHEDULED_TIME(),\n                RESULT_LIMIT => 10000\n            )) \n    where \n        TIME_WITHIN_TARGET_LAG_RATIO < 0.9\n      )\n  ) \nthen          \n    declare\n        DT_NAMES string;\n    begin\n        DT_NAMES := (\n            select\n                listagg(distinct(SCHEMA_NAME||'.'||NAME),', ') as LATE_DTS\n            from \n                table(INFORMATION_SCHEMA.DYNAMIC_TABLES(\n                        REFRESH_DATA_TIMESTAMP_START => SNOWFLAKE.ALERT.LAST_SUCCESSFUL_SCHEDULED_TIME(),\n                        RESULT_LIMIT => 10000\n                    ))  \n            where \n                TIME_WITHIN_TARGET_LAG_RATIO < 0.9\n            );\n\n        call SYSTEM$SEND_SNOWFLAKE_NOTIFICATION(\n            array_construct(                                                -- providing multiple message formats\n                    SNOWFLAKE.NOTIFICATION.APPLICATION_JSON(\n                        'Dynamic Tables(s) '||:DT_NAMES ||' less than 90% of the last 24 hours within target lag.'        -- my json message for slack\n                        ),\n                    SNOWFLAKE.NOTIFICATION.TEXT_HTML(\n                        '<b>Dynamic Tables(s) '||:DT_NAMES ||' less than 90% of the last 24 hours within target lag.</b>'        -- my html message for emails\n                        )\n            ),\n            array_construct(                                                -- multiple destinations\n                    SNOWFLAKE.NOTIFICATION.INTEGRATION(\n                        'SLACK_CHANNEL_PIPELINE_ALERTS'                     -- slack integration\n                        ),\n                    SNOWFLAKE.NOTIFICATION.EMAIL_INTEGRATION_CONFIG(\n                        'DEMO_EMAIL_NOTIFICATIONS',                         -- email integration\n                        'Snowflake DEMO Pipeline Alert',                    -- email header\n                        ARRAY_CONSTRUCT('{{MY_DEMO_EMAIL}}')                -- validated user email addresses\n                    )\n            )\n        );\n    end;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cb63d96a-aaf5-47f5-b69c-fb4a28952840",
   "metadata": {
    "language": "sql",
    "name": "activate_DT_alert",
    "collapsed": false,
    "codeCollapsed": false,
    "resultHeight": 112
   },
   "outputs": [],
   "source": "alter alert DT_LAGGING resume;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8c817f4c-5b26-4375-a2ce-631a7568ed9d",
   "metadata": {
    "language": "sql",
    "name": "test_run_DT_alert",
    "collapsed": false,
    "resultHeight": 112
   },
   "outputs": [],
   "source": "execute alert DT_LAGGING;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "04ec97cb-7714-4521-870b-3ff50a8e9e8b",
   "metadata": {
    "name": "PART_5_Check_Alerts",
    "collapsed": false,
    "resultHeight": 102
   },
   "source": "## 5. Check Alerts History and Notification History\n\nNow we can see which Alerts ran and if their condition triggered a notification.\nWe can also see when notifications were sent out."
  },
  {
   "cell_type": "code",
   "id": "9194e25b-67a0-4818-9e7c-5a6c229dd6c9",
   "metadata": {
    "language": "sql",
    "name": "check_alert_history",
    "collapsed": false,
    "resultHeight": 439
   },
   "outputs": [],
   "source": "select\n    to_char(convert_timezone('Europe/Berlin', SCHEDULED_TIME), 'YYYY-MM-DD at HH:MI:SS') as SCHEDULED_TIME,\n    NAME,\n    STATE,\n    SQL_ERROR_MESSAGE,      -- in case an Alert itself failed\n    TIMEDIFF(second, SCHEDULED_TIME, COMPLETED_TIME) as DURATION_IN_S,\n    SCHEMA_NAME\nfrom \n    table (INFORMATION_SCHEMA.ALERT_HISTORY())\nwhere\n    STATE != 'SCHEDULED'\norder by\n    SCHEDULED_TIME desc\nlimit \n    20\n;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6c1a2401-8dcd-43c5-b856-bceb6095e865",
   "metadata": {
    "language": "sql",
    "name": "check_notification_history",
    "collapsed": false,
    "resultHeight": 439
   },
   "outputs": [],
   "source": "--- see when notifications were sent out\n\nselect\n    to_char(convert_timezone('Europe/Berlin', PROCESSED), 'YYYY-MM-DD at HH:MI:SS') as PROCESSED,\n    INTEGRATION_NAME,\n    STATUS,\n    ERROR_MESSAGE\nfrom \n    table(INFORMATION_SCHEMA.NOTIFICATION_HISTORY(\n      START_TIME=>dateadd('hour',-24,current_timestamp()),\n      END_TIME=>current_timestamp()\n      ))\nwhere\n    INTEGRATION_NAME in ('SLACK_CHANNEL_PIPELINE_ALERTS', 'DEMO_EMAIL_NOTIFICATIONS')\norder by\n    PROCESSED desc;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2f3b336e-3b01-4d6e-9edc-9424c083935f",
   "metadata": {
    "name": "BONUS_TIP",
    "collapsed": false,
    "resultHeight": 158
   },
   "source": "### Bonus tip:\n\nBuild your custom Alerts Monitoring Dashboard with Streamlit or Snowsight Dashboards\n\n* requires ACCOUNT_USAGE privileges\n* adjust to your local timezone in line 30"
  },
  {
   "cell_type": "code",
   "id": "5c15638f-4dfb-4336-bb86-549d12dbe79b",
   "metadata": {
    "language": "python",
    "name": "Streamlit_dashboard",
    "collapsed": false,
    "codeCollapsed": false,
    "resultHeight": 799
   },
   "outputs": [],
   "source": "import streamlit as st\nimport pandas as pd\nimport altair as alt\nsession = get_active_session()\n\nst.header('My Pipeline Alerts')\n\nALERTS = session.sql(\"\"\"\n        with LATEST_ALERTS as (\n            select\n                NAME as ALERT_NAME,\n                DATABASE_NAME,\n                SCHEMA_NAME,\n                max(SCHEDULED_TIME) as LATEST_SCHEDULED_TIME,\n                array_agg(case \n                            when STATE = 'TRIGGERED' then '🚨'\n                            when STATE = 'CONDITION_FALSE' then '✅'\n                            else '⚠️' end) within group (order by SCHEDULED_TIME desc) as STATE_HISTORY,            \n            from\n                SNOWFLAKE.ACCOUNT_USAGE.ALERT_HISTORY\n            group by\n                NAME,\n                DATABASE_NAME,\n                SCHEMA_NAME\n        )\n        select\n            L.ALERT_NAME,\n            --LATEST_SCHEDULED_TIME,\n            concat(to_char(convert_timezone('Europe/Berlin', LATEST_SCHEDULED_TIME), 'YYYY-MM-DD at HH:MI:SS'),' (',(timediff(minute, LATEST_SCHEDULED_TIME, current_timestamp())),' minutes ago)') as LAST_RUN,\n            case when D.STATE = 'TRIGGERED' then ('🚨 Triggered')\n                 when D.STATE = 'CONDITION_FALSE' then ('✅ Condition False')\n                 when D.STATE = 'CONDITION_FAILED' then ('⚠️ Condition Failed')\n                 when D.STATE = 'ACTION_FAILED' then ('⚠️ Action Failed')\n                 else concat('❌ ', D.STATE)\n                 end as LAST_RESULT,\n            STATE_HISTORY,\n            L.DATABASE_NAME,\n            L.SCHEMA_NAME\n        from\n            LATEST_ALERTS L\n        join\n            SNOWFLAKE.ACCOUNT_USAGE.ALERT_HISTORY D\n            on L.ALERT_NAME = D.NAME\n            and L.DATABASE_NAME = D.DATABASE_NAME\n            and L.SCHEMA_NAME = D.SCHEMA_NAME\n            and L.LATEST_SCHEDULED_TIME = D.SCHEDULED_TIME\n        order by\n            LAST_RUN desc\n        limit \n            100\n        \"\"\").to_pandas()\n\n\n\nALL_ALERTS_HISTOGRAM = session.sql(\"\"\"\n    select\n        count(distinct case when STATE = 'TRIGGERED'                            then NAME || '|' || SCHEMA_NAME || '|' || DATABASE_NAME end) as TRIGGERED,\n        count(distinct case when STATE = 'CONDITION_FALSE'                      then NAME || '|' || SCHEMA_NAME || '|' || DATABASE_NAME end) as CONDITION_FALSE,\n        count(distinct case when STATE in ('ACTION_FAILED', 'CONDITION_FAILED') then NAME || '|' || SCHEMA_NAME || '|' || DATABASE_NAME end) as ALERT_FAILED,\n        date_trunc(hour,SCHEDULED_TIME) as HOUR\n    from\n        SNOWFLAKE.ACCOUNT_USAGE.ALERT_HISTORY\n    where\n        timediff(day, SCHEDULED_TIME, current_timestamp()) < 7\n    group by\n        HOUR\n    order by\n        HOUR desc\n    \"\"\").to_pandas()\n \nMELTED_DF = ALL_ALERTS_HISTOGRAM.melt('HOUR', var_name='RESULT', value_name='COUNTER')\n    \nCHART = alt.Chart(MELTED_DF).mark_bar(size=5).encode(\n        x=alt.X('HOUR:T', axis=alt.Axis(title='Distinct Alerts running per hour')), \n        y=alt.Y('COUNTER:Q', axis=alt.Axis(title=None)), \n        color=alt.Color('RESULT:N', legend=None,\n                scale=alt.Scale(domain=['TRIGGERED', 'CONDITION_FALSE', 'ALERT_FAILED'], range=['#FF0000', '#008000', '#FFA500']))\n        ).properties(height=240)\n\nst.altair_chart(CHART, use_container_width=True)\n\n\n\n\n\n\nst.dataframe(ALERTS,\n             column_config={\n                \"STATE_HISTORY\": st.column_config.ListColumn(\"History (last 7 days)\")\n             },\n             hide_index= True, use_container_width=True)\n\n\n\n\nwith st.expander('Show Alerts History'):\n    ALERTS_HISTORY = session.sql(\"\"\"\n        select\n            SCHEDULED_TIME,\n            NAME,\n            STATE,\n            TIMEDIFF(second, SCHEDULED_TIME, COMPLETED_TIME) as DURATION_IN_S,\n            DATABASE_NAME,\n            SCHEMA_NAME\n        from \n            SNOWFLAKE.ACCOUNT_USAGE.ALERT_HISTORY \n        order by\n            SCHEDULED_TIME desc\n        limit \n            100\n    \"\"\").collect()\n    st.dataframe(ALERTS_HISTORY, hide_index= True, use_container_width=True)",
   "execution_count": null
  }
 ]
}