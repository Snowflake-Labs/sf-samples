{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0814a74-90b2-415c-8f6d-0615083ad2a1",
   "metadata": {},
   "source": [
    "## Imports and sflk session\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "4556db78-936e-436b-a0f8-d5a9850c5657",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Initialization"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CURRENT_ACCOUNT()</th>\n",
       "      <th>CURRENT_USER()</th>\n",
       "      <th>CURRENT_ROLE()</th>\n",
       "      <th>CURRENT_DATABASE()</th>\n",
       "      <th>CURRENT_SCHEMA()</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CIB92733</td>\n",
       "      <td>JPRUSA</td>\n",
       "      <td>SERVICESNOW_USER_ROLE</td>\n",
       "      <td>FASHION</td>\n",
       "      <td>PUBLIC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  CURRENT_ACCOUNT() CURRENT_USER()         CURRENT_ROLE() CURRENT_DATABASE()  \\\n",
       "0          CIB92733         JPRUSA  SERVICESNOW_USER_ROLE            FASHION   \n",
       "\n",
       "  CURRENT_SCHEMA()  \n",
       "0           PUBLIC  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML , Markdown\n",
    "from snowflake.snowpark.session import Session\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import logging\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.io import read_image\n",
    "\n",
    "\n",
    "# Import the commonly defined utility scripts using\n",
    "# dynamic path include\n",
    "import sys\n",
    "sys.path.append('../python/lutils')\n",
    "import sflk_base as L\n",
    "\n",
    "display(Markdown(\"### Initialization\"))\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.ERROR)\n",
    "\n",
    "# Source various helper functions\n",
    "%run ./scripts/notebook_helpers.py\n",
    "\n",
    "# Define the project home directory, this is used for locating the config.ini file\n",
    "PROJECT_HOME_DIR = '../../'\n",
    "config = L.get_config(PROJECT_HOME_DIR)\n",
    "session = L.connect_to_snowflake(PROJECT_HOME_DIR)\n",
    "\n",
    "if(session == None):\n",
    "   raise Exception(f'Unable to connect to snowflake. Validate connection information ')\n",
    "\n",
    "session.use_role(f'''{config['APP_DB']['role']}''')\n",
    "session.use_schema(f'''{config['APP_DB']['database']}.{config['APP_DB']['schema']}''')\n",
    "session.use_warehouse(f'''{config['SNOW_CONN']['warehouse']}''')\n",
    "\n",
    "df1 = session.sql('select current_account(), current_user() ,current_role() ,current_database() ,current_schema();').to_pandas()\n",
    "display(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c56bf96-6223-4fee-8fe2-c7b54fe3769e",
   "metadata": {},
   "source": [
    "## Train/Test annotations \n",
    "\n",
    "To train our embedding model, we need a train and validation split. We elect a 90:10 split, where 90% of the data is used for training and 10% to validate model performance to identify the best model iteration and avoid overfitting.\n",
    "\n",
    "We create a train and test annotation file containing the image names and labels (classes) for the images selected for training and validation. Since model training resizes images to 256x256 pixels, we are using our preprocessed images which have already been resized to have have a dimension of 256 on their shortest size. This saves time/bandwidth when pushing the images into staging, and uses less space in staging.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f3a63d12-615c-4d6c-907e-e15fa59933cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create dataframe of all preprocessed images and labels\n",
    "image_files = os.listdir('../../data_preprocessed')\n",
    "image_labels = [x.replace('t_shirt', 'tshirt').split('_')[0] for x in image_files]\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    'img_name': image_files,\n",
    "    'label': image_labels\n",
    "})\n",
    "# randomly split into train and test with a 90:10 ratio\n",
    "msk = np.random.rand(len(data)) < 0.9\n",
    "train = data[msk]\n",
    "test = data[~msk]\n",
    "\n",
    "# save as csvs\n",
    "train.to_csv('sim_train.csv', index=False)\n",
    "test.to_csv('sim_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6c9f0e-83f2-4a64-8e34-dca72d79d9fd",
   "metadata": {},
   "source": [
    "## Upload data to to staging\n",
    "\n",
    "The best way for our model to ingest images while training is to have them mounted in a volume on the training container created by Snowflake Container Services (SCS). SCS lets us mount any stage provided it is encrypted with `SNOWFLAKE_SSE` encryption. Thus, we create a new stage `Image_STG` with `SNOWFLAKE_SSE` encryption and push our preprocessed images to this stage. We also push both annotation files to this stage so that they can be leveraged by our training script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "fa8f9a7d-309d-449c-9c04-ea67f82b616d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(status='Stage area IMAGE_STG successfully created.')]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#only run the first time to create the stage. do not run again, or we'll lose our images\n",
    "\n",
    "#session.sql(\"CREATE OR REPLACE STAGE IMAGE_STG ENCRYPTION = (type = 'SNOWFLAKE_SSE')\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "1f82d985-abcb-4380-94c3-704768280f1d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_on</th>\n",
       "      <th>name</th>\n",
       "      <th>database_name</th>\n",
       "      <th>schema_name</th>\n",
       "      <th>url</th>\n",
       "      <th>has_credentials</th>\n",
       "      <th>has_encryption_key</th>\n",
       "      <th>owner</th>\n",
       "      <th>comment</th>\n",
       "      <th>region</th>\n",
       "      <th>type</th>\n",
       "      <th>cloud</th>\n",
       "      <th>notification_channel</th>\n",
       "      <th>storage_integration</th>\n",
       "      <th>owner_role_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-09-11 11:29:40.914000-07:00</td>\n",
       "      <td>FASHION_REPOSITORY</td>\n",
       "      <td>FASHION</td>\n",
       "      <td>PUBLIC</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>SERVICESNOW_USER_ROLE</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>IMAGE REPOSITORY</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ROLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-09-26 09:12:25.666000-07:00</td>\n",
       "      <td>IMAGE_STG</td>\n",
       "      <td>FASHION</td>\n",
       "      <td>PUBLIC</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>SERVICESNOW_USER_ROLE</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>INTERNAL NO CSE</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ROLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-08-31 14:55:29.865000-07:00</td>\n",
       "      <td>MODELS</td>\n",
       "      <td>FASHION</td>\n",
       "      <td>PUBLIC</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>SERVICESNOW_USER_ROLE</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>INTERNAL NO CSE</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ROLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-07-31 09:00:30.527000-07:00</td>\n",
       "      <td>MODEL_STG</td>\n",
       "      <td>FASHION</td>\n",
       "      <td>PUBLIC</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>SERVICESNOW_USER_ROLE</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>INTERNAL</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ROLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-09-13 13:18:56.893000-07:00</td>\n",
       "      <td>UDF_STG</td>\n",
       "      <td>FASHION</td>\n",
       "      <td>PUBLIC</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>SERVICESNOW_USER_ROLE</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>INTERNAL</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ROLE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        created_on                name database_name  \\\n",
       "0 2023-09-11 11:29:40.914000-07:00  FASHION_REPOSITORY       FASHION   \n",
       "1 2023-09-26 09:12:25.666000-07:00           IMAGE_STG       FASHION   \n",
       "2 2023-08-31 14:55:29.865000-07:00              MODELS       FASHION   \n",
       "3 2023-07-31 09:00:30.527000-07:00           MODEL_STG       FASHION   \n",
       "4 2023-09-13 13:18:56.893000-07:00             UDF_STG       FASHION   \n",
       "\n",
       "  schema_name url has_credentials has_encryption_key                  owner  \\\n",
       "0      PUBLIC                   N                  N  SERVICESNOW_USER_ROLE   \n",
       "1      PUBLIC                   N                  N  SERVICESNOW_USER_ROLE   \n",
       "2      PUBLIC                   N                  N  SERVICESNOW_USER_ROLE   \n",
       "3      PUBLIC                   N                  N  SERVICESNOW_USER_ROLE   \n",
       "4      PUBLIC                   N                  N  SERVICESNOW_USER_ROLE   \n",
       "\n",
       "  comment region              type cloud notification_channel  \\\n",
       "0           None  IMAGE REPOSITORY  None                 None   \n",
       "1           None   INTERNAL NO CSE  None                 None   \n",
       "2           None   INTERNAL NO CSE  None                 None   \n",
       "3           None          INTERNAL  None                 None   \n",
       "4           None          INTERNAL  None                 None   \n",
       "\n",
       "  storage_integration owner_role_type  \n",
       "0                None            ROLE  \n",
       "1                None            ROLE  \n",
       "2                None            ROLE  \n",
       "3                None            ROLE  \n",
       "4                None            ROLE  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(session.sql('SHOW STAGES').collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "23013d4c-56ba-4ba1-a422-02007f54599a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this lets us resume from partial upload, always run before running the cell below\n",
    "\n",
    "uploaded = pd.DataFrame(session.sql('LIST @IMAGE_STG/data_preprocessed').collect())\n",
    "if 'name' in uploaded.columns:\n",
    "    uploaded = uploaded.name.apply(lambda x: x.split('/')[-1]).values\n",
    "else:\n",
    "    uploaded=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f79d8b29-8ae7-4f7e-831d-d8060f956832",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 5762/5762 [1:03:10<00:00,  1.52it/s]\n"
     ]
    }
   ],
   "source": [
    "# preprocessed images\n",
    "failed = [] # the event any fail we can track which fail\n",
    "for img in tqdm.tqdm(image_files):\n",
    "    if img not in uploaded:\n",
    "        try:\n",
    "            session.sql(f\"\"\"PUT file:///Users/jprusa/documents/github/FASHION/data_preprocessed/{img} \n",
    "        @IMAGE_STG/data_preprocessed AUTO_COMPRESS=FALSE OVERWRITE=TRUE;\"\"\").collect()\n",
    "        except:\n",
    "            failed.append(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "ed100f04-4c8e-4940-8aad-3fd4f56bb955",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(source='sim_test.csv', target='sim_test.csv', source_size=31655, target_size=31655, source_compression='NONE', target_compression='NONE', status='UPLOADED', message='')]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train and test annotation file\n",
    "session.sql(f\"\"\"PUT file:///Users/jprusa/documents/github/FASHION/src/notebook/sim_train.csv\n",
    "@IMAGE_STG AUTO_COMPRESS=FALSE OVERWRITE=TRUE;\"\"\").collect()\n",
    "session.sql(f\"\"\"PUT file:///Users/jprusa/documents/github/FASHION/src/notebook/sim_test.csv\n",
    "@IMAGE_STG AUTO_COMPRESS=FALSE OVERWRITE=TRUE;\"\"\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "48183445-277d-4802-9f97-e5b078f90dcd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>size</th>\n",
       "      <th>md5</th>\n",
       "      <th>last_modified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>image_stg/data_preprocessed/blazer_00b8048d-63...</td>\n",
       "      <td>8820</td>\n",
       "      <td>6992a671d7e3c4a275c11480628abc17</td>\n",
       "      <td>Tue, 26 Sep 2023 16:52:21 GMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>image_stg/data_preprocessed/blazer_01a54355-b5...</td>\n",
       "      <td>9562</td>\n",
       "      <td>5ecc710646521b8f64ef441fc0cfae09</td>\n",
       "      <td>Tue, 26 Sep 2023 17:11:40 GMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>image_stg/data_preprocessed/blazer_03c6360d-73...</td>\n",
       "      <td>13572</td>\n",
       "      <td>7e7b4463fc0179868a922ca580cdd983</td>\n",
       "      <td>Tue, 26 Sep 2023 16:59:38 GMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>image_stg/data_preprocessed/blazer_06aaacf1-ba...</td>\n",
       "      <td>11016</td>\n",
       "      <td>888db1e4bec0a2c9a6bcdf1f8f3314a8</td>\n",
       "      <td>Tue, 26 Sep 2023 16:17:20 GMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>image_stg/data_preprocessed/blazer_094a6288-3f...</td>\n",
       "      <td>8488</td>\n",
       "      <td>1baba40dfa672e830fe03f12ebc4fcf4</td>\n",
       "      <td>Tue, 26 Sep 2023 16:58:09 GMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5759</th>\n",
       "      <td>image_stg/data_preprocessed/undershirt_f8bf048...</td>\n",
       "      <td>12078</td>\n",
       "      <td>64aff4398e86193390d85209baa7d124</td>\n",
       "      <td>Tue, 26 Sep 2023 16:30:51 GMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5760</th>\n",
       "      <td>image_stg/data_preprocessed/undershirt_fdee18e...</td>\n",
       "      <td>10073</td>\n",
       "      <td>c65a2896d1bea677640ef4aac6096e73</td>\n",
       "      <td>Tue, 26 Sep 2023 16:23:12 GMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5761</th>\n",
       "      <td>image_stg/data_preprocessed/undershirt_ff80d9e...</td>\n",
       "      <td>12834</td>\n",
       "      <td>6b24f2a36a9806e6d6be80aba1fa4c26</td>\n",
       "      <td>Tue, 26 Sep 2023 17:14:33 GMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5762</th>\n",
       "      <td>image_stg/sim_test.csv</td>\n",
       "      <td>31655</td>\n",
       "      <td>a8240f5d96bc475a7851387458371292</td>\n",
       "      <td>Tue, 26 Sep 2023 19:16:51 GMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5763</th>\n",
       "      <td>image_stg/sim_train.csv</td>\n",
       "      <td>290367</td>\n",
       "      <td>a0e986823aa643d038c72a65317c5658</td>\n",
       "      <td>Tue, 26 Sep 2023 19:16:50 GMT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5764 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   name    size  \\\n",
       "0     image_stg/data_preprocessed/blazer_00b8048d-63...    8820   \n",
       "1     image_stg/data_preprocessed/blazer_01a54355-b5...    9562   \n",
       "2     image_stg/data_preprocessed/blazer_03c6360d-73...   13572   \n",
       "3     image_stg/data_preprocessed/blazer_06aaacf1-ba...   11016   \n",
       "4     image_stg/data_preprocessed/blazer_094a6288-3f...    8488   \n",
       "...                                                 ...     ...   \n",
       "5759  image_stg/data_preprocessed/undershirt_f8bf048...   12078   \n",
       "5760  image_stg/data_preprocessed/undershirt_fdee18e...   10073   \n",
       "5761  image_stg/data_preprocessed/undershirt_ff80d9e...   12834   \n",
       "5762                             image_stg/sim_test.csv   31655   \n",
       "5763                            image_stg/sim_train.csv  290367   \n",
       "\n",
       "                                   md5                  last_modified  \n",
       "0     6992a671d7e3c4a275c11480628abc17  Tue, 26 Sep 2023 16:52:21 GMT  \n",
       "1     5ecc710646521b8f64ef441fc0cfae09  Tue, 26 Sep 2023 17:11:40 GMT  \n",
       "2     7e7b4463fc0179868a922ca580cdd983  Tue, 26 Sep 2023 16:59:38 GMT  \n",
       "3     888db1e4bec0a2c9a6bcdf1f8f3314a8  Tue, 26 Sep 2023 16:17:20 GMT  \n",
       "4     1baba40dfa672e830fe03f12ebc4fcf4  Tue, 26 Sep 2023 16:58:09 GMT  \n",
       "...                                ...                            ...  \n",
       "5759  64aff4398e86193390d85209baa7d124  Tue, 26 Sep 2023 16:30:51 GMT  \n",
       "5760  c65a2896d1bea677640ef4aac6096e73  Tue, 26 Sep 2023 16:23:12 GMT  \n",
       "5761  6b24f2a36a9806e6d6be80aba1fa4c26  Tue, 26 Sep 2023 17:14:33 GMT  \n",
       "5762  a8240f5d96bc475a7851387458371292  Tue, 26 Sep 2023 19:16:51 GMT  \n",
       "5763  a0e986823aa643d038c72a65317c5658  Tue, 26 Sep 2023 19:16:50 GMT  \n",
       "\n",
       "[5764 rows x 4 columns]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that everything is in place in staging\n",
    "pd.DataFrame(session.sql('LIST @IMAGE_STG').collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69605c78-e08c-43f3-b2f5-bde99aae5946",
   "metadata": {},
   "source": [
    "## Create and Push Docker Image\n",
    "0. open a terminal window and `cd` into `/src/docker`\n",
    "\n",
    "1. Using the Docker CLI, execute the docker build command, specifying the current working directory (.):\n",
    "\n",
    "    `docker build --rm --platform linux/amd64 -t <image_name> .`\n",
    "\n",
    "2. Tag the image with the image URL:\n",
    "image_name = 'fashion:recommender'\n",
    "repository_url = 'sfsenorthamerica-polaris2.registry.snowflakecomputing.com/fashion/public/fashion_repository'\n",
    "db = 'fashion'\n",
    "schema = 'public'\n",
    "repo = 'fashion_repository'\n",
    "user_name = 'jprusa'\n",
    "    `docker tag <image_name> <repository_url>/<image_name>`\n",
    "\n",
    "3. To authenticate Docker with the Snowflake registry, execute the docker login command:\n",
    "\n",
    "    `docker login <repository_url> -u <user_name>`\n",
    "\n",
    "4. To upload the image to the image repository, execute the following docker push command:\n",
    "\n",
    "    `docker push <repository_url>/<image_name>`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1fe70cfe-242a-4483-a0c3-a89cd3aa75ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_name = 'fashion:image_embeddings'\n",
    "repository_url = 'sfsenorthamerica-polaris2.registry.snowflakecomputing.com/fashion/public/fashion_repository'\n",
    "db = 'fashion'\n",
    "schema = 'public'\n",
    "repo = 'fashion_repository'\n",
    "user_name = 'jprusa'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "53705648-c8e5-4c83-9a56-9578acb44cc7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docker build --rm --platform linux/amd64 -t fashion:image_embeddings .\n",
      "\n",
      "docker tag fashion:image_embeddings sfsenorthamerica-polaris2.registry.snowflakecomputing.com/fashion/public/fashion_repository/fashion:image_embeddings\n",
      "\n",
      "docker login sfsenorthamerica-polaris2.registry.snowflakecomputing.com/fashion/public/fashion_repository -u jprusa\n",
      "\n",
      "docker push sfsenorthamerica-polaris2.registry.snowflakecomputing.com/fashion/public/fashion_repository/fashion:image_embeddings\n"
     ]
    }
   ],
   "source": [
    "print(f\"docker build --rm --platform linux/amd64 -t {image_name} .\")\n",
    "print(f\"\\ndocker tag {image_name} {repository_url}/{image_name}\")\n",
    "print(f\"\\ndocker login {repository_url} -u {user_name}\")\n",
    "print(f\"\\ndocker push {repository_url}/{image_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a9e70b-c987-4f99-a51f-33575371d943",
   "metadata": {},
   "source": [
    "## Launch Container Service\n",
    "\n",
    "Since we are running a training job, we will create a service that when executed:\n",
    "\n",
    "1. downloads a base image classification model\n",
    "2. finetunes the model on our data\n",
    "3. saves the best model to staging \n",
    "4. converts the best model to an embedding model\n",
    "5. saves the embedding model to staging\n",
    "\n",
    "### Create Compute Pool\n",
    "\n",
    "Since we are training a deep learning model in pytorch, we create a gpu compute pool to execute our service on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "a034d8ce-7ee0-4d7e-a138-00286d2b0999",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(status='Compute Pool EMBEDDING_COMPUTE_POOL successfully created.')]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.sql(\"\"\"CREATE OR REPLACE COMPUTE POOL embedding_compute_pool\n",
    "  MIN_NODES = 1\n",
    "  MAX_NODES = 1\n",
    "  INSTANCE_FAMILY = GPU_7;\"\"\").collect() # HIGH_MEMORY_5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd90e6aa-7511-490b-971b-bdfc3411beb4",
   "metadata": {},
   "source": [
    "### Upload spec.yaml and run service\n",
    "\n",
    "This yaml provides important specifications for our training service. In addition to specifying the docker image we will be using, this is also where we specify three mounted volumes in this yaml. \n",
    "\n",
    "    1. `images`, from `@IMAGE_STG`. This contains our images and annotation files\n",
    "    2. `models`, from `@MODELS`. This is where we will save our trained models to\n",
    "    3. `dshm`, from memory. This is a shared space used while training our deep learning model. If we fail to define this, a default value is used that is far to small and results in segmentation faults while training.\n",
    "    \n",
    "Additionally, we define 3 environment variables\n",
    "\n",
    "    1. IMAGE_PATH: location of training images in the mounted volume\n",
    "    2. ANNOTATION_PATH: location of image annotations in the mounted volume\n",
    "    3. SAVE_PATH: location of the mounted volume we will save our model to\n",
    "    \n",
    "    \n",
    "`EXECUTE SERVICE` is used (instead of CREATE SERVICE) as we want our service to run, then automatically shut down the container once training is complete.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "6d82ab76-8eec-497b-8b29-a91b18c5961f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(source='embedding_spec.yaml', target='embedding_spec.yaml', source_size=691, target_size=704, source_compression='NONE', target_compression='NONE', status='UPLOADED', message='')]"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# push spec.yaml to stage\n",
    "session.sql(\"\"\"PUT file:///Users/jprusa/documents/github/Fashion/src/docker_embedding/embedding_spec.yaml \n",
    "@MODEL_STG AUTO_COMPRESS=FALSE OVERWRITE=TRUE;\"\"\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "1a24237e-021d-450a-aa75-7ce74463f3ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# execute service\n",
    "output = session.sql(\"\"\"EXECUTE SERVICE\n",
    "  IN COMPUTE POOL embedding_compute_pool\n",
    "  FROM @MODEL_STG\n",
    "  SPEC='embedding_spec.yaml';\"\"\").collect()\n",
    "UUID = output[0][0].split()[-1][:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2523d3fd-bf78-4764-9291-f3f55215d729",
   "metadata": {},
   "source": [
    "### Check status and logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "eaea7d59-9935-42e5-845a-bb31eb9798de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'status': 'READY',\n",
       "  'message': 'Running',\n",
       "  'containerName': 'fashion',\n",
       "  'instanceId': '0',\n",
       "  'serviceName': 'JOB_01AF41060001C60F00226D870235EC7A',\n",
       "  'image': 'sfsenorthamerica-polaris2.registry.snowflakecomputing.com/fashion/public/fashion_repository/fashion:image_embeddings',\n",
       "  'restartCount': 0,\n",
       "  'startTime': '2023-09-26T20:22:51Z'}]"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check status of service\n",
    "eval(session.sql(f\"SELECT SYSTEM$GET_JOB_STATUS('{UUID}');\").collect()[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "288beed4-e3cc-4a45-8ea4-c004eb1825d9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
      "100%|██████████| 44.7M/44.7M [00:00<00:00, 253MB/s]\n",
      "Epoch 0/24\n",
      "----------\n",
      "100%|██████████| 325/325 [01:38<00:00,  3.29it/s]\n",
      "train Loss: 1.9486 Acc: 0.4467\n",
      "100%|██████████| 36/36 [00:11<00:00,  3.22it/s]\n",
      "val Loss: 1.3178 Acc: 0.6277\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "100%|██████████| 325/325 [00:18<00:00, 17.85it/s]\n",
      "train Loss: 1.4555 Acc: 0.5727\n",
      "100%|██████████| 36/36 [00:01<00:00, 18.01it/s]\n",
      "val Loss: 1.1248 Acc: 0.6507\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "100%|██████████| 325/325 [00:17<00:00, 18.66it/s]\n",
      "train Loss: 1.2793 Acc: 0.6179\n",
      "100%|██████████| 36/36 [00:01<00:00, 18.74it/s]\n",
      "val Loss: 1.0156 Acc: 0.6809\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "100%|██████████| 325/325 [00:17<00:00, 18.78it/s]\n",
      "train Loss: 1.2248 Acc: 0.6368\n",
      "100%|██████████| 36/36 [00:01<00:00, 18.34it/s]\n",
      "val Loss: 1.0476 Acc: 0.6986\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "100%|██████████| 325/325 [00:16<00:00, 19.12it/s]\n",
      "train Loss: 1.1282 Acc: 0.6566\n",
      "100%|██████████| 36/36 [00:01<00:00, 18.89it/s]\n",
      "val Loss: 0.9713 Acc: 0.7021\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "100%|██████████| 325/325 [00:16<00:00, 19.48it/s]\n",
      "train Loss: 1.0668 Acc: 0.6701\n",
      "100%|██████████| 36/36 [00:02<00:00, 16.36it/s]\n",
      "val Loss: 0.9568 Acc: 0.7305\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "100%|██████████| 325/325 [00:18<00:00, 17.81it/s]\n",
      "train Loss: 1.0326 Acc: 0.6833\n",
      "100%|██████████| 36/36 [00:02<00:00, 16.86it/s]\n",
      "val Loss: 0.9982 Acc: 0.7039\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "100%|██████████| 325/325 [00:19<00:00, 16.90it/s]\n",
      "train Loss: 0.9297 Acc: 0.7126\n",
      "100%|██████████| 36/36 [00:02<00:00, 17.12it/s]\n",
      "val Loss: 0.9525 Acc: 0.7234\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n",
      "100%|██████████| 325/325 [00:18<00:00, 17.29it/s]\n",
      "train Loss: 0.8795 Acc: 0.7309\n",
      "100%|██████████| 36/36 [00:01<00:00, 18.64it/s]\n",
      "val Loss: 0.9305 Acc: 0.7181\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n",
      "100%|██████████| 325/325 [00:17<00:00, 18.71it/s]\n",
      "train Loss: 0.8563 Acc: 0.7389\n",
      "100%|██████████| 36/36 [00:01<00:00, 18.99it/s]\n",
      "val Loss: 0.9306 Acc: 0.7110\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n",
      "100%|██████████| 325/325 [00:17<00:00, 18.32it/s]\n",
      "train Loss: 0.8506 Acc: 0.7366\n",
      "100%|██████████| 36/36 [00:02<00:00, 16.23it/s]\n",
      "val Loss: 0.9436 Acc: 0.7234\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n",
      "100%|██████████| 325/325 [00:18<00:00, 17.17it/s]\n",
      "train Loss: 0.8170 Acc: 0.7513\n",
      "100%|██████████| 36/36 [00:02<00:00, 16.77it/s]\n",
      "val Loss: 0.9349 Acc: 0.7074\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n",
      "100%|██████████| 325/325 [00:19<00:00, 16.40it/s]\n",
      "train Loss: 0.8321 Acc: 0.7399\n",
      "100%|██████████| 36/36 [00:02<00:00, 16.15it/s]\n",
      "val Loss: 0.9480 Acc: 0.7252\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n",
      "100%|██████████| 325/325 [00:18<00:00, 17.42it/s]\n",
      "train Loss: 0.8190 Acc: 0.7437\n",
      "100%|██████████| 36/36 [00:01<00:00, 18.11it/s]\n",
      "val Loss: 0.9274 Acc: 0.7270\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n",
      "100%|██████████| 325/325 [00:18<00:00, 17.62it/s]\n",
      "train Loss: 0.7894 Acc: 0.7530\n",
      "100%|██████████| 36/36 [00:02<00:00, 16.53it/s]\n",
      "val Loss: 0.9358 Acc: 0.7181\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n",
      " 79%|███████▉  | 258/325 [00:14<00:03, 19.90it/s]\n"
     ]
    }
   ],
   "source": [
    "# check logs for training progress \n",
    "print(session.sql(f\"SELECT SYSTEM$GET_JOB_LOGS('{UUID}', 'fashion');\").collect()[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0a5c00-b6f2-4317-bb8d-666ad8953854",
   "metadata": {},
   "source": [
    "### Check that models were saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "17bc4215-784c-46bd-87a3-6d0f793fa76c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>size</th>\n",
       "      <th>md5</th>\n",
       "      <th>last_modified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>models/.ipynb_checkpoints/image_captioning-che...</td>\n",
       "      <td>5483</td>\n",
       "      <td>cca7bff8fdad45e40503201398e412c7</td>\n",
       "      <td>Thu, 31 Aug 2023 23:00:00 GMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>models/best_model.pt</td>\n",
       "      <td>44838851</td>\n",
       "      <td>3cfa9610a9af4a5decc6bf5d38d562af-5</td>\n",
       "      <td>Tue, 26 Sep 2023 20:32:59 GMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>models/embedding_model.pt</td>\n",
       "      <td>44795880</td>\n",
       "      <td>a11751037dd96d7dc50d3c9bcb9bde53-5</td>\n",
       "      <td>Tue, 26 Sep 2023 20:33:00 GMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>models/image_captioning.ipynb</td>\n",
       "      <td>5483</td>\n",
       "      <td>cca7bff8fdad45e40503201398e412c7</td>\n",
       "      <td>Thu, 31 Aug 2023 23:00:00 GMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>models/images.csv</td>\n",
       "      <td>130087123</td>\n",
       "      <td>cd19eff08e06f2717f96fde15d2c5e3d</td>\n",
       "      <td>Thu, 31 Aug 2023 22:27:33 GMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>models/images_captioned.csv</td>\n",
       "      <td>130370149</td>\n",
       "      <td>f7f7ed81de778dad65989757e3df5768-13</td>\n",
       "      <td>Thu, 31 Aug 2023 22:59:56 GMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>models/spec-finetune.yaml</td>\n",
       "      <td>535</td>\n",
       "      <td>aa7f212e0607ea6c9c1ae54a7b99298e</td>\n",
       "      <td>Fri, 1 Sep 2023 13:34:48 GMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>models/spec_img_desc.yaml</td>\n",
       "      <td>553</td>\n",
       "      <td>611deac90a1f4ac646fc098ebeff0be6</td>\n",
       "      <td>Thu, 31 Aug 2023 21:56:22 GMT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name       size  \\\n",
       "0  models/.ipynb_checkpoints/image_captioning-che...       5483   \n",
       "1                               models/best_model.pt   44838851   \n",
       "2                          models/embedding_model.pt   44795880   \n",
       "3                      models/image_captioning.ipynb       5483   \n",
       "4                                  models/images.csv  130087123   \n",
       "5                        models/images_captioned.csv  130370149   \n",
       "6                          models/spec-finetune.yaml        535   \n",
       "7                          models/spec_img_desc.yaml        553   \n",
       "\n",
       "                                   md5                  last_modified  \n",
       "0     cca7bff8fdad45e40503201398e412c7  Thu, 31 Aug 2023 23:00:00 GMT  \n",
       "1   3cfa9610a9af4a5decc6bf5d38d562af-5  Tue, 26 Sep 2023 20:32:59 GMT  \n",
       "2   a11751037dd96d7dc50d3c9bcb9bde53-5  Tue, 26 Sep 2023 20:33:00 GMT  \n",
       "3     cca7bff8fdad45e40503201398e412c7  Thu, 31 Aug 2023 23:00:00 GMT  \n",
       "4     cd19eff08e06f2717f96fde15d2c5e3d  Thu, 31 Aug 2023 22:27:33 GMT  \n",
       "5  f7f7ed81de778dad65989757e3df5768-13  Thu, 31 Aug 2023 22:59:56 GMT  \n",
       "6     aa7f212e0607ea6c9c1ae54a7b99298e   Fri, 1 Sep 2023 13:34:48 GMT  \n",
       "7     611deac90a1f4ac646fc098ebeff0be6  Thu, 31 Aug 2023 21:56:22 GMT  "
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(session.sql('LIST @MODELS').collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf0372c-0bed-4a14-a2de-46b81c380161",
   "metadata": {},
   "source": [
    "## Stop Service and Clean Up\n",
    "\n",
    "we need to stop any running service(s) on our compute pool and stop the compute pool as we will continue to be charged as long as the compute exists, even if no services are actively running on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "2df53879-c3fe-411e-b10d-968af8db7be7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(status='Statement executed successfully.')]"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stop services running on the compute pool\n",
    "session.sql(\"\"\"ALTER COMPUTE POOL embedding_compute_pool STOP ALL;\"\"\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "8001aa1b-beb4-4263-a91e-e05dab99518b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(status='EMBEDDING_COMPUTE_POOL successfully dropped.')]"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shut down compute pool\n",
    "session.sql(\"\"\"DROP COMPUTE POOL embedding_compute_pool;\"\"\").collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
