{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d68878a7-ebc2-412f-8476-881e7c876a64",
   "metadata": {},
   "source": [
    "Article for inspiration: https://www.snowflake.com/blog/container-services-llama2-snowpark-ml/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "11e6af3e-d311-49ba-ba7e-f379b1c9f776",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.snowpark.session import Session\n",
    "from snowflake.ml.registry import model_registry\n",
    "from snowflake.ml.model import deploy_platforms\n",
    "\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f421d77c-5053-48dc-b9c6-703801d71b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_parameters = json.load(open('/Users/skhara/Documents/Code/creds_spcs.json'))\n",
    "session = Session.builder.configs(connection_parameters).create()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5c9d19-c103-4352-8e91-1bb46c80c30b",
   "metadata": {},
   "source": [
    "#### Compute Pool\n",
    "A compute pool is a collection of virtual machines or nodes which can have GPUs.\n",
    "This process takes time.\n",
    "\n",
    "#### Learn More:\n",
    "https://medium.com/snowflake/snowpark-container-services-a-tech-primer-99ff2ca8e741#:~:text=my_image%3Alatest-,Compute%20Pools,-A%20service%20in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "74d941c3-252d-4fda-bc2e-4d4d2cf3ddb7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(status='Compute Pool SKHARA_COMPUTE_GPU3 successfully created.')]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.sql('''CREATE COMPUTE POOL SKHARA_COMPUTE_GPU3\n",
    "MIN_NODES = 1\n",
    "MAX_NODES = 1\n",
    "INSTANCE_FAMILY = \"GPU_3\"\n",
    "''').collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab3957c-b5a2-4f0b-ba38-c017efba4ecd",
   "metadata": {},
   "source": [
    "# 1.0 LLAMA Model Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44cbe0fe-4b01-48a0-9224-6bb607dc4d0a",
   "metadata": {},
   "source": [
    "## 1.1 Load LLAMA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "91d1f137-c1f7-41ce-92c2-45aead415145",
   "metadata": {},
   "outputs": [],
   "source": [
    "HF_AUTH_TOKEN = \"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\" #Your token from Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3f79b171-c59a-48a6-9132-2d9f94f2869b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import pipeline\n",
    "from snowflake.ml.model.models import huggingface_pipeline\n",
    "\n",
    "llama_model = huggingface_pipeline.HuggingFacePipelineModel(task=\"text-generation\",\n",
    "                                                            model=\"meta-llama/Llama-2-7b-chat-hf\",\n",
    "                                                            token=HF_AUTH_TOKEN,\n",
    "                                                            return_full_text=False,\n",
    "                                                            max_new_tokens=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9441ff24-d65b-4678-bdd6-0956b31d6788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.getsizeof(llama_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498b5b02-ee82-4203-90b1-729082c9b9d3",
   "metadata": {},
   "source": [
    "## 1.2 Register the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "be126725-457c-45b8-8888-c3a0e1c80ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "create_model_registry() is in private preview since 0.2.0. Do not use it in production. \n",
      "WARNING:absl:The database SKHARA already exists. Skipping creation.\n"
     ]
    }
   ],
   "source": [
    "registry_name = 'SKHARA' #Replace this with the name of a database that you have access to\n",
    "schema_name = 'BUILD_REGISTRY'\n",
    "\n",
    "model_registry.create_model_registry(session= session,\n",
    "                                     database_name= registry_name,\n",
    "                                     schema_name= schema_name)\n",
    "\n",
    "registry = model_registry.ModelRegistry(session= session,\n",
    "                                        database_name= registry_name,\n",
    "                                        schema_name= schema_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "54bbce04-1567-4d4f-b014-31306cdbad08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:snowflake.snowpark:ModelRegistry.log_model() is in private preview since 0.2.0. Do not use it in production. \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<snowflake.ml.registry.model_registry.ModelReference at 0x105b355b0>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_NAME = \"LLAMA2_MODEL_7b_CHAT\"\n",
    "MODEL_VERSION = \"1\"\n",
    "\n",
    "llama_model_ref= registry.log_model(\n",
    "    model_name=MODEL_NAME,\n",
    "    model_version=MODEL_VERSION,\n",
    "    model=llama_model\n",
    ")\n",
    "\n",
    "llama_model_ref"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca777a9d-b01a-4a5f-b547-2e6661780a0b",
   "metadata": {},
   "source": [
    "## 1.3 Deploy Model\n",
    "\n",
    "Pre-req: create a GPU compute pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "01eee5d7-a159-4c8f-a882-60455526b4d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(name='SKHARA_COMPUTE_GPU3', state='IDLE', min_nodes=1, max_nodes=1, instance_family='GPU_3', num_services=0, num_jobs=0, auto_suspend_secs=3600, auto_resume='true', active_nodes=0, idle_nodes=1, created_on=datetime.datetime(2023, 10, 31, 13, 28, 56, 790000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), resumed_on=datetime.datetime(2023, 10, 31, 13, 28, 56, 802000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), updated_on=datetime.datetime(2023, 10, 31, 15, 35, 31, 274000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), owner='SPC_USER_ROLE', comment=None),\n",
       " Row(name='SKHARA_COMPUTE_GPU7', state='SUSPENDED', min_nodes=1, max_nodes=1, instance_family='GPU_7', num_services=0, num_jobs=0, auto_suspend_secs=0, auto_resume='true', active_nodes=0, idle_nodes=0, created_on=datetime.datetime(2023, 10, 16, 13, 42, 37, 390000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), resumed_on=datetime.datetime(2023, 10, 26, 9, 33, 36, 485000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), updated_on=datetime.datetime(2023, 10, 31, 15, 33, 0, 801000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), owner='SPC_USER_ROLE', comment=None)]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if compute pool is ready. It may take some time for the compute resource to be ready.\n",
    "session.sql('''Show compute pools like 'SKHARA_%';''').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236dee2f-1d53-4e63-868b-1533e3d1d06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:snowflake.ml.model._deploy_client.snowservice.deploy:Building the Docker image and deploying to Snowpark Container Service. This process may take a few minutes.\n"
     ]
    }
   ],
   "source": [
    "llama_model_ref.deploy(\n",
    "    deployment_name=\"llama_predict\",\n",
    "    platform= deploy_platforms.TargetPlatform.SNOWPARK_CONTAINER_SERVICES,\n",
    "    options={\"compute_pool\": \"SKHARA_COMPUTE_GPU3\",\n",
    "             \"num_gpus\": 1,\n",
    "             # Remove the 'prebuilt_snowflake_image' argument below when running .deploy() for the first time\n",
    "             #\"prebuilt_snowflake_image\": \"sfsenorthamerica-fcto-spc.registry.snowflakecomputing.com/skhara/build_registry/snowml_repo/116da812e88f2751324c6a16eb00de3726ed06a3:latest\"\n",
    "            },\n",
    "    permanent = True\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b3c4148d-7a15-46be-aa49-2915999b06d9",
   "metadata": {},
   "source": [
    "# 2.0 Data Processing\n",
    "\n",
    "We will load a JSON file to a Snowflake Table. For prediction purposes, we have two options - use Snowpark DataFrame or use Local Pandas DataFrame.\n",
    "\n",
    "Snowpark dataframes allow us to work at scale and enable us to keep the data on server side without ever bringing data locally."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672a5f2b-872d-401f-b665-f12dbf67f333",
   "metadata": {},
   "source": [
    "## 2.1 Load Data\n",
    "\n",
    "In this lab, you do not have the required data in Snowflake so we will load a local .csv file to Snowflake using snowflake-snowpark library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130484b8-0d6f-4ca7-ab4a-b3cacfdd9f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_dataset = pd.read_json(\"data/frosty_transcripts_all.jsonl\", lines=True).convert_dtypes()\n",
    "json_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825f7214-f405-4748-bf24-51e4910e777a",
   "metadata": {},
   "outputs": [],
   "source": [
    "TABLE_NAME = \"BUILD_HOL_DATA\"\n",
    "session.write_pandas(json_dataset, table_name=TABLE_NAME, auto_create_table=True, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265cfa22-b448-483e-a6f1-9577217a92bd",
   "metadata": {},
   "source": [
    "## 2.2 Input: Prompt Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c11758-a3c9-44d2-976b-7619526359f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# I am going to bring 2 rows from the data to my local machine to create the prompt examples.\n",
    "sdf_input = session.table('BUILD_HOL_DATA')\n",
    "df_local = sdf_input.limit(2).to_pandas()\n",
    "df_local.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4a2e10-6854-4a88-aac9-a88f767a1b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_prefix = f'''[INST] <<SYS>>\n",
    "Your output will be parsed by a computer program as a JSON object. Please respond ONLY with valid json that conforms to this JSON schema:\n",
    "{{\n",
    "  \"name\": {{\n",
    "    \"type\": \"string\",\n",
    "    \"description\": \"The name of the person calling\"\n",
    "  }},\n",
    "  \"location\": {{\n",
    "    \"type\": \"string\",\n",
    "    \"description\": \"The name of the location where the person is calling from.\"\n",
    "  }},\n",
    "  \"toy_list\": {{\n",
    "    \"type\": \"array\",\n",
    "    \"description\": \"The list of toys requested by the person calling.\"\n",
    "  }},\n",
    "  \"required\": [\"name\", \"location\", \"toy_list\"]\n",
    "}}\n",
    "\n",
    "Example 1:\n",
    "Input: \"{df_local['transcript'].iloc[0]}\"\n",
    "Output: {{\"name\": {df_local['name'].iloc[0]}, \"location\": {df_local['location'].iloc[0]}, \"toy_list\": {df_local['toy_list'].iloc[0]}}}\n",
    "\n",
    "Example 2:\n",
    "Input: \"{df_local['transcript'].iloc[1]}\"\n",
    "Output: {{\"name\": {df_local['name'].iloc[1]}, \"location\": {df_local['location'].iloc[1]}, \"toy_list\": {df_local['toy_list'].iloc[1]}}}\n",
    "<</SYS>>\n",
    "\n",
    "Input:\n",
    "\n",
    "'''\n",
    "\n",
    "prompt_suffix = \" [/INST]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b67c44a4-def1-4f7e-a347-0993d46a39eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import snowflake.snowpark.functions as F\n",
    "\n",
    "input_df = sdf_input.with_column(\n",
    "    '\"inputs\"',\n",
    "    F.concat_ws(\n",
    "        F.lit(\" \"), F.lit(prompt_prefix), F.col('\"transcript\"'), F.lit(prompt_suffix)\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0f98f90d-8904-4f84-b96f-d12ea0ce8ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df.write.mode(\"overwrite\").save_as_table(\"DATA_WITH_PROMPT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34bb6b5-10b1-4987-b0ad-36fa3fb1e161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_local['inputs'] = df_local['transcript'].apply(add_prompt)\n",
    "# print(df_local['inputs'].iloc[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf85c1c9-1300-46db-982f-071fc3f7900c",
   "metadata": {},
   "source": [
    "# 3.0 LLM Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ddb75b-0726-4625-b82e-31a3eb0dc891",
   "metadata": {},
   "source": [
    "## 3.1 Get Deployed Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ca1c6631-8dd5-4e1f-841e-4af9cd1feb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "REGISTRY_NAME = 'SKHARA'\n",
    "SCHEMA_NAME = 'BUILD_REGISTRY'\n",
    "MODEL_NAME = 'LLAMA2_MODEL_7b_CHAT'\n",
    "MODEL_VERSION = '7'\n",
    "DEPLOYMENT_NAME = 'llama_predict'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7fb7f9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "registry = model_registry.ModelRegistry(session= session,\n",
    "                                        database_name= REGISTRY_NAME,\n",
    "                                        schema_name= SCHEMA_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c94b5689-c8d3-4950-ae1a-6f21a43f3ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ModelRegistry.list_models() is in private preview since 0.2.0. Do not use it in production. \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CREATION_CONTEXT</th>\n",
       "      <th>CREATION_ENVIRONMENT_SPEC</th>\n",
       "      <th>CREATION_ROLE</th>\n",
       "      <th>CREATION_TIME</th>\n",
       "      <th>ID</th>\n",
       "      <th>INPUT_SPEC</th>\n",
       "      <th>NAME</th>\n",
       "      <th>OUTPUT_SPEC</th>\n",
       "      <th>RUNTIME_ENVIRONMENT_SPEC</th>\n",
       "      <th>TYPE</th>\n",
       "      <th>URI</th>\n",
       "      <th>VERSION</th>\n",
       "      <th>ARTIFACT_IDS</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "      <th>METRICS</th>\n",
       "      <th>TAGS</th>\n",
       "      <th>REGISTRATION_TIMESTAMP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>{\\n  \"python\": \"3.9.17\"\\n}</td>\n",
       "      <td>\"SPC_USER_ROLE\"</td>\n",
       "      <td>2023-10-18 11:19:26.257000-07:00</td>\n",
       "      <td>d90f1c246de211eeae210a72b796458c</td>\n",
       "      <td>None</td>\n",
       "      <td>LLAMA2_MODEL_7b_CHAT</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>huggingface_pipeline</td>\n",
       "      <td>sfc://SKHARA.BUILD_REGISTRY.SNOWML_MODEL_D90F1...</td>\n",
       "      <td>3</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-10-18 11:19:27.494000-07:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>{\\n  \"python\": \"3.9.17\"\\n}</td>\n",
       "      <td>\"SPC_USER_ROLE\"</td>\n",
       "      <td>2023-10-18 11:20:31.620000-07:00</td>\n",
       "      <td>0168781e6de311eeae210a72b796458c</td>\n",
       "      <td>None</td>\n",
       "      <td>LLAMA2_MODEL_7b_CHAT</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>huggingface_pipeline</td>\n",
       "      <td>sfc://SKHARA.BUILD_REGISTRY.SNOWML_MODEL_01687...</td>\n",
       "      <td>4</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-10-18 11:20:33.306000-07:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>{\\n  \"python\": \"3.9.17\"\\n}</td>\n",
       "      <td>\"SPC_USER_ROLE\"</td>\n",
       "      <td>2023-10-23 08:23:21.668000-07:00</td>\n",
       "      <td>1454b4e671b811eeb25b0a72b796458c</td>\n",
       "      <td>None</td>\n",
       "      <td>LLAMA2_MODEL_7b_CHAT</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>huggingface_pipeline</td>\n",
       "      <td>sfc://SKHARA.BUILD_REGISTRY.SNOWML_MODEL_1454B...</td>\n",
       "      <td>5</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-10-23 08:23:22.988000-07:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>{\\n  \"python\": \"3.9.17\"\\n}</td>\n",
       "      <td>\"SPC_USER_ROLE\"</td>\n",
       "      <td>2023-10-23 11:06:19.746000-07:00</td>\n",
       "      <td>d870c6ec71ce11ee9c1d0a72b796458c</td>\n",
       "      <td>None</td>\n",
       "      <td>LLAMA2_MODEL_7b_CHAT</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>huggingface_pipeline</td>\n",
       "      <td>sfc://SKHARA.BUILD_REGISTRY.SNOWML_MODEL_D870C...</td>\n",
       "      <td>6</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-10-23 11:06:21.405000-07:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>{\\n  \"python\": \"3.9.17\"\\n}</td>\n",
       "      <td>\"SPC_USER_ROLE\"</td>\n",
       "      <td>2023-10-23 12:33:41.971000-07:00</td>\n",
       "      <td>0dfc6cb071db11ee9c1d0a72b796458c</td>\n",
       "      <td>None</td>\n",
       "      <td>LLAMA2_MODEL_7b_CHAT</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>huggingface_pipeline</td>\n",
       "      <td>sfc://SKHARA.BUILD_REGISTRY.SNOWML_MODEL_0DFC6...</td>\n",
       "      <td>7</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-10-23 12:33:43.307000-07:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  CREATION_CONTEXT   CREATION_ENVIRONMENT_SPEC    CREATION_ROLE  \\\n",
       "0             None  {\\n  \"python\": \"3.9.17\"\\n}  \"SPC_USER_ROLE\"   \n",
       "1             None  {\\n  \"python\": \"3.9.17\"\\n}  \"SPC_USER_ROLE\"   \n",
       "2             None  {\\n  \"python\": \"3.9.17\"\\n}  \"SPC_USER_ROLE\"   \n",
       "3             None  {\\n  \"python\": \"3.9.17\"\\n}  \"SPC_USER_ROLE\"   \n",
       "4             None  {\\n  \"python\": \"3.9.17\"\\n}  \"SPC_USER_ROLE\"   \n",
       "\n",
       "                     CREATION_TIME                                ID  \\\n",
       "0 2023-10-18 11:19:26.257000-07:00  d90f1c246de211eeae210a72b796458c   \n",
       "1 2023-10-18 11:20:31.620000-07:00  0168781e6de311eeae210a72b796458c   \n",
       "2 2023-10-23 08:23:21.668000-07:00  1454b4e671b811eeb25b0a72b796458c   \n",
       "3 2023-10-23 11:06:19.746000-07:00  d870c6ec71ce11ee9c1d0a72b796458c   \n",
       "4 2023-10-23 12:33:41.971000-07:00  0dfc6cb071db11ee9c1d0a72b796458c   \n",
       "\n",
       "  INPUT_SPEC                  NAME OUTPUT_SPEC RUNTIME_ENVIRONMENT_SPEC  \\\n",
       "0       None  LLAMA2_MODEL_7b_CHAT        None                     None   \n",
       "1       None  LLAMA2_MODEL_7b_CHAT        None                     None   \n",
       "2       None  LLAMA2_MODEL_7b_CHAT        None                     None   \n",
       "3       None  LLAMA2_MODEL_7b_CHAT        None                     None   \n",
       "4       None  LLAMA2_MODEL_7b_CHAT        None                     None   \n",
       "\n",
       "                   TYPE                                                URI  \\\n",
       "0  huggingface_pipeline  sfc://SKHARA.BUILD_REGISTRY.SNOWML_MODEL_D90F1...   \n",
       "1  huggingface_pipeline  sfc://SKHARA.BUILD_REGISTRY.SNOWML_MODEL_01687...   \n",
       "2  huggingface_pipeline  sfc://SKHARA.BUILD_REGISTRY.SNOWML_MODEL_1454B...   \n",
       "3  huggingface_pipeline  sfc://SKHARA.BUILD_REGISTRY.SNOWML_MODEL_D870C...   \n",
       "4  huggingface_pipeline  sfc://SKHARA.BUILD_REGISTRY.SNOWML_MODEL_0DFC6...   \n",
       "\n",
       "  VERSION ARTIFACT_IDS DESCRIPTION METRICS  TAGS  \\\n",
       "0       3           []        None    None  None   \n",
       "1       4           []        None    None  None   \n",
       "2       5           []        None    None  None   \n",
       "3       6           []        None    None  None   \n",
       "4       7           []        None    None  None   \n",
       "\n",
       "            REGISTRATION_TIMESTAMP  \n",
       "0 2023-10-18 11:19:27.494000-07:00  \n",
       "1 2023-10-18 11:20:33.306000-07:00  \n",
       "2 2023-10-23 08:23:22.988000-07:00  \n",
       "3 2023-10-23 11:06:21.405000-07:00  \n",
       "4 2023-10-23 12:33:43.307000-07:00  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_list = registry.list_models()\n",
    "model_list.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9003c94f-6954-4449-bdbf-697e25add6fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ModelRegistry.list_deployments() is in private preview since 1.0.1. Do not use it in production. \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MODEL_NAME</th>\n",
       "      <th>MODEL_VERSION</th>\n",
       "      <th>DEPLOYMENT_NAME</th>\n",
       "      <th>CREATION_TIME</th>\n",
       "      <th>TARGET_METHOD</th>\n",
       "      <th>TARGET_PLATFORM</th>\n",
       "      <th>SIGNATURE</th>\n",
       "      <th>OPTIONS</th>\n",
       "      <th>STAGE_PATH</th>\n",
       "      <th>ROLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LLAMA2_MODEL_7b_CHAT</td>\n",
       "      <td>7</td>\n",
       "      <td>llama_predict</td>\n",
       "      <td>2023-10-23 12:35:19.101000-07:00</td>\n",
       "      <td>__call__</td>\n",
       "      <td>SNOWPARK_CONTAINER_SERVICES</td>\n",
       "      <td>{\\n  \"inputs\": [\\n    {\\n      \"name\": \"inputs...</td>\n",
       "      <td>{\\n  \"compute_pool\": \"SKHARA_COMPUTE_GPU3\",\\n ...</td>\n",
       "      <td>@SKHARA.BUILD_REGISTRY._SYSTEM_REGISTRY_DEPLOY...</td>\n",
       "      <td>\"SPC_USER_ROLE\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             MODEL_NAME MODEL_VERSION DEPLOYMENT_NAME  \\\n",
       "0  LLAMA2_MODEL_7b_CHAT             7   llama_predict   \n",
       "\n",
       "                     CREATION_TIME TARGET_METHOD              TARGET_PLATFORM  \\\n",
       "0 2023-10-23 12:35:19.101000-07:00      __call__  SNOWPARK_CONTAINER_SERVICES   \n",
       "\n",
       "                                           SIGNATURE  \\\n",
       "0  {\\n  \"inputs\": [\\n    {\\n      \"name\": \"inputs...   \n",
       "\n",
       "                                             OPTIONS  \\\n",
       "0  {\\n  \"compute_pool\": \"SKHARA_COMPUTE_GPU3\",\\n ...   \n",
       "\n",
       "                                          STAGE_PATH             ROLE  \n",
       "0  @SKHARA.BUILD_REGISTRY._SYSTEM_REGISTRY_DEPLOY...  \"SPC_USER_ROLE\"  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_list = registry.list_deployments(model_name = MODEL_NAME, model_version = MODEL_VERSION)\n",
    "model_list.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "65793fa7-e3d0-4f48-b472-666a36ebc802",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_registry.ModelReference(registry=registry, model_name=MODEL_NAME, model_version=MODEL_VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0419ae9d-dcd4-4137-8948-611d7315e351",
   "metadata": {},
   "source": [
    "## 3.2 Inference using LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "19840f05-c7db-4f57-b6dd-c581f5d1bc45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "      <th>name</th>\n",
       "      <th>location</th>\n",
       "      <th>toy_list</th>\n",
       "      <th>inputs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>frosty: Hi there! This is Frosty. How can I he...</td>\n",
       "      <td>Alex</td>\n",
       "      <td>Houston</td>\n",
       "      <td>[\\n  \"Barbie Science Lab Playset\",\\n  \"Pokémon...</td>\n",
       "      <td>[INST] &lt;&lt;SYS&gt;&gt;\\nYour output will be parsed by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>frosty: Hello, happy holiday! How can I help y...</td>\n",
       "      <td>Amber</td>\n",
       "      <td>London</td>\n",
       "      <td>[\\n  \"Dog-E\",\\n  \"2023 Holiday Fox 12-Inch Plu...</td>\n",
       "      <td>[INST] &lt;&lt;SYS&gt;&gt;\\nYour output will be parsed by ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          transcript   name location  \\\n",
       "0  frosty: Hi there! This is Frosty. How can I he...   Alex  Houston   \n",
       "1  frosty: Hello, happy holiday! How can I help y...  Amber   London   \n",
       "\n",
       "                                            toy_list  \\\n",
       "0  [\\n  \"Barbie Science Lab Playset\",\\n  \"Pokémon...   \n",
       "1  [\\n  \"Dog-E\",\\n  \"2023 Holiday Fox 12-Inch Plu...   \n",
       "\n",
       "                                              inputs  \n",
       "0  [INST] <<SYS>>\\nYour output will be parsed by ...  \n",
       "1  [INST] <<SYS>>\\nYour output will be parsed by ...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf_data_prompt = session.table('DATA_WITH_PROMPT')\n",
    "sdf_data_prompt.limit(2).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b12d55c0-565c-4988-94d1-49f8f88bf32a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(name='FAZEEM_COMPUTE_POOL', state='ACTIVE', min_nodes=1, max_nodes=1, instance_family='STANDARD_1', num_services=2, num_jobs=0, auto_suspend_secs=3600, auto_resume='true', active_nodes=1, idle_nodes=0, created_on=datetime.datetime(2023, 7, 13, 11, 13, 46, 46000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), resumed_on=datetime.datetime(2023, 10, 2, 14, 48, 7, 832000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), updated_on=datetime.datetime(2023, 10, 31, 11, 50, 30, 70000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), owner='SPC_USER_ROLE', comment=None),\n",
       " Row(name='FSDEMO', state='ACTIVE', min_nodes=1, max_nodes=2, instance_family='STANDARD_1', num_services=2, num_jobs=0, auto_suspend_secs=0, auto_resume='true', active_nodes=1, idle_nodes=0, created_on=datetime.datetime(2023, 5, 17, 14, 17, 22, 289000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), resumed_on=datetime.datetime(2023, 10, 5, 6, 40, 41, 49000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), updated_on=datetime.datetime(2023, 10, 31, 11, 49, 23, 390000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), owner='SPC_ADMIN_ROLE', comment=None),\n",
       " Row(name='GPU_3', state='IDLE', min_nodes=1, max_nodes=1, instance_family='GPU_3', num_services=3, num_jobs=0, auto_suspend_secs=0, auto_resume='true', active_nodes=0, idle_nodes=1, created_on=datetime.datetime(2023, 8, 31, 15, 29, 50, 713000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), resumed_on=datetime.datetime(2023, 8, 31, 15, 29, 50, 712000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), updated_on=datetime.datetime(2023, 10, 31, 11, 58, 0, 805000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), owner='SPC_USER_ROLE', comment=None),\n",
       " Row(name='GR_COMPUTE_POOL', state='SUSPENDED', min_nodes=1, max_nodes=1, instance_family='STANDARD_1', num_services=0, num_jobs=0, auto_suspend_secs=0, auto_resume='true', active_nodes=0, idle_nodes=0, created_on=datetime.datetime(2023, 8, 9, 8, 54, 1, 608000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), resumed_on=datetime.datetime(2023, 8, 21, 6, 12, 35, 796000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), updated_on=datetime.datetime(2023, 10, 31, 11, 44, 30, 101000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), owner='SPC_USER_ROLE', comment=None),\n",
       " Row(name='HARSH_LLAMA_GPU_POOL', state='ACTIVE', min_nodes=1, max_nodes=1, instance_family='GPU_5', num_services=1, num_jobs=0, auto_suspend_secs=0, auto_resume='true', active_nodes=1, idle_nodes=0, created_on=datetime.datetime(2023, 7, 31, 6, 23, 23, 574000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), resumed_on=datetime.datetime(2023, 10, 17, 14, 45, 35, 191000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), updated_on=datetime.datetime(2023, 10, 31, 11, 48, 30, 189000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), owner='SPC_USER_ROLE', comment=None),\n",
       " Row(name='JOE_DEMO_LLAMA_GPU_POOL', state='ACTIVE', min_nodes=1, max_nodes=1, instance_family='GPU_5', num_services=1, num_jobs=0, auto_suspend_secs=0, auto_resume='true', active_nodes=1, idle_nodes=0, created_on=datetime.datetime(2023, 10, 10, 14, 5, 21, 199000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), resumed_on=datetime.datetime(2023, 10, 10, 14, 5, 21, 198000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), updated_on=datetime.datetime(2023, 10, 31, 11, 15, 6, 142000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), owner='SPC_USER_ROLE', comment=None),\n",
       " Row(name='JUPYTERLAB_STANDARD_2_CPU', state='ACTIVE', min_nodes=1, max_nodes=1, instance_family='STANDARD_2', num_services=1, num_jobs=0, auto_suspend_secs=0, auto_resume='true', active_nodes=1, idle_nodes=0, created_on=datetime.datetime(2023, 7, 6, 8, 19, 35, 305000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), resumed_on=datetime.datetime(2023, 7, 6, 8, 19, 35, 319000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), updated_on=datetime.datetime(2023, 10, 31, 11, 52, 30, 71000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), owner='SPC_USER_ROLE', comment=None),\n",
       " Row(name='JUPYTER_CP', state='ACTIVE', min_nodes=1, max_nodes=1, instance_family='STANDARD_2', num_services=1, num_jobs=0, auto_suspend_secs=3600, auto_resume='true', active_nodes=1, idle_nodes=0, created_on=datetime.datetime(2023, 10, 17, 7, 5, 1, 338000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), resumed_on=datetime.datetime(2023, 10, 17, 7, 5, 1, 328000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), updated_on=datetime.datetime(2023, 10, 31, 11, 42, 30, 42000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), owner='SPC_USER_ROLE', comment=None),\n",
       " Row(name='MGORKOW_GPU_POOL', state='SUSPENDED', min_nodes=1, max_nodes=1, instance_family='GPU_3', num_services=1, num_jobs=2, auto_suspend_secs=3600, auto_resume='true', active_nodes=0, idle_nodes=0, created_on=datetime.datetime(2023, 10, 23, 7, 22, 39, 184000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), resumed_on=datetime.datetime(2023, 10, 24, 15, 1, 18, 759000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), updated_on=datetime.datetime(2023, 10, 31, 11, 48, 23, 752000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), owner='SPC_USER_ROLE', comment=None),\n",
       " Row(name='NODE_BACKEND_COMPUTE_POOL', state='ACTIVE', min_nodes=1, max_nodes=1, instance_family='STANDARD_1', num_services=1, num_jobs=0, auto_suspend_secs=0, auto_resume='true', active_nodes=1, idle_nodes=0, created_on=datetime.datetime(2023, 8, 16, 5, 33, 18, 346000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), resumed_on=datetime.datetime(2023, 8, 16, 5, 33, 18, 363000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), updated_on=datetime.datetime(2023, 10, 31, 11, 58, 30, 131000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), owner='SPC_USER_ROLE', comment=None),\n",
       " Row(name='OKHTAY_COMPUTE_POOL', state='SUSPENDED', min_nodes=1, max_nodes=1, instance_family='GPU_3', num_services=0, num_jobs=0, auto_suspend_secs=0, auto_resume='true', active_nodes=0, idle_nodes=0, created_on=datetime.datetime(2023, 9, 10, 17, 42, 6, 933000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), resumed_on=datetime.datetime(2023, 9, 10, 17, 42, 6, 931000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), updated_on=datetime.datetime(2023, 10, 31, 11, 54, 30, 91000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), owner='SPC_USER_ROLE', comment=None),\n",
       " Row(name='PLAKHANPAL_GPU_5', state='SUSPENDED', min_nodes=1, max_nodes=1, instance_family='GPU_5', num_services=1, num_jobs=0, auto_suspend_secs=300, auto_resume='true', active_nodes=0, idle_nodes=0, created_on=datetime.datetime(2023, 10, 11, 11, 15, 23, 127000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), resumed_on=datetime.datetime(2023, 10, 11, 11, 15, 23, 119000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), updated_on=datetime.datetime(2023, 10, 31, 11, 54, 30, 108000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), owner='SPC_USER_ROLE', comment=None),\n",
       " Row(name='PL_CPU_STANDARD_1', state='SUSPENDED', min_nodes=1, max_nodes=1, instance_family='STANDARD_1', num_services=0, num_jobs=0, auto_suspend_secs=0, auto_resume='true', active_nodes=0, idle_nodes=0, created_on=datetime.datetime(2023, 7, 17, 13, 40, 5, 199000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), resumed_on=datetime.datetime(2023, 7, 17, 13, 40, 5, 190000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), updated_on=datetime.datetime(2023, 10, 31, 11, 48, 23, 344000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), owner='SPC_USER_ROLE', comment=None),\n",
       " Row(name='PL_CPU_STANDARD_2', state='SUSPENDED', min_nodes=1, max_nodes=4, instance_family='STANDARD_2', num_services=0, num_jobs=0, auto_suspend_secs=0, auto_resume='true', active_nodes=0, idle_nodes=0, created_on=datetime.datetime(2023, 7, 5, 12, 32, 8, 603000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), resumed_on=datetime.datetime(2023, 7, 5, 12, 32, 8, 612000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), updated_on=datetime.datetime(2023, 10, 31, 11, 57, 0, 714000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), owner='SPC_USER_ROLE', comment=None),\n",
       " Row(name='PL_CPU_STANDARD_5', state='SUSPENDED', min_nodes=1, max_nodes=1, instance_family='STANDARD_5', num_services=0, num_jobs=0, auto_suspend_secs=0, auto_resume='true', active_nodes=0, idle_nodes=0, created_on=datetime.datetime(2023, 7, 6, 18, 41, 36, 427000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), resumed_on=datetime.datetime(2023, 7, 6, 18, 41, 36, 419000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), updated_on=datetime.datetime(2023, 10, 31, 11, 51, 0, 736000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), owner='SPC_USER_ROLE', comment=None),\n",
       " Row(name='PL_DOC_SEARCH_GPU_3', state='ACTIVE', min_nodes=1, max_nodes=1, instance_family='GPU_3', num_services=2, num_jobs=0, auto_suspend_secs=0, auto_resume='true', active_nodes=1, idle_nodes=0, created_on=datetime.datetime(2023, 10, 10, 19, 55, 22, 32000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), resumed_on=datetime.datetime(2023, 10, 10, 19, 55, 22, 37000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), updated_on=datetime.datetime(2023, 10, 31, 11, 55, 23, 620000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), owner='SPC_USER_ROLE', comment=None),\n",
       " Row(name='PL_DOC_SEARCH_GPU_5', state='ACTIVE', min_nodes=1, max_nodes=1, instance_family='GPU_5', num_services=1, num_jobs=0, auto_suspend_secs=0, auto_resume='true', active_nodes=1, idle_nodes=0, created_on=datetime.datetime(2023, 10, 10, 19, 56, 39, 420000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), resumed_on=datetime.datetime(2023, 10, 10, 19, 56, 39, 420000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), updated_on=datetime.datetime(2023, 10, 31, 11, 51, 23, 337000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), owner='SPC_USER_ROLE', comment=None),\n",
       " Row(name='PL_EMBEDDINGS_GPU_3', state='ACTIVE', min_nodes=1, max_nodes=1, instance_family='GPU_3', num_services=1, num_jobs=0, auto_suspend_secs=0, auto_resume='true', active_nodes=1, idle_nodes=0, created_on=datetime.datetime(2023, 10, 11, 0, 45, 36, 497000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), resumed_on=datetime.datetime(2023, 10, 11, 0, 45, 36, 497000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), updated_on=datetime.datetime(2023, 10, 31, 11, 58, 0, 682000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), owner='SPC_USER_ROLE', comment=None),\n",
       " Row(name='PL_STD_2', state='SUSPENDED', min_nodes=1, max_nodes=1, instance_family='STANDARD_2', num_services=0, num_jobs=0, auto_suspend_secs=0, auto_resume='true', active_nodes=0, idle_nodes=0, created_on=datetime.datetime(2023, 9, 25, 14, 0, 14, 961000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), resumed_on=datetime.datetime(2023, 9, 25, 14, 0, 14, 968000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), updated_on=datetime.datetime(2023, 10, 31, 11, 44, 30, 153000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), owner='SPC_USER_ROLE', comment=None),\n",
       " Row(name='SDAS_GPU7_COMPUTE_POOL', state='SUSPENDED', min_nodes=1, max_nodes=1, instance_family='GPU_7', num_services=1, num_jobs=0, auto_suspend_secs=0, auto_resume='true', active_nodes=0, idle_nodes=0, created_on=datetime.datetime(2023, 8, 25, 8, 58, 37, 759000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), resumed_on=datetime.datetime(2023, 9, 8, 14, 24, 37, 822000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), updated_on=datetime.datetime(2023, 10, 31, 11, 56, 0, 722000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), owner='SPC_USER_ROLE', comment=None),\n",
       " Row(name='SDAS_GPU_COMPUTE_POOL', state='SUSPENDED', min_nodes=1, max_nodes=1, instance_family='GPU_3', num_services=2, num_jobs=0, auto_suspend_secs=0, auto_resume='true', active_nodes=0, idle_nodes=0, created_on=datetime.datetime(2023, 8, 24, 12, 7, 56, 150000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), resumed_on=datetime.datetime(2023, 8, 31, 11, 39, 38, 405000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), updated_on=datetime.datetime(2023, 10, 31, 11, 46, 23, 374000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), owner='SPC_USER_ROLE', comment=None),\n",
       " Row(name='SD_GPU_31', state='ACTIVE', min_nodes=1, max_nodes=1, instance_family='GPU_3', num_services=3, num_jobs=0, auto_suspend_secs=0, auto_resume='true', active_nodes=1, idle_nodes=0, created_on=datetime.datetime(2023, 10, 2, 11, 59, 12, 682000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), resumed_on=datetime.datetime(2023, 10, 2, 11, 59, 12, 691000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), updated_on=datetime.datetime(2023, 10, 31, 11, 49, 30, 118000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), owner='SPC_USER_ROLE', comment=None),\n",
       " Row(name='SD_GPU_32', state='IDLE', min_nodes=3, max_nodes=3, instance_family='GPU_3', num_services=0, num_jobs=0, auto_suspend_secs=0, auto_resume='true', active_nodes=0, idle_nodes=3, created_on=datetime.datetime(2023, 10, 3, 16, 10, 50, 269000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), resumed_on=datetime.datetime(2023, 10, 3, 16, 10, 50, 278000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), updated_on=datetime.datetime(2023, 10, 31, 11, 52, 23, 340000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), owner='SPC_USER_ROLE', comment=None),\n",
       " Row(name='SD_GPU_7', state='ACTIVE', min_nodes=1, max_nodes=1, instance_family='GPU_7', num_services=1, num_jobs=0, auto_suspend_secs=0, auto_resume='true', active_nodes=1, idle_nodes=0, created_on=datetime.datetime(2023, 10, 15, 0, 28, 19, 954000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), resumed_on=datetime.datetime(2023, 10, 15, 0, 28, 19, 959000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), updated_on=datetime.datetime(2023, 10, 31, 11, 58, 36, 411000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), owner='SPC_USER_ROLE', comment=None),\n",
       " Row(name='SF_COMPUTE_POOL', state='IDLE', min_nodes=1, max_nodes=1, instance_family='STANDARD_1', num_services=0, num_jobs=0, auto_suspend_secs=0, auto_resume='true', active_nodes=0, idle_nodes=1, created_on=datetime.datetime(2023, 10, 6, 12, 34, 24, 79000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), resumed_on=datetime.datetime(2023, 10, 6, 12, 34, 24, 91000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), updated_on=datetime.datetime(2023, 10, 31, 11, 40, 23, 638000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), owner='SPC_USER_ROLE', comment=None),\n",
       " Row(name='SKHARA_COMPUTE_GPU3', state='ACTIVE', min_nodes=1, max_nodes=1, instance_family='GPU_3', num_services=1, num_jobs=0, auto_suspend_secs=0, auto_resume='true', active_nodes=1, idle_nodes=0, created_on=datetime.datetime(2023, 10, 13, 8, 41, 14, 362000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), resumed_on=datetime.datetime(2023, 10, 31, 11, 43, 41, 142000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), updated_on=datetime.datetime(2023, 10, 31, 11, 52, 3, 903000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), owner='SPC_USER_ROLE', comment=None),\n",
       " Row(name='SKHARA_COMPUTE_GPU7', state='SUSPENDED', min_nodes=1, max_nodes=1, instance_family='GPU_7', num_services=0, num_jobs=0, auto_suspend_secs=0, auto_resume='true', active_nodes=0, idle_nodes=0, created_on=datetime.datetime(2023, 10, 16, 13, 42, 37, 390000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), resumed_on=datetime.datetime(2023, 10, 26, 9, 33, 36, 485000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), updated_on=datetime.datetime(2023, 10, 31, 11, 31, 23, 766000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), owner='SPC_USER_ROLE', comment=None),\n",
       " Row(name='SUMMIT_GPU_3', state='SUSPENDED', min_nodes=1, max_nodes=1, instance_family='GPU_3', num_services=0, num_jobs=0, auto_suspend_secs=0, auto_resume='true', active_nodes=0, idle_nodes=0, created_on=datetime.datetime(2023, 9, 26, 8, 36, 14, 118000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), resumed_on=datetime.datetime(2023, 9, 26, 8, 36, 14, 128000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), updated_on=datetime.datetime(2023, 10, 31, 11, 51, 30, 155000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), owner='SPC_USER_ROLE', comment=None),\n",
       " Row(name='TESTPOOL_FCTO_STANDARD_2_CPU', state='SUSPENDED', min_nodes=1, max_nodes=1, instance_family='STANDARD_2', num_services=4, num_jobs=0, auto_suspend_secs=0, auto_resume='true', active_nodes=0, idle_nodes=0, created_on=datetime.datetime(2023, 5, 9, 7, 43, 27, 413000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), resumed_on=datetime.datetime(2023, 6, 9, 19, 56, 15, 759000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), updated_on=datetime.datetime(2023, 10, 31, 11, 39, 23, 603000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), owner='SPC_ADMIN_ROLE', comment=None),\n",
       " Row(name='TUTORIAL_COMPUTE_POOL', state='ACTIVE', min_nodes=1, max_nodes=1, instance_family='STANDARD_1', num_services=9, num_jobs=0, auto_suspend_secs=0, auto_resume='true', active_nodes=1, idle_nodes=0, created_on=datetime.datetime(2023, 6, 20, 7, 16, 42, 249000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), resumed_on=datetime.datetime(2023, 10, 16, 15, 9, 21, 999000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), updated_on=datetime.datetime(2023, 10, 31, 11, 52, 23, 416000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), owner='SPC_USER_ROLE', comment=None),\n",
       " Row(name='VB_COMPUTE_POOL', state='IDLE', min_nodes=1, max_nodes=1, instance_family='STANDARD_1', num_services=1, num_jobs=0, auto_suspend_secs=0, auto_resume='true', active_nodes=0, idle_nodes=1, created_on=datetime.datetime(2023, 8, 12, 5, 7, 3, 922000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), resumed_on=datetime.datetime(2023, 8, 12, 5, 7, 3, 930000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), updated_on=datetime.datetime(2023, 10, 31, 11, 58, 30, 75000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), owner='SPC_USER_ROLE', comment=None),\n",
       " Row(name='WEAVIATE_CP', state='ACTIVE', min_nodes=1, max_nodes=1, instance_family='STANDARD_2', num_services=1, num_jobs=0, auto_suspend_secs=3600, auto_resume='true', active_nodes=1, idle_nodes=0, created_on=datetime.datetime(2023, 10, 17, 7, 4, 59, 562000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), resumed_on=datetime.datetime(2023, 10, 19, 7, 55, 38, 111000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), updated_on=datetime.datetime(2023, 10, 31, 11, 54, 0, 708000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>), owner='SPC_USER_ROLE', comment=None)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.sql('SHOW COMPUTE POOLS').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d97059d4-bd1c-4eb7-83b9-c2221fabfb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model.predict(\n",
    "    deployment_name= DEPLOYMENT_NAME,\n",
    "    data= sdf_data_prompt\n",
    ")\n",
    "\n",
    "df_local = res.limit(5).to_pandas() #bring 5 rows locally"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a5d0c1-c080-4f65-84e1-51f6e1cd1c78",
   "metadata": {},
   "source": [
    "## 3.3 Output Processing\n",
    "Ensure that processing code conforms to the JSON Structure provided during Prompt Engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6ffb8d94-2f4e-40ef-b18e-cc53ad388f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def format_output(output_string):\n",
    "    try:\n",
    "        # Step 1: Parse the outer string to convert it to a list of dictionaries\n",
    "        outer_list = json.loads(output_string)\n",
    "        \n",
    "        # Step 2: Extract the 'generated_text' value from the first dictionary in the list\n",
    "        generated_text_str = outer_list[0]['generated_text']\n",
    "        \n",
    "        # Step 3: Locate the JSON object within the 'generated_text' value\n",
    "        start_pos = generated_text_str.find('{')\n",
    "        end_pos = generated_text_str.rfind('}')\n",
    "        if start_pos == -1 or end_pos == -1:\n",
    "            raise ValueError(\"No JSON object found in generated_text\")\n",
    "        json_str = generated_text_str[start_pos:end_pos + 1]\n",
    "        \n",
    "        # Step 4: Parse the JSON object to convert it to a dictionary\n",
    "        json_obj = json.loads(json_str)\n",
    "        \n",
    "        return json_obj\n",
    "    except:\n",
    "        return 'Could not parse output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a4fe9654-f53b-4864-9c65-c6477f3f2d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " **** Transcript # 0 ****\n",
      "frosty: Hi there! This is Frosty. How can I help you today?\n",
      "caller: Hi Frosty, I want to make my holiday wish.\n",
      "frosty: Of course! May I know your name, please?\n",
      "caller: I'm Alex.\n",
      "frosty: Hi Alex! Where are you calling from?\n",
      "caller: From Houston.\n",
      "frosty: Wonderful! Now, what's your holiday wish?\n",
      "caller: I want the barbie science doll set and pokemon plushie.\n",
      "frosty: Awesome choices, Alex! Your list has been added. Thanks for calling and have a jolly Holiday!\n",
      "\n",
      "\n",
      "{'name': 'Alex', 'location': 'Houston', 'toy_list': ['Barbie Science Lab Playset', 'Pokémon 8-Inch Plush First Partner Three-Pack']}\n",
      "\n",
      "\n",
      " **** Transcript # 1 ****\n",
      "frosty: Hello, happy holiday! How can I help you today?\n",
      "caller: I'm Amber. I want to give my wish list.\n",
      "frosty: Of course, Amber! What's on your wish list?\n",
      "caller: robot dog and the fox plushie.\n",
      "frosty: Brilliant choices, Amber! And where are you calling from? \n",
      "caller: From London.\n",
      "frosty: Alright, Amber from London. Your list has been recorded. Have a fantastic holiday!\n",
      "\n",
      "\n",
      "{'name': 'Amber', 'location': 'London', 'toy_list': ['Dog-E', '2023 Holiday Fox 12-Inch Plush']}\n",
      "\n",
      "\n",
      " **** Transcript # 2 ****\n",
      "frosty: Hi! I'm Frosty, how can I assist you today?\n",
      "caller: Hi, I'm Bella from San Francisco. \n",
      "frosty: Wonderful, Bella! How can I assist you today?\n",
      "caller: I wish for trasformers bumblebee and the new barbie dreamhouse.\n",
      "frosty: Those are fantastic wishes, Bella! I've added these to your list. Enjoy your holidays!\n",
      "\n",
      "\n",
      "{'name': 'Bella', 'location': 'San Francisco', 'toy_list': ['Transformers Bumblebee', 'Barbie Dreamhouse']}\n",
      "\n",
      "\n",
      " **** Transcript # 3 ****\n",
      "frosty: Hello! This is Frosty. How can I help you?\n",
      "caller: Hi, I'm Luke. \n",
      "frosty: Hi Luke! Where are you calling from?\n",
      "caller: I'm calling from Melbourne.\n",
      "frosty: Great! What would you like to wish for, Luke?\n",
      "caller: I wish for magic microscope and spiderman playset.\n",
      "frosty: Good choices, Luke! Your wish list has been recorded. Happy Holidays!\n",
      "\n",
      "\n",
      "{'name': 'Luke', 'location': 'Melbourne', 'toy_list': ['Magic Microscope', 'Spiderman Playset']}\n",
      "\n",
      "\n",
      " **** Transcript # 4 ****\n",
      "frosty: Hi, happy holidays! How can I assist you?\n",
      "caller: Hi, I'm Owen from Toronto.\n",
      "frosty: Hello, Owen! What are your holiday wishes?\n",
      "caller: I wish for lola droid and mickey playset.\n",
      "frosty: Brilliant! Your wishes have been noted, Owen. Have a fantastic holiday!\n",
      "\n",
      "\n",
      "{'name': 'Owen', 'location': 'Toronto', 'toy_list': ['Lola Droid', 'Mickey Mouse Playset']}\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(df_local)):\n",
    "    print(f'\\n\\n **** Transcript # {i} ****')\n",
    "    print(df_local['transcript'].iloc[i])\n",
    "    print('\\n')\n",
    "    print(format_output(df_local['outputs'].iloc[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f363428-d07a-40cd-9235-a5dbfa88f056",
   "metadata": {},
   "source": [
    "# 4.0 Clean Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7f5b373d-da0f-4d48-aee7-e03950eec316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(status='Statement executed successfully.')]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.sql(\"ALTER COMPUTE POOL IF EXISTS SKHARA_COMPUTE_GPU3 STOP ALL\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a07b0c-4e6a-4f94-82e5-c9de5a5d169f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
