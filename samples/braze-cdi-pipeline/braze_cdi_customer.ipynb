{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "name": "intro",
    "collapsed": false,
    "resultHeight": 448
   },
   "source": "# Braze Cloud Data Ingestion - Snowflake Notebook QuickStart\n\nAuthor: Luke Ambrosetti\n\nVersion: 1.0\n\n### What is Braze Cloud Data Ingestion (CDI)?\n\n[Braze CDI](https://www.braze.com/docs/user_guide/data_and_analytics/cloud_ingestion) is a dedicated change data capture process to sync data updates from Snowflake into Braze. This notebook was designed specifically for a Snowflake Quickstar, which can be found [here](LINKHERE).\n\n### What this Notebook does\n1. Generates necessary schema, as well as a custom user, role, and virtual warehouse for Braze Cloud Data Ingestion\n2. Generates very simple sample customer data\n3. Gives example code with a Snowflake Stream for handling inserts, updates, and deletes from sample customer data\n4. Shows how inserts, updates, and deletes are handled within the new Braze schema for ingestion"
  },
  {
   "cell_type": "markdown",
   "id": "bb810b15-b4df-44d0-9a7e-de6f0f6e84c8",
   "metadata": {
    "name": "create_role_md",
    "collapsed": false,
    "resultHeight": 195
   },
   "source": "## Create the Braze User, Role, and Warehouse\n\nHere, we'll create the dedicated role and user. The user will be created as a service user as this user is not a human logging into Snowflake, but rather used as a part of the Braze platform to read data from Snowflake. This means that we will be explicitly be deactivating password authentication for login via the Snowflake UI.\n\nBraze will generate the necessary key-pair authentication during the actual Braze CDI installation steps in the Braze UI. In this step, we're just creating the user, role, and the virtual warehouse."
  },
  {
   "cell_type": "code",
   "id": "ee7d918c-99f0-4144-8752-2cd924241dc2",
   "metadata": {
    "language": "sql",
    "name": "create_role_sql",
    "collapsed": false,
    "resultHeight": 112
   },
   "outputs": [],
   "source": "use role accountadmin;\ncreate or replace role braze_cdi_role;\ncreate or replace user svc_braze_cdi type = service default_role = braze_cdi_role;\n\ngrant role braze_cdi_role to role accountadmin;\ngrant role braze_cdi_role to user svc_braze_cdi;\n\ncreate or replace warehouse braze_cdi_wh with warehouse_size='xsmall'; -- XS for this demo, but even in production - this warehouse shouldn't be larger than a M/L for large scale. Start with Small and then bump as needed to meet any sync time/SLA requirement\n\ngrant usage on warehouse braze_cdi_wh to role braze_cdi_role;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7aefacf0-6164-4ea0-a4b9-5e8eeaf72cff",
   "metadata": {
    "name": "create_schema_md",
    "collapsed": false,
    "resultHeight": 532
   },
   "source": "## Create the Braze Schema\n\nThis creates a dedicated Braze database + schema for use with CDI. It allows CDI to read updates in the necessary Braze format.\n\nIn this example notebook, we'll only be focused on **user attribute** updates and **deletes** by creating the users_attributes_sync table. That table will then have two views: the `users_attributes_sync_vw` and the `users_deletes_vw`.\n\nThe `users_attributes_sync_vw` view will have the following fields:\n- external_id - which is the [External ID](https://www.braze.com/docs/developer_guide/platform_integration_guides/web/analytics/setting_user_ids/#suggested-user-id-naming-convention) that you feed to Braze\n- payload - which is JSON-as-text\n- updated_at - the UTC timestamp of when the sync record was created in this table. This allows Braze to keep track of only ingesting net-new events\n\nThe `users_deletes_vw` view will have the following fields\n- external_id - which is the [External ID](https://www.braze.com/docs/developer_guide/platform_integration_guides/web/analytics/setting_user_ids/#suggested-user-id-naming-convention) that you feed to Braze\n- updated_at - the UTC timestamp of when the sync record was created in this table. This allows Braze to keep track of only ingesting net-new events\n\nThere is no payload for the deletes view.\n\nAlternatively, you can use the email_address or phone_number as your primary customer identifier; however, for most uses of this process, it's highly suggested that you keep a primary external_id / customer_id that is separate from that. Fields for email and phone can be found in the Braze [documentation](https://www.braze.com/docs/user_guide/data_and_analytics/cloud_ingestion/integrations/#step-1-set-up-tables-or-views)."
  },
  {
   "cell_type": "code",
   "id": "af03ff93-af9a-4ea6-a68f-881cd325c2a8",
   "metadata": {
    "language": "sql",
    "name": "create_schema_sql",
    "collapsed": false,
    "resultHeight": 112
   },
   "outputs": [],
   "source": "create or replace database braze_cloud_production;\ngrant ownership on database braze_cloud_production to role braze_cdi_role;\nuse role braze_cdi_role;\n\ncreate or replace schema braze_cloud_production.ingestion;\nuse schema braze_cloud_production.ingestion;\n\ncreate or replace table users_attributes_sync (\n    external_id varchar,\n    payload varchar,\n    updated_at timestamp_ntz not null default sysdate()\n);\n\ncreate or replace view users_attributes_sync_vw \nas\n    select *\n    from users_attributes_sync\n    where payload is not null\n;\n\ncreate or replace view users_deletes_vw\nas\n    select external_id, updated_at\n    from users_attributes_sync\n    where payload is null\n;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "94f79bb8-3826-41fd-8ffd-f73b44a62d6e",
   "metadata": {
    "name": "sample_data_md",
    "collapsed": false,
    "resultHeight": 169
   },
   "source": "## Generate simple sample data\n\nWe're not going to get too fancy with this sample data to make sure tracking the changes are as easy to understand as possible in the next sections. We'll just generate a few records of \"customer\" data with a few attributes on each customer.\n\nIn a real-world scenario, this \"customer\" table would be a table with all of your customers. "
  },
  {
   "cell_type": "code",
   "id": "9f4bc5f2-8ccd-4bcc-847e-f0bf4d8bc3d1",
   "metadata": {
    "language": "sql",
    "name": "sample_data_sql",
    "codeCollapsed": false,
    "collapsed": false,
    "resultHeight": 182
   },
   "outputs": [],
   "source": "create or replace schema braze_cloud_production.demo_data;\nuse schema braze_cloud_production.demo_data;\n\ncreate or replace table customer\n(\n    customer_id number(11,0), --this will be used for the external_id\n    first_name varchar,\n    last_name varchar,\n    title varchar,\n    state varchar,\n    employer varchar,\n    days_since_last_purchase number\n);\n\ninsert into customer select 1, 'jim', 'smith', 'developer', 'CA', 'Glooble', 320;\ninsert into customer select 2, 'luke', 'skywalker', 'jedi', 'TN', 'Rebels', 1;\ninsert into customer select 3, 'george p.', 'burdell', 'engineer', 'GA', 'CNN', 72;\n\nselect *\nfrom customer;\n",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c9076944-98d9-4a3a-8fa1-bf305b737651",
   "metadata": {
    "name": "streams_md",
    "collapsed": false,
    "resultHeight": 127
   },
   "source": "## Tracking changes with a Snowflake Stream\n\nA [Snowflake Stream](https://docs.snowflake.com/en/user-guide/streams-intro) is an easy way to track changes on a table in Snowflake. The below code simulates inserting a new customer, updates a customer, and deleting a customer."
  },
  {
   "cell_type": "code",
   "id": "9c3e8052-7f29-4804-aac2-a8a6b66780b2",
   "metadata": {
    "language": "sql",
    "name": "streams_sql",
    "collapsed": false,
    "resultHeight": 217
   },
   "outputs": [],
   "source": "create or replace stream customer_stream\non table customer;\n\n-- new customer\ninsert into customer select 4, 'alice', 'gates', 'chef', 'NY', 'self-employed', 0;\n\n-- updated customer\nupdate customer\nset title = 'senior engineer'\nwhere customer_id = 3;\n\n-- deleted customer\ndelete\nfrom customer\nwhere customer_id = 2;\n\nselect *\nfrom customer_stream;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d825b90b-8f6b-4098-9e9d-105e8dca96f5",
   "metadata": {
    "name": "transform_md",
    "collapsed": false,
    "resultHeight": 190
   },
   "source": "## Load the changes to the Braze schema\n\nThese are the core steps that is done continously at a time period of your choosing. We'll show an example of automating this at the end.\n\n### Create a temporary table\n\nFirst, we'll want to capture these changes as a new temp table to operate on them, but it's also an easy way to advance the offset in the stream."
  },
  {
   "cell_type": "code",
   "id": "b90da36b-b038-458a-bacf-f6ee976f57b8",
   "metadata": {
    "language": "sql",
    "name": "temp_table",
    "collapsed": false,
    "resultHeight": 112
   },
   "outputs": [],
   "source": "create or replace temp table cust_stream_tmp\nas\nselect *\nfrom customer_stream;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "27b8e703-d28d-44a2-bb8e-06bec8d3bb77",
   "metadata": {
    "name": "temp_table_md",
    "collapsed": false,
    "resultHeight": 41
   },
   "source": "Then, you can check the stream to ensure that the stream is now back to being **empty** (as it waits for new inserts, updates, or deletes)."
  },
  {
   "cell_type": "code",
   "id": "3e948ae1-2925-4450-ad3d-9971ecfb905f",
   "metadata": {
    "language": "sql",
    "name": "empty_stream",
    "collapsed": false,
    "resultHeight": 112
   },
   "outputs": [],
   "source": "select *\nfrom customer_stream;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d93fd1a4-d366-42a3-abf7-a9f24b01b860",
   "metadata": {
    "name": "transform2_md",
    "collapsed": false,
    "resultHeight": 923
   },
   "source": "### Transform into the Braze payload\n\nEach attribute that has changed on each customer will need to be translated to a json representation of the same record when data is sync'd to Braze. Therefore, a record like:\n\n| customer_id | first_name | last_name | title | state | employer | days_since_last_purchase |\n| -------- | ------- | ------- | ------- | ------- | ------- | ------- |\n| 3 | george p. | burdell | engineer | GA | CNN | 72 |\n#\nWould equate to the following json payload for Braze:\n\n```json\n{\n    \"first_name\" : \"george p.\",\n    \"last_name\" : \"burdell\",\n    \"title\" : \"engineer\",\n    \"state\" : \"GA\",\n    \"employer\" : \"CNN\",\n    \"days_since_last_purchase\" : 72\n}\n```\n\nWhile this is what the *entire* record would look like in Braze, we need to efficiently submit the payload for only the **changed** attributes. For George, only his title changed from \"engineer\" to \"senior engineer\". Therefore, we need a payload that matches that changed attribute:\n\n```json\n{\n    \"title\" : \"senior engineer\"\n}\n```\n\nBecause \"updates\" are handled as both an *insert* and *delete* in a stream, the SQL to do this can seem a little opaque. In the code below, you'll see that comments separate each section specifying which records are new, which records are updated, and which records have been deleted - all combined with UNION ALL.\n\n| customer_id | first_name | last_name | title | state | employer | days_since_last_purchase | METADATA$ACTION | METADATA$ISUPDATE | METADATA$ROW_ID\n| -------- | ------- | ------- | ------- | ------- | ------- | ------- | ------- | ------- | ------- |\n| 3 | george p. | burdell | engineer | GA | CNN | 72 | DELETE | TRUE | 123abc |\n| 3 | george p. | burdell | senior engineer | GA | CNN | 72 | INSERT | TRUE | 123abc |"
  },
  {
   "cell_type": "code",
   "id": "8d50cbf4-0c8d-4950-86cb-114990437ac9",
   "metadata": {
    "language": "sql",
    "name": "transform_sql",
    "codeCollapsed": false,
    "resultHeight": 182,
    "collapsed": false
   },
   "source": "INSERT into braze_cloud_production.ingestion.users_attributes_sync\n\n-- get new customers in the CUSTOMER table\nselect cs.customer_id::varchar as external_id, to_json(object_agg(cs.col, cs.val::variant))::varchar as payload, sysdate() updated_at\nfrom cust_stream_tmp\n    UNPIVOT(val FOR col IN (first_name, last_name, title, state, employer)) cs\nwhere cs.metadata$action = 'INSERT'\nand cs.metadata$isupdate = FALSE\ngroup by cs.customer_id\n\n-- add updates to existing customers\nUNION ALL\nselect cs.customer_id::varchar as external_id, to_json(object_agg(cs.col, cs.val::variant))::varchar as payload, sysdate() updated_at \nfrom cust_stream_tmp\n    UNPIVOT(val FOR col IN (first_name, last_name, title, state, employer)) cs\nleft join \n    (select * from cust_stream_tmp\n    UNPIVOT(val FOR col IN (first_name, last_name, title, state, employer)) where metadata$action = 'DELETE') cs2\n    on cs.metadata$row_id = cs2.metadata$row_id and cs.val = cs2.val\nwhere cs.metadata$action = 'INSERT'\nand cs2.val is null\nand cs.metadata$isupdate = TRUE\ngroup by cs.customer_id\n\n-- add deletes to deleted customers\nUNION ALL\nselect customer_id::varchar as external_id, null as payload, sysdate() updated_at\nfrom cust_stream_tmp\nwhere metadata$action = 'DELETE'\nand metadata$isupdate = FALSE;\n\nselect *\nfrom braze_cloud_production.ingestion.users_attributes_sync;",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "d1f68eb7-aa66-4dab-a0ab-e0d1b8e1dadf",
   "metadata": {
    "name": "vw_upserts_md",
    "collapsed": false,
    "resultHeight": 41
   },
   "source": "Now - we can see the views for both the inserts/updates:"
  },
  {
   "cell_type": "code",
   "id": "a768848b-ce80-4cc2-97e0-40b3eaa9ee3a",
   "metadata": {
    "language": "sql",
    "name": "vw_upserts_sql",
    "collapsed": false,
    "resultHeight": 147
   },
   "outputs": [],
   "source": "select *\nfrom braze_cloud_production.ingestion.users_attributes_sync_vw;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "97ab873c-d933-4dcd-9e79-68233163e508",
   "metadata": {
    "name": "vw_deletes_md",
    "collapsed": false,
    "resultHeight": 41
   },
   "source": "As well as the deletes:"
  },
  {
   "cell_type": "code",
   "id": "e8f82bc0-58e3-4bb6-994a-60664fbf315c",
   "metadata": {
    "language": "sql",
    "name": "vw_deletes_sql",
    "collapsed": false,
    "resultHeight": 112
   },
   "outputs": [],
   "source": "select *\nfrom braze_cloud_production.ingestion.users_deletes_vw;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "84aee07e-e026-48cb-92d1-8abc965fbf92",
   "metadata": {
    "name": "automation_md",
    "collapsed": false,
    "resultHeight": 553
   },
   "source": "A Snowflake stream is going to be one of the easiest and most efficient ways to track changes to a single table. The above method keeps [best practices](https://www.braze.com/docs/user_guide/data_and_analytics/cloud_ingestion/overview/#only-write-new-or-updated-attributes-to-minimize-consumption) in mind to save on both Snowflake and Braze costs.\n\n## Automation + CDI Installation\n\nNow that we've successfully simulated how this process works, it's time to think about automating this process to run consistently for Braze CDI.\n\nEvery step through creating the stream was a one-time setup piece. We'll need to automate the transformation piece to run periodically.\n\nTo automate this, we'll put the recurring steps in a stored procedure, and then schedule them with a [Snowflake Task](https://docs.snowflake.com/en/user-guide/tasks-intro). There are other options, like creating a new notebook with just the necessary sells and scheduling the notebook to run, but overall I recommend tasks for data pipelines. Alternatively, you may choose to use your own orchestration outside of Snowflake as well!\n\nIn the stored procedure, there will only be a few steps:\n1. Create the temp table (and advance the stream offset)\n2. Create the SQL for the transformation\n3. Run the SQL\n\nThe stored procedure will take in 2 parameters: the stream name and the fields/attributes to be analyzed for changes. It will then output the records that are inserted into the `ingestion.users_attributes_sync` table. \n\nThe task will then wrap the procedure and take care of the actual insert operation. "
  },
  {
   "cell_type": "code",
   "id": "c695373e-ac74-4b62-a1f1-08206cbd5c81",
   "metadata": {
    "language": "sql",
    "name": "automation_sql",
    "collapsed": false,
    "resultHeight": 0
   },
   "source": "CREATE OR REPLACE PROCEDURE braze_cdi_cust_proc(stream_name STRING, fields STRING)\n  RETURNS table(external_id varchar, payload varchar, updated_at timestamp_ntz)\n  LANGUAGE PYTHON\n  RUNTIME_VERSION = '3.9'\n  PACKAGES = ('snowflake-snowpark-python')\n  HANDLER = 'run'\nAS\n$$\ndef run(session, temp_table, fields):\n\n  temp_table_sql = f\"\"\"\n    create or replace temp table temp_table as select * from {stream_name}\n  \"\"\"\n  session.sql(temp_table_sql)\n\n  transform_sql = f\"\"\"\n  SELECT cs.customer_id::varchar as external_id, to_json(object_agg(cs.col, cs.val::variant)) as payload, sysdate() updated_at\n    FROM temp_table\n        UNPIVOT(val FOR col IN ({fields})) cs\n    where cs.metadata$action = 'INSERT'\n    and cs.metadata$isupdate = FALSE\n    group by cs.customer_id\n\n    -- add updates to existing customers\n    UNION ALL\n    SELECT cs.customer_id::varchar as external_id, to_json(object_agg(cs.col, cs.val::variant)) as payload, sysdate() updated_at \n    FROM temp_table\n        UNPIVOT(val FOR col IN ({fields})) cs\n    left join \n        (select * from temp_table\n        UNPIVOT(val FOR col IN ({fields})) where metadata$action = 'DELETE' and metadata$isupdate = TRUE) cs2\n        on cs.metadata$row_id = cs2.metadata$row_id and cs.val = cs2.val\n    where cs.metadata$action = 'INSERT'\n    and cs2.val is null\n    and cs.metadata$isupdate = TRUE\n    group by cs.customer_id\n    \n    -- add deletes to deleted customers\n    UNION ALL\n    select cs.customer_id::varchar as external_id, null as payload, sysdate() updated_at\n    FROM temp_table\n    where cs.metadata$action = 'DELETE'\n    and cs.metadata$isupdate = FALSE\n  \"\"\"\n  return session.sql(transform_sql)\n\n$$;\n\ncreate task braze_cdi_cust_task\n  warehouse = braze_cdi_wh\n  schedule = '60 MINUTE'\n  as\n    insert into braze_cloud_production_dd.ingestion.users_attributes_sync\n    select *\n    from table(braze_cdi_cust_proc('customer_stream','first_name, last_name, title, state, employer'));",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "5b52b98d-a056-404e-865b-b2ab5521246e",
   "metadata": {
    "name": "conclusion",
    "collapsed": false,
    "resultHeight": 547
   },
   "source": "After creating a task, you'll need to `RESUME` the task to kick it off. It then runs on the schedule until suspended. So that you don't actually run this code accidentally in the notebook, it will be included here for reference:\n\n```sql\nalter task braze_cdi_cust_task resume;\n```\n\nAs deciding on the schedule, a best practice here would be to run the task similar to how the customer table is updated. If the customer table is updated every hour, then run the task every hour (and subsequently, CDI every hour).\n\nThe CDI set up process will not be in this notebook, but rather in the quickstart. If you're looking for that - check that out at https://quickstarts.snowflake.com and [Braze CDI docs](https://www.braze.com/docs/user_guide/data_and_analytics/cloud_ingestion/integrations/?tab=snowflake).\n\n## Conclusion\n\nWith this notebook, you've learned how to do the following steps in Snowflake for use in Braze CDI:\n1. Setup the necessary Snowflake objects\n2. Generate sample customer records\n3. Simulate inserting, updating, and deleting sample records\n4. Automate the Snowflake process\n\nHopefully this was helpful!"
  }
 ]
}