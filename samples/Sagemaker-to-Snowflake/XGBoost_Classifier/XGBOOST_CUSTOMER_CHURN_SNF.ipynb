{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "nasuateia7jyqpmuwhj6",
   "authorId": "6149508575120",
   "authorName": "RPEGU",
   "authorEmail": "ranjeeta.pegu@snowflake.com",
   "sessionId": "78f8c5f2-6a29-440b-98da-67fb24ac8c4a",
   "lastEditTime": 1756827515044
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c2528dc-25c7-4442-8cb9-144c02f127c2",
   "metadata": {
    "name": "Introduction",
    "collapsed": false
   },
   "source": "## Introduction ##\n\nCustomer loss can significantly impact a business’s bottom line. By detecting at-risk customers early, companies can proactively engage them with retention strategies. In this workshop, we'll explore how to use native Snowflake’s [machine learning](https://docs.snowflake.com/de/developer-guide/snowpark-ml/reference/1.5.3/modeling) capabilities to automate the identification of dissatisfied customers—commonly referred to as churn prediction\n\n ** Internal** [aws - example ](https://sagemaker-examples.readthedocs.io/en/latest/introduction_to_applying_machine_learning/xgboost_customer_churn/xgboost_customer_churn_outputs.html#Data)\n\n### Configuring the environment "
  },
  {
   "cell_type": "markdown",
   "id": "af05cc8a-7a47-4ea3-812b-554343ab2260",
   "metadata": {
    "name": "prerequisite",
    "collapsed": false
   },
   "source": "I have download the data and uploaded it into snowflake using the  **COPY** Command"
  },
  {
   "cell_type": "code",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "Libraries"
   },
   "source": "# Import python packages\nimport streamlit as st\nimport pandas as pd\n\n# We can also use Snowpark for our analyses!\nfrom snowflake.snowpark.context import get_active_session\nsession = get_active_session()\n\n#Snowflake libraries \nfrom snowflake import snowpark\nfrom snowflake.ml import dataset\nfrom snowflake.snowpark.functions import col,when,lit\nfrom snowflake.snowpark.types import *\n\n## Snowflake ml libraries\nfrom snowflake.ml.modeling.xgboost import XGBClassifier\nfrom snowflake.ml.modeling.preprocessing import MinMaxScaler , OneHotEncoder\n\n# snowpark ML metrics\nfrom snowflake.ml.modeling.metrics import accuracy_score,f1_score,precision_score,roc_auc_score,roc_curve,recall_score\n\n\n# python libraries \nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport time\nimport json\nfrom IPython.display import display\n\n## set the database and schema\nsession.use_database('ml_models')\nsession.use_schema('ml_models.ds')\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "8d50cbf4-0c8d-4950-86cb-114990437ac9",
   "metadata": {
    "language": "python",
    "name": "downloadData"
   },
   "source": "#download the data \nchurn = session.table(\"CHURN\")\n\nchurn.show(5)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "beaacb4a-a9ef-4c2b-9bfe-e3ba6067fb5c",
   "metadata": {
    "name": "cell2",
    "collapsed": false
   },
   "source": "## EDA\n\nLet’s explore the dataset further and uncover additional insights."
  },
  {
   "cell_type": "code",
   "id": "c695373e-ac74-4b62-a1f1-08206cbd5c81",
   "metadata": {
    "language": "python",
    "name": "EDA"
   },
   "source": "# get the numerical and categorical features\n#get the schema\nschema = churn.schema\n\nnumerical_types = (IntegerType, FloatType, DecimalType, LongType, ShortType, DoubleType)\nnumerical_columns =[f.name for f in schema if isinstance(f.datatype, numerical_types)]\n\n\ncategorical_types  = (StringType, VariantType, BooleanType)\ncategorical_columns = [f.name  for f in schema if isinstance(f.datatype, categorical_types)]\n\nprint(\"Numerical Columns:\", numerical_columns)\nprint(\"Categorical Columns:\", categorical_columns)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "de9b1cea-3344-4117-8989-b0af6eaa36be",
   "metadata": {
    "language": "python",
    "name": "describe"
   },
   "outputs": [],
   "source": "pd.set_option(\"display.max_columns\", 500)\ndf = churn.describe()\ndf\n",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "bd05e5bd-de68-429c-bfe3-95695392996c",
   "metadata": {
    "name": "cell1",
    "collapsed": false
   },
   "source": "We can see immediately that: - State appears to be quite evenly distributed. - Phone takes on too many unique values to be of any practical use. It’s possible that parsing out the prefix could have some value, but without more context on how these are allocated, we should avoid using it. - Most of the numeric features are surprisingly nicely distributed, with many showing bell-like gaussianity. VMail Message is a notable exception (and Area Code showing up as a feature we should convert to non-numeric)."
  },
  {
   "cell_type": "code",
   "id": "e166619a-c6af-4f75-aeac-0281e928a2df",
   "metadata": {
    "language": "python",
    "name": "drop_phone_col"
   },
   "outputs": [],
   "source": "#drop column phone from the snowprk dataframe\nchurn = churn.drop(\"PHONE\")\n\n#convert to a string column\nchurn = churn.with_column(\"AREA_CODE\", col(\"AREA_CODE\").cast(StringType()))\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "41e13eb5-4b31-43a8-ac9e-a241e60b4666",
   "metadata": {
    "language": "python",
    "name": "Hist",
    "collapsed": false,
    "codeCollapsed": true
   },
   "outputs": [],
   "source": "import matplotlib.pyplot as plt\ndf = churn.to_pandas()\n\n# Histograms of numeric features by CHURN class\nfor column in df.select_dtypes(include=[\"number\"]).columns:\n    hist = df[[column, \"CHURN\"]].hist(by=\"CHURN\", bins=30, edgecolor='black', figsize=(4, 3))\n    plt.suptitle(f\"{column} by CHURN\", y=1)  # Add title\n    plt.tight_layout()\n    plt.show()\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4c410412-42f3-4972-8068-b93d40f8e5e1",
   "metadata": {
    "language": "python",
    "name": "corr"
   },
   "outputs": [],
   "source": "#df_corr = churn.select_dtypes(include=['number']).corr()\n#df_corr\nnumerical_columns =[f.name for f in churn.schema if isinstance(f.datatype, numerical_types)]\n # Initialize an empty DataFrame to store the correlation matrix\ncorr_matrix = pd.DataFrame(index=numerical_columns, columns=numerical_columns, dtype=float)\n\n\n# For each pair of numerical columns, calculate the correlation\nfor col1 in numerical_columns:\n        for col2 in numerical_columns:\n            correlation_value = churn.stat.corr(col1, col2)\n            corr_matrix.loc[col1, col2] = correlation_value\n            \n            \nprint(\"\\nCorrelation Matrix calculated with df.stat.corr():\")\nprint(corr_matrix)\n    \n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cd41666f-1de9-40bb-b6b0-e2390b736b5f",
   "metadata": {
    "language": "python",
    "name": "corrmatrix"
   },
   "outputs": [],
   "source": "import seaborn as sns\nplt.figure(figsize=(10, 8))\n\nsns.heatmap(\n    corr_matrix,\n    annot = True,\n    cmap ='coolwarm',\n    fmt = \".2f\",\n    linewidths =-.5,\n    cbar_kws={'label': 'Correlation Coefficient'}\n)\n\n",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7dc5ec61-0ef1-494a-af01-65c39e1e3423",
   "metadata": {
    "name": "cell8",
    "collapsed": false
   },
   "source": "We see several features that essentially have 100% correlation with one another. Including these feature pairs in some machine learning algorithms can create catastrophic problems, while in others it will only introduce minor redundancy and bias. Let’s remove one feature from each of the highly correlated pairs: Day Charge from the pair with Day Mins, Night Charge from the pair with Night Mins, Intl Charge from the pair with Intl Mins:"
  },
  {
   "cell_type": "code",
   "id": "1df86bf2-6fe6-4a97-bad2-ba40107d4c99",
   "metadata": {
    "language": "python",
    "name": "rename_bool_col",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "churn= churn.with_column_renamed(\"Int'l Plan\",\"INTL_PLAN\")\n#churn.columns\n#Cat_cols =['STATE','INTL_PLAN', 'VMAIL_PLAN']\n\n\n\nchurn= (\n    churn\n    .with_column(\"INTL_PLAN\", \n                 when(col(\"INTL_PLAN\")== True,1).otherwise(0))\n    .with_column(\"VMAIL_PLAN\", when(col(\"VMAIL_PLAN\")== True,1).otherwise(0))\n)\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "534eedd3-31ea-4b44-8292-5a9073aa6521",
   "metadata": {
    "language": "python",
    "name": "drop_correlate_cols"
   },
   "outputs": [],
   "source": "#drop \nchurn = churn.drop(\"Day Charge\", \"Eve Charge\", \"Night Charge\", \"Intl Charge\")",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "32673c44-0071-4f4a-95e3-cae5f2f1fcd6",
   "metadata": {
    "name": "cell11",
    "collapsed": false
   },
   "source": "But first, let’s convert our categorical features into numeric features."
  },
  {
   "cell_type": "code",
   "id": "15b86be3-987d-426d-a3d6-634a1dac6f5b",
   "metadata": {
    "language": "python",
    "name": "Onehotencoding"
   },
   "outputs": [],
   "source": "\n\ncat_cols =['STATE','INTL_PLAN', 'VMAIL_PLAN','AREA_CODE']\nohe = OneHotEncoder(input_cols=cat_cols,\n                   output_cols=cat_cols,\n                   drop_input_cols=True,\n                   drop=\"first\",\n                   handle_unknown=\"ignore\")\n#fit & Transform\ndf = ohe.fit(churn).transform(churn)\ndf= df.with_column(\n    \"CHURN\",\n    when(col(\"CHURN\") == \"True.\", 1).otherwise(0)\n)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "27a5b8f6-2fa7-47e0-80ed-ab1d3393a8ab",
   "metadata": {
    "language": "python",
    "name": "cell4"
   },
   "outputs": [],
   "source": "#df",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f6383ab1-65bf-401e-b917-06ce75c739b2",
   "metadata": {
    "name": "Train_test_split",
    "collapsed": false
   },
   "source": "# Train Test Split \nLet’s split the data into training, validation, and test sets."
  },
  {
   "cell_type": "code",
   "id": "760188b7-c8fe-4156-938d-9137ae9430ff",
   "metadata": {
    "language": "sql",
    "name": "optional_runifneeded",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "ALTER DATASET CHURN_TRAIN_DF DROP VERSION 'snf';\nALTER DATASET CHURN_TEST_DF DROP VERSION 'snf';\nALTER DATASET CHURN_VALIDATION_DF DROP VERSION 'snf';\n",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2bb5965b-4563-4a1c-b3a3-80b33b0cc8c3",
   "metadata": {
    "name": "cell3",
    "collapsed": false
   },
   "source": "# Dataset\nAfter splitting the data into training, validation, and test sets,  I will store them as Snowflake datasets (tables or views).  \nThis ensures I can reuse the splits in future runs without repeating the preprocessing steps.\n"
  },
  {
   "cell_type": "code",
   "id": "a012985c-77cd-4459-a5a5-94d069535901",
   "metadata": {
    "language": "python",
    "name": "snfdataset"
   },
   "outputs": [],
   "source": "\ntrain_df, validation_data,test_df = df.random_split(weights = [0.70,0.20,0.1],seed=62)\n\n## we will keep the dataset in snowflake for future use\nfrom snowflake.ml import dataset\n\n# Materialize DataFrame contents into a Dataset\nds1 = dataset.create_from_dataframe(\n    session,\n    \"churn_train_df\",\n    \"snf\",\n    input_dataframe=train_df)\nds2 = dataset.create_from_dataframe(\n    session,\n    \"churn_test_df\",\n    \"snf\",\n    input_dataframe=train_df)\nds3 = dataset.create_from_dataframe(\n    session,\n    \"churn_validation_df\",\n    \"snf\",\n    input_dataframe=train_df)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "963dd88e-2e9e-4ede-995f-7c596e0557ea",
   "metadata": {
    "language": "python",
    "name": "download_traindata"
   },
   "outputs": [],
   "source": "# Create a DataConnector from a Snowflake Dataset\nds_train = dataset.load_dataset(session, \"churn_train_df\", \"snf\")\n# Get a Snowpark DataFrame\ndf_train = ds_train.read.to_snowpark_dataframe()\n\nds_validation = dataset.load_dataset(session, \"churn_validation_df\", \"snf\")\ndf_validation = ds_validation.read.to_snowpark_dataframe()\n\n\nds_test = dataset.load_dataset(session, \"churn_test_df\", \"snf\")\ndf_test = ds_test.read.to_snowpark_dataframe()\n\n\n\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1733e471-9628-4adf-9334-32183ee349be",
   "metadata": {
    "language": "python",
    "name": "CastDouble"
   },
   "outputs": [],
   "source": "\n# the snowflake ml libraries are sensitive to datatypes , make sure to cast it properly \ninput_cols = [c for c in df.columns if c != \"CHURN\"]\n\n\nfor c in input_cols:\n    df_train = df_train.with_column(c, col(c).cast(\"double\"))\n\nfor c in input_cols:\n    df_test = df_test.with_column(c, col(c).cast(\"double\"))\nfor c in input_cols:\n    df_validation = df_validation.with_column(c, col(c).cast(\"double\"))\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "53070813-c44f-47b4-81e5-cb4a403c718b",
   "metadata": {
    "language": "python",
    "name": "input_label_cols"
   },
   "outputs": [],
   "source": "#df_train.columns\n# Filter out the target column to get the feature columns\ninput_cols = [col_name for col_name in df_train.columns if col_name != \"CHURN\"]\nOUTPUT_COLUMNS=\"PREDICTED_CHURN\"\nlabel_col=\"CHURN\"",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5eeead4d-241b-4d23-b72e-f5e3be79dd72",
   "metadata": {
    "language": "python",
    "name": "modelTrain",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "model1 = XGBClassifier(\n    objective=\"binary:logistic\",\n    n_estimators=100,\n    learning_rate=0.1,\n    max_depth=5,\n    gamma=4,\n    min_child_weight=6,\n    subsample=0.8,\n    use_label_encoder=False,\n    eval_metric=\"logloss\",\n    input_cols=input_cols  ,\n    label_cols=label_col,\n    output_cols=OUTPUT_COLUMNS\n)\n\n#fit\nmodel1.fit(df_train)\npredict_df_train = model1.predict(df_train)\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "521da291-f095-49c9-8cd1-09b5790f111f",
   "metadata": {
    "language": "python",
    "name": "Test_Xgbclassifier"
   },
   "outputs": [],
   "source": "predict_on_test_data = model1.predict(df_test)\n\n\n\n\ntest_accuracy = accuracy_score(df=predict_on_test_data, \n                                   y_true_col_names=[\"CHURN\"],\n                                   y_pred_col_names=[\"PREDICTED_CHURN\"]\n                              )\n\n\n\n# Evaluate\nprint(\"Test Accuracy:\", test_accuracy)\n#print(\"\\nClassification Report:\\n\", classification_report(predict_on_test_data[\"CHURN\"], predict_on_test_data[\"PREDICTED_CHURN\"]))\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "51214f91-08f1-434d-9fc3-3332f22841ef",
   "metadata": {
    "language": "python",
    "name": "xgboostMetrics"
   },
   "outputs": [],
   "source": "from snowflake.ml.modeling.metrics import confusion_matrix\nresult = model.predict(df_validation)\n\n\nmetrics = {\n\"accuracy\":accuracy_score(df=result, \n                          y_true_col_names=\"CHURN\", \n                          y_pred_col_names=\"PREDICTED_CHURN\"),\n\n\"precision\":precision_score(df=result,\n                            y_true_col_names=\"CHURN\", \n                            y_pred_col_names=\"PREDICTED_CHURN\"),\n\n\n\"recall\": recall_score(df=result, \n                       y_true_col_names=\"CHURN\",\n                       y_pred_col_names=\"PREDICTED_CHURN\"),\n\n\n\n\"f1_score\":f1_score(df=result,\n                   y_true_col_names=\"CHURN\",\n                   y_pred_col_names=\"PREDICTED_CHURN\"),\n\"confusion_matrix\":confusion_matrix(df=result, \n                                    y_true_col_name=\"CHURN\",\n                                    y_pred_col_name=\"PREDICTED_CHURN\").tolist()\n}\n\nprint(f\" The Score for the xgboost model :\\n {metrics}\")\nprint(f\" The Score for the xgboost model :\\n {metrics}\")",
   "execution_count": null
  }
 ]
}