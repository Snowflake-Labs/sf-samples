{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c695373e-ac74-4b62-a1f1-08206cbd5c81",
   "metadata": {
    "language": "python",
    "name": "cell3"
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b67244-3b3f-4f30-b770-745a2b10cb0a",
   "metadata": {
    "language": "python",
    "name": "cell4"
   },
   "outputs": [],
   "source": [
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa1318d-0e3a-4fce-88c9-bb791b8c5b52",
   "metadata": {
    "collapsed": false,
    "name": "cell21"
   },
   "source": [
    "# CIFAR-10 Computer Vision Model Training and Evaluation\n",
    "\n",
    "This notebook implements a Convolutional Neural Network (CNN) for image classification using the CIFAR-10 dataset. The code demonstrates a complete machine learning pipeline from data loading to model evaluation.\n",
    "\n",
    "## Key Components:\n",
    "\n",
    "### 1. **Library Imports**\n",
    "- **TensorFlow/Keras**: Deep learning framework for building and training the CNN\n",
    "- **NumPy**: Numerical operations and array handling\n",
    "- **Scikit-learn**: Evaluation metrics (accuracy, precision, recall, F1-score, confusion matrix)\n",
    "- **OS**: File system operations for saving the trained model\n",
    "- **Logging**: Training progress and debugging information\n",
    "\n",
    "### 2. **Data Preprocessing**\n",
    "- Loads CIFAR-10 dataset (60,000 32x32 color images in 10 classes)\n",
    "- Normalizes pixel values from [0,255] to [0,1] range for better training performance\n",
    "- Uses sparse categorical labels (integers 0-9) instead of one-hot encoding\n",
    "\n",
    "### 3. **CNN Architecture**\n",
    "- **Input Layer**: 32x32x3 (RGB images)\n",
    "- **Convolutional Layers**: Two Conv2D layers (32 and 64 filters) with ReLU activation\n",
    "- **Pooling Layers**: MaxPooling2D for dimensionality reduction\n",
    "- **Dense Layers**: Fully connected layers ending with 10-class softmax output\n",
    "\n",
    "### 4. **Optimizer Comparison**\n",
    "The code includes three optimizer options with performance characteristics:\n",
    "- **SGD**: Slower convergence, needs 50+ epochs, achieves ~65-70% accuracy\n",
    "- **RMSprop**: Medium convergence, ~30 epochs, achieves ~60-65% accuracy  \n",
    "- **Adam**: Fast convergence, ~20-30 epochs, achieves ~60-65% accuracy\n",
    "\n",
    "### 5. **Training Process**\n",
    "- Compiles model with sparse categorical crossentropy loss\n",
    "- Trains with validation on test set to monitor overfitting\n",
    "- Saves trained model to `/saved_model/cifar10_model.keras`\n",
    "\n",
    "### 6. **Model Evaluation**\n",
    "Comprehensive evaluation using multiple metrics:\n",
    "- **Accuracy**: Overall classification correctness\n",
    "- **Precision**: True positives / (True positives + False positives)\n",
    "- **Recall**: True positives / (True positives + False negatives)\n",
    "- **F1-Score**: Harmonic mean of precision and recall\n",
    "- **Confusion Matrix**: Detailed breakdown of classification results\n",
    "\n",
    "### 7. **Key Technical Details**\n",
    "- Uses `np.argmax()` to convert probability predictions to class labels\n",
    "- Handles label format conversion (flattening for sparse labels)\n",
    "- Implements weighted averaging for multi-class metrics\n",
    "- Includes TensorBoard logging for hyperparameter visualization\n",
    "\n",
    "This implementation provides a solid foundation for image classification tasks and demonstrates best practices for CNN training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1dc3905-7f5e-4e6e-b2c9-3916566a2da4",
   "metadata": {
    "language": "python",
    "name": "TRAIN_MODEL"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os  # Add this import since you're using os.makedirs\n",
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "#from tensorflow.keras.layers import Input\n",
    "#from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
    "import logging\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO)\n",
    "\n",
    "METRIC_ACCURACY = \"accuracy\"\n",
    "validation = 'validation'\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO)\n",
    "\n",
    "\n",
    "def train_cifar_model(epochs, batch_size, optimizer):\n",
    "    \"\"\"\n",
    "    This function contains the logic from your keras_cifar10.py script.\n",
    "    \"\"\"\n",
    "    # 1. Load data\n",
    "    (x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "    # Normalize pixel values\n",
    "    x_train = x_train.astype(\"float32\") / 255.0\n",
    "    x_test = x_test.astype(\"float32\") / 255.0\n",
    "\n",
    "    # 2. Define the Keras model - Use Input layer instead of input_shape\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Input(shape=(32, 32, 3)),  # Add Input layer first\n",
    "        keras.layers.Conv2D(32, (3, 3), activation='relu'),  # Remove input_shape parameter\n",
    "        keras.layers.MaxPooling2D((2, 2)),\n",
    "        keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        keras.layers.MaxPooling2D((2, 2)),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(64, activation='relu'),\n",
    "        keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    # Typical results for CIFAR-10:\n",
    "    ##SGD:     Slower convergence, may need 50+ epochs, final accuracy ~65-70%\n",
    "    ##RMSprop: Medium convergence, ~30 epochs, final accuracy ~60-65%  \n",
    "    ##Adam:    Fast convergence, ~20-30 epochs, final accuracy ~60-65%\n",
    "    ##Learning Rate Sensitivity:\n",
    "    ##SGD:     Very sensitive - wrong LR can break training\n",
    "    ##RMSprop: Moderately sensitive - usually works with default\n",
    "    ##Adam:    Least sensitive - 0.001 works for most problems\n",
    "\n",
    "\n",
    "    learning_rate = 0.001\n",
    "\n",
    "    \n",
    "    loss_param=\"categorical_crossentropy\"\n",
    "    loss_param='sparse_categorical_crossentropy'\n",
    "\n",
    "    #optimizer = \"sgd\"\n",
    "    #optimizer = \"rmsprop\"\n",
    "    optimizer = \"adam\"\n",
    "    #opt = None\n",
    "    if optimizer == \"sgd\":\n",
    "        opt = SGD(learning_rate=learning_rate)\n",
    "    elif optimizer == \"rmsprop\":\n",
    "        opt = RMSprop(learning_rate=learning_rate)\n",
    "    elif optimizer == \"adam\":\n",
    "        opt = Adam(learning_rate=learning_rate)\n",
    "    else:\n",
    "        raise Exception(\"Unknown optimizer\", optimizer)\n",
    "\n",
    "    # 3. Compile the model\n",
    "    model.compile(#optimizer=optimizer,\n",
    "                  loss=loss_param,\n",
    "                  metrics=['accuracy'],\n",
    "                  optimizer=opt\n",
    "    )\n",
    "\n",
    "    # 4. Train the model\n",
    "    history = model.fit(x_train, y_train,\n",
    "                        epochs=epochs,\n",
    "                        batch_size=batch_size,\n",
    "                        validation_data=(x_test, y_test))\n",
    "    print(f\"Model History: {history}\")\n",
    "\n",
    "    # 5. Save the trained model\n",
    "    os.makedirs('/saved_model', exist_ok=True)\n",
    "    model_save_path = '/saved_model/cifar10_model.keras' \n",
    "    model.save(model_save_path)\n",
    "    print(f\"Model saved to {model_save_path}\")\n",
    "\n",
    "    # -- model.summary()\n",
    "    \n",
    "    # Convert the lists of uniform elements into NumPy arrays\n",
    "    test_x = x_test # np.array(test_x_list)\n",
    "    test_y = y_test # np.array(test_y_list)\n",
    "\n",
    "    # Use the model to predict the labels\n",
    "    test_predictions = model.predict(test_x)\n",
    "    test_y_pred = np.argmax(test_predictions, axis=1)\n",
    "    ###test_y_true = np.argmax(test_y, axis=1) - incorrect\n",
    "    test_y_true = test_y.flatten()  # Correct\n",
    "    # or\n",
    "    ##test_y_true = test_y.squeeze()  # Also correct\n",
    "\n",
    "\n",
    "    y_pred = np.argmax(test_predictions, axis=1)  # Convert probabilities to class predictions\n",
    "    y_true = np.argmax(y_test, axis=1)  # Convert one-hot encoded labels to class indices\n",
    "\n",
    "    # Evaluating model accuracy and logging it as a scalar for TensorBoard hyperparameter visualization.\n",
    "    accuracy = sklearn.metrics.accuracy_score(test_y_true, test_y_pred)\n",
    "    tf.summary.scalar(METRIC_ACCURACY, accuracy, step=1)\n",
    "    #logging.info(\"Test accuracy:{}\".format(accuracy))\n",
    "\n",
    "    print(\"Test accuracy:{}\".format(accuracy))\n",
    "\n",
    "    ## Diff test accuracy\n",
    "\n",
    "    # Evaluate\n",
    "    ## 2\n",
    "\n",
    "    #result = test_predictions #model.predict(test_y_true, test_y_pred)\n",
    "\n",
    "    #print(result)\n",
    "    ''' ''' \n",
    "    y_true = test_y_true\n",
    "    y_pred = test_y_pred\n",
    "    \n",
    "    # Calculate metrics\n",
    "    metrics = {\n",
    "    \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "    \n",
    "    \"precision\": precision_score(y_true, y_pred, average='weighted'),  # or 'macro', 'micro'\n",
    "    \n",
    "    \"recall\": recall_score(y_true, y_pred, average='weighted'),\n",
    "    \n",
    "    \"f1_score\": f1_score(y_true, y_pred, average='weighted'),\n",
    "    \n",
    "    \"confusion_matrix\": confusion_matrix(y_true, y_pred).tolist()\n",
    "    }\n",
    "\n",
    "\n",
    "    return f\"The Score for the computer vision model:\\n {metrics}\" # history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438c3e30-d61a-43a3-9a6b-d03da3db6734",
   "metadata": {
    "language": "python",
    "name": "RUN_TRAIN_MODEL"
   },
   "outputs": [],
   "source": [
    "#Run to train the model\n",
    "\n",
    "# Typical results for CIFAR-10:\n",
    "##SGD:     Slower convergence, may need 50+ epochs, final accuracy ~65-70%\n",
    "##RMSprop: Medium convergence, ~30 epochs, final accuracy ~60-65%  \n",
    "##Adam:    Fast convergence, ~20-30 epochs, final accuracy ~60-65%\n",
    "##Learning Rate Sensitivity:\n",
    "##SGD:     Very sensitive - wrong LR can break training\n",
    "##RMSprop: Moderately sensitive - usually works with default\n",
    "##Adam:    Least sensitive - 0.001 works for most problems\n",
    "\n",
    "hyperparameters = {\"epochs\": 30, \"batch-size\": 256, \"optimizer\": 'adam'}\n",
    "\n",
    "train_cifar_model('', hyperparameters[\"epochs\"], hyperparameters[\"batch-size\"], hyperparameters[\"optimizer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6226010-dc28-407a-9a0e-2988ffc9bf12",
   "metadata": {
    "collapsed": false,
    "name": "Mark_IMG"
   },
   "source": [
    "## Image Preprocessing - Essential Requirements\n",
    "\n",
    "This preprocessing step is **essential** because:\n",
    "\n",
    "- **Standardization**: All images must be the same size for batch processing\n",
    "- **Model Compatibility**: The CNN was trained on 32Ã—32 images, so new images must match  \n",
    "- **Memory Efficiency**: Smaller images reduce computational requirements\n",
    "- **Consistency**: Ensures the model receives data in the expected format\n",
    "\n",
    "> **Note**: This resizing step is critical before feeding images to our trained CIFAR-10 model for accurate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95dc3140-a431-47b5-9e0c-32360162ead0",
   "metadata": {
    "language": "python",
    "name": "Check_IMG"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "image_path = '0009.jpg' \n",
    "img = Image.open(image_path).resize((32, 32))\n",
    "\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848c2467-2705-439e-8aaf-b75e0ff90e72",
   "metadata": {
    "collapsed": false,
    "name": "Mark_Test"
   },
   "source": [
    "## CIFAR-10 Image Prediction System\n",
    "\n",
    "- This notebook demonstrates how to load a trained CIFAR-10 model and make predictions on new images using Snowflake's Python environment.\n",
    "- Load a saved Keras model and predict which of the 10 CIFAR-10 classes a new image belongs to, with complete preprocessing pipeline.\n",
    "- Predict single image\n",
    "- Batch Processing predict images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ec134d-e84e-4580-b474-49dd4ad12b5c",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "TEST_1"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "# You might need to install Pillow: pip install Pillow\n",
    "from PIL import Image\n",
    "\n",
    "# Define the human-readable class names for CIFAR-10\n",
    "CLASS_NAMES = ['airplane', 'automobile', 'bird', 'cat', 'deer', \n",
    "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "local_model_path = '/tmp/keras_cifar10_model'\n",
    "\n",
    "def predict_single_image(model_path, image_path):\n",
    "    \"\"\"\n",
    "    Loads a saved model, preprocesses a single image,\n",
    "    and returns the predicted class name.\n",
    "    \n",
    "    Args:\n",
    "        model_path (str): The path to the saved Keras model directory.\n",
    "        image_path (str): The path to the new image file.\n",
    "        \n",
    "    Returns:\n",
    "        str: The predicted class name.\n",
    "    \"\"\"\n",
    "    # --- 1. Load the saved model ---\n",
    "    # Use tf.keras.models.load_model to load the entire model.\n",
    "    print(f\"Loading model from: {model_path}\")\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "    \n",
    "    # --- 2. Load and Preprocess the Image ---\n",
    "    # The model was trained on 32x32 images, so we must resize our new image.\n",
    "    img = Image.open(image_path).resize((32, 32))\n",
    "    \n",
    "    # Convert the image to a NumPy array and normalize pixel values to [0, 1]\n",
    "    img_array = np.array(img) / 255.0\n",
    "    \n",
    "    # The model.predict method expects a \"batch\" of images.\n",
    "    # We add a new axis to turn our (32, 32, 3) image into (1, 32, 32, 3).\n",
    "    img_batch = np.expand_dims(img_array, axis=0)\n",
    "    \n",
    "    # --- 3. Make the Prediction ---\n",
    "    predictions = model.predict(img_batch)\n",
    "    \n",
    "    # --- 4. Interpret the Results ---\n",
    "    # The output is an array of probabilities for each class.\n",
    "    # We find the index of the highest probability using np.argmax.\n",
    "    predicted_class_index = np.argmax(predictions[0])\n",
    "    \n",
    "    # Map the index to its corresponding class name.\n",
    "    predicted_class_name = CLASS_NAMES[predicted_class_index]\n",
    "    \n",
    "    return predicted_class_name\n",
    "\n",
    "# --- Example Usage ---\n",
    "if __name__ == '__main__':\n",
    "    # First, run your training process\n",
    "    ##main()\n",
    "    \n",
    "    # Now, use the function to predict on a new image\n",
    "    # IMPORTANT: Replace these paths with your actual paths\n",
    "    SAVED_MODEL_PATH = '/saved_model/cifar10_model.keras' # '/tmp/keras_cifar10_model'\n",
    "    # Download or find a sample image of a truck, car, etc.\n",
    "    NEW_IMAGE_PATH = '0009.jpg' #plane\n",
    "    #NEW_IMAGE_PATH = '0016.jpg' # cat\n",
    "    #NEW_IMAGE_PATH = '0007.jpg' # ship\n",
    "\n",
    "    # Create a list of all images you want to test\n",
    "    images_to_test = ['0007.jpg', '0009.jpg', '0016.jpg'] # ship, plane, cat\n",
    "    \n",
    "    for image_file in images_to_test:\n",
    "        try:\n",
    "            print(f\"\\n--- Predicting for image: {image_file} ---\")\n",
    "            prediction = predict_single_image(SAVED_MODEL_PATH, image_file)\n",
    "            print(f\"ðŸ“¸ The model predicts this image is a: {prediction.upper()}\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Error: Image file not found at '{image_file}'.\")\n",
    "\n",
    "    try:\n",
    "        prediction = predict_single_image(SAVED_MODEL_PATH, NEW_IMAGE_PATH)\n",
    "        print(\"\\n\" + \"=\"*30)\n",
    "        print(f\"ðŸ“¸ The model predicts the image is a: {prediction.upper()}\")\n",
    "        print(\"=\"*30)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"\\nError: Image file not found at '{NEW_IMAGE_PATH}'.\")\n",
    "        print(\"Please update NEW_IMAGE_PATH with a valid path to an image.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "authorEmail": "ihor.karbovskyy@snowflake.com",
   "authorId": "26807344418",
   "authorName": "IKARBOV",
   "lastEditTime": 1757002350893,
   "notebookId": "azkuerkjgkaq6evt5sll",
   "sessionId": "eff06377-08f9-408e-8f7e-774e6f67b0c7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
