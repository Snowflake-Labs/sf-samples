{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "cell1",
    "collapsed": false,
    "resultHeight": 0
   },
   "source": "# Import python packages\nimport streamlit as st\nimport pandas as pd\nimport os\n# We can also use Snowpark for our analyses!\nfrom snowflake.snowpark.context import get_active_session\nsession = get_active_session()\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "8ae58f97-bb31-4290-b2dd-2416f3c2ce15",
   "metadata": {
    "name": "cell9",
    "collapsed": false,
    "resultHeight": 74
   },
   "source": "# Growth Accounting"
  },
  {
   "cell_type": "code",
   "id": "435baefb-25ff-42a1-b4f8-236a98b4afac",
   "metadata": {
    "language": "sql",
    "name": "cell3",
    "collapsed": false,
    "resultHeight": 510
   },
   "outputs": [],
   "source": "select\n    o_custkey as id,\n    date_trunc(year, o_orderdate) as order_year,\n    sum(o_totalprice) as total\nfrom SNOWFLAKE_SAMPLE_DATA.TPCH_SF1.ORDERS\ngroup by all\norder by id, order_year",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "20f1dd62-d796-4190-b34a-89a16fea1819",
   "metadata": {
    "language": "python",
    "name": "cell10",
    "collapsed": false,
    "resultHeight": 0
   },
   "outputs": [],
   "source": "df = cell3.to_pandas()\n\n#pivot data to add row for each id:year with no revenue\nresult = df.pivot_table(\n    index='ID',\n    columns='ORDER_YEAR', \n    values='TOTAL',\n    fill_value=0\n).reset_index().melt(\n    id_vars='ID',\n    var_name='ORDER_YEAR',\n    value_name='TOTAL'\n)\n\n# save the dataframe as table for SQL querying \ndf = session.create_dataframe(result)\ndf.write.mode(\"overwrite\").save_as_table(\"df\", table_type=\"temporary\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "52ae5a36-e143-4ebb-b884-e17750b0c77f",
   "metadata": {
    "language": "sql",
    "name": "cell7",
    "collapsed": false,
    "resultHeight": 426
   },
   "outputs": [],
   "source": "select * from df\norder by id, order_year\nlimit 10",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "11971c03-53a7-4429-870a-4b51bbef7aca",
   "metadata": {
    "language": "sql",
    "name": "cell6",
    "collapsed": false,
    "resultHeight": 510
   },
   "outputs": [],
   "source": "with windowed as (\n    \n    select\n        *,\n        sum(total) over(partition by id order by order_year asc) as lifetime_spend,\n        coalesce(lag(total) over(partition by id order by order_year asc), 0) as previous_year_total,\n    from df\n\n)\n\nselect *,\n  case\n    when total = previous_year_total and total > 0 then 'retained'\n    when total > 0 and previous_year_total = 0 and lifetime_spend = total then 'new'\n    when total = 0 and previous_year_total > 0 then 'churned'\n    when total > previous_year_total and previous_year_total > 0 then 'expanded'\n    when total < previous_year_total and previous_year_total > 0 then 'contracted'\n    when total > 0 and previous_year_total = 0 and lifetime_spend > total then 'resurrected'\n  else 'irrelevant' end as category,\n  case category\n    when 'retained' then 0\n    when 'new' then total\n    when 'churned' then (-1 * previous_year_total)\n    when 'expanded' then total - previous_year_total\n    when 'contracted' then (-1 * (previous_year_total - total))\n    when 'resurrected' then total\n  else 0 end as net_change\nfrom windowed\norder by id, order_year",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "13f099e5-4265-438d-ab46-b3315bfc1f1d",
   "metadata": {
    "language": "sql",
    "name": "cell4",
    "collapsed": false,
    "resultHeight": 438
   },
   "outputs": [],
   "source": "select\n    date_part(year, order_year) as order_year,\n    category,\n    round(sum(total)) as total,\n    round(sum(net_change)) as net_change\nfrom {{ cell6 }}\ngroup by all",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "735da8fc-91c0-4604-8041-1437208a1f01",
   "metadata": {
    "language": "python",
    "name": "cell2",
    "collapsed": false,
    "resultHeight": 772
   },
   "outputs": [],
   "source": "# Option to define dictionary to color code each category, may need to use matplotlib\n# Option to use altair for better control of ticks on Y axis\nst.bar_chart(cell4, x='ORDER_YEAR', y='NET_CHANGE', color='CATEGORY', height=750)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "06f083eb-ae70-42ad-af0d-261138126bed",
   "metadata": {
    "language": "python",
    "name": "cell5",
    "collapsed": false,
    "resultHeight": 96
   },
   "outputs": [],
   "source": "df = cell6.to_pandas()\nbutton_csv = df.to_csv().encode(\"utf-8\")\nst.download_button(label=\"Download\", data=button_csv, file_name=\"growth_accounting.csv\", mime=\"text/csv\")",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "db63ea18-13d4-43a4-a29c-a734db89e796",
   "metadata": {
    "name": "cell8",
    "collapsed": false,
    "resultHeight": 74
   },
   "source": "# Forecasting"
  },
  {
   "cell_type": "markdown",
   "id": "1d9d5e85-1ad1-422d-9859-20025e4b8561",
   "metadata": {
    "name": "cell11",
    "collapsed": false,
    "resultHeight": 74
   },
   "source": "# API Enrichment"
  },
  {
   "cell_type": "code",
   "id": "9bd53742-511c-4cf9-9e28-02bdbcaca463",
   "metadata": {
    "language": "python",
    "name": "cell13",
    "collapsed": false,
    "resultHeight": 6166
   },
   "outputs": [],
   "source": "import requests\n\ndef get_wiki_extract(title):\n    # Base URL for Wikipedia's API\n    url = \"https://en.wikipedia.org/w/api.php\"\n    \n    # Parameters for the API request\n    params = {\n        \"action\": \"query\",\n        \"format\": \"json\",\n        \"titles\": title,\n        \"prop\": \"extracts\",\n        \"exintro\": True,  # Only get the intro section\n        \"explaintext\": True,  # Get plain text instead of HTML\n    }\n    \n    # Make the request\n    response = requests.get(url, params=params)\n    \n    # Check if request was successful\n    if response.status_code == 200:\n        data = response.json()\n        # Navigate through the JSON response to get the extract\n        pages = data[\"query\"][\"pages\"]\n        # Get the first (and only) page's extract\n        page = list(pages.values())[0]\n        return page.get(\"extract\", \"No extract available\")\n    else:\n        return f\"Error: {response.status_code}\"\n\ncat_breeds = [\n    'Abyssinian_cat',\n    'Aegean_cat',\n    'American_Bobtail',\n    'American_Curl',\n    'American_Ringtail',\n    'American_Shorthair',\n    'American_Wirehair',\n    'Arabian_Mau',\n    'Asian_cat',\n    'Asian_Semi-longhair',\n    'Australian_Mist',\n    'Balinese_cat',\n    'Bambino_cat',\n    'Bengal_cat',\n    'Birman',\n    'Bombay_cat',\n    'Brazilian_Shorthair',\n    'British_Longhair',\n    'British_Shorthair',\n    'Burmese_cat',\n    'Burmilla',\n    'California_Spangled',\n    'Chantilly-Tiffany',\n    'Chartreux',\n    'Chausie',\n    'Colorpoint_Shorthair',\n    'Cornish_Rex',\n    'Cymric_cat',\n    'Cyprus_cat',\n    'Devon_Rex',\n    'Donskoy_cat',\n    'Dragon_Li',\n    'Egyptian_Mau',\n    'European_Shorthair',\n    'Exotic_Shorthair',\n    'Foldex_cat',\n    'German_Rex',\n    'Havana_Brown',\n    'Highlander_cat',\n    'Himalayan_cat',\n    'Japanese_Bobtail',\n    'Javanese_cat',\n    'Kanaani_cat',\n    'Khao_Manee',\n    'Kinkalow',\n    'Korat',\n    'Korean_Bobtail',\n    'Kurilian_Bobtail',\n    'Lambkin_cat',\n    'LaPerm',\n    'Lykoi',\n    'Maine_Coon',\n    'Manx_cat',\n    'Mekong_Bobtail',\n    'Minskin',\n    'Minuet_cat',\n    'Munchkin_cat',\n    'Nebelung',\n    'Neva_Masquerade',\n    'Norwegian_Forest_cat',\n    'Ocicat',\n    'Ojos_Azules',\n    'Oriental_bicolour',\n    'Oriental_Longhair',\n    'Oriental_Shorthair',\n    'Persian_cat',\n    'Traditional_Persian',\n    'Peterbald',\n    'Pixie-bob',\n    'Ragamuffin_cat',\n    'Ragdoll',\n    'Raas_cat',\n    'Russian_Blue',\n    'Savannah_cat',\n    'Scottish_Fold',\n    'Selkirk_Rex',\n    'Serengeti_cat',\n    'Siamese_cat',\n    'Siberian_cat',\n    'Singapura_cat',\n    'Snowshoe_cat',\n    'Sokoke',\n    'Somali_cat',\n    'Sphynx_cat',\n    'Suphalak',\n    'Thai_cat',\n    'Tonkinese_cat',\n    'Toybob',\n    'Toyger',\n    'Turkish_Angora',\n    'Turkish_Van',\n    'Van_cat',\n    'Ukrainian_Levkoy',\n    'York_Chocolate'\n]\ncsv_list = []\n\nfor cat in cat_breeds:\n    print(cat)\n    extract = get_wiki_extract(cat)\n    print(extract)\n    csv_list.append((cat, extract))\n\n# Convert to dataframe and save\ndf = pd.DataFrame(csv_list, columns=['breed', 'description'])\ndf.to_csv('cat_breeds.csv', index=False, encoding='utf-8')",
   "execution_count": null
  }
 ]
}