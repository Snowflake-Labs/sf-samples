{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "session_creation",
    "resultHeight": 0
   },
   "outputs": [],
   "source": [
    "from snowflake.snowpark.context import get_active_session\n",
    "session = get_active_session()\n",
    "\n",
    "import logging\n",
    "logging.getLogger(\"cmdstanpy\").setLevel(logging.WARNING)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d776341f-464d-4a9b-8c98-ac8e05286559",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "orders_sample",
    "resultHeight": 426
   },
   "outputs": [],
   "source": [
    "select\n",
    "    o_custkey,\n",
    "    o_orderdate,\n",
    "    o_totalprice\n",
    "from SNOWFLAKE_SAMPLE_DATA.TPCH_SF1.ORDERS\n",
    "limit 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23297335-ae53-477e-af45-1355957bc24e",
   "metadata": {
    "codeCollapsed": true,
    "collapsed": false,
    "language": "python",
    "name": "generate_synthetic_data",
    "resultHeight": 0
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "\n",
    "class OrderGenerator:\n",
    "    def __init__(\n",
    "        self,\n",
    "        # Basic parameters\n",
    "        start_date='1992-01-01',\n",
    "        end_date='1998-12-31',\n",
    "        target_daily_total=100_000_000,\n",
    "        target_daily_orders=500,\n",
    "        \n",
    "        # Trend parameters\n",
    "        annual_growth_rate=0.15,        # 15% annual growth\n",
    "        order_value_growth_rate=0.05,   # 5% annual growth in order values\n",
    "        \n",
    "        # Seasonal parameters\n",
    "        holiday_peak_day=350,           # Peak shopping day (Dec 16)\n",
    "        holiday_effect_magnitude=1.0,   # Strength of holiday effect\n",
    "        seasonal_baseline=0.8,          # Minimum seasonal multiplier\n",
    "        seasonal_spread=1000,           # Controls how spread out the holiday effect is\n",
    "        \n",
    "        # Weekly parameters\n",
    "        weekend_dip=0.85,              # Weekend order multiplier\n",
    "        weekday_boost=1.1,             # Weekday order multiplier\n",
    "        \n",
    "        # Value distribution parameters\n",
    "        pareto_shape=2.0,              # Shape parameter for order values\n",
    "        min_value_factor=0.3,          # Minimum order value as fraction of average\n",
    "        value_noise_stddev=0.15,       # Standard deviation for order value noise\n",
    "        \n",
    "        # Random seed for reproducibility\n",
    "        random_seed=None\n",
    "    ):\n",
    "        self.start_date = pd.to_datetime(start_date)\n",
    "        self.end_date = pd.to_datetime(end_date)\n",
    "        self.target_daily_total = target_daily_total\n",
    "        self.target_daily_orders = target_daily_orders\n",
    "        \n",
    "        # Store all other parameters\n",
    "        self.annual_growth_rate = annual_growth_rate\n",
    "        self.order_value_growth_rate = order_value_growth_rate\n",
    "        self.holiday_peak_day = holiday_peak_day\n",
    "        self.holiday_effect_magnitude = holiday_effect_magnitude\n",
    "        self.seasonal_baseline = seasonal_baseline\n",
    "        self.seasonal_spread = seasonal_spread\n",
    "        self.weekend_dip = weekend_dip\n",
    "        self.weekday_boost = weekday_boost\n",
    "        self.pareto_shape = pareto_shape\n",
    "        self.min_value_factor = min_value_factor\n",
    "        self.value_noise_stddev = value_noise_stddev\n",
    "        \n",
    "        # Derived parameters\n",
    "        self.avg_order_value = target_daily_total / target_daily_orders\n",
    "        self.min_order_value = self.avg_order_value * self.min_value_factor\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            np.random.seed(random_seed)\n",
    "    \n",
    "    def seasonal_effect(self, day_of_year):\n",
    "        \"\"\"Stronger effect during holiday season\"\"\"\n",
    "        holiday_effect = np.exp(\n",
    "            -((day_of_year - self.holiday_peak_day) ** 2) / \n",
    "            self.seasonal_spread\n",
    "        ) * self.holiday_effect_magnitude\n",
    "        return np.maximum(self.seasonal_baseline + holiday_effect, 0)\n",
    "    \n",
    "    def weekly_effect(self, day_of_week):\n",
    "        \"\"\"Weekend dips in orders\"\"\"\n",
    "        return self.weekend_dip if day_of_week in [5, 6] else self.weekday_boost\n",
    "    \n",
    "    def trend_effect(self, years_passed):\n",
    "        \"\"\"Long-term growth trend\"\"\"\n",
    "        return np.power(1 + self.annual_growth_rate, years_passed)\n",
    "    \n",
    "    def generate_order_value(self, years_passed):\n",
    "        \"\"\"Generate order values following a Pareto distribution\"\"\"\n",
    "        u = np.random.random()\n",
    "        value = self.min_order_value / np.power(1 - u, 1/self.pareto_shape)\n",
    "        value = value * np.power(1 + self.order_value_growth_rate, years_passed)\n",
    "        noise = np.random.normal(1, self.value_noise_stddev)\n",
    "        return round(value * noise)\n",
    "    \n",
    "    def generate_clerk(self):\n",
    "        \"\"\"Generate clerk IDs matching TPCH format\"\"\"\n",
    "        clerk_id = np.random.randint(1000)\n",
    "        return f\"Clerk#{clerk_id:09d}\"\n",
    "    \n",
    "    def generate_customer(self, num_customers=149999):\n",
    "        \"\"\"Generate customer IDs matching TPCH format\"\"\"\n",
    "        return np.random.randint(num_customers)\n",
    "    \n",
    "    def generate_orders(self):\n",
    "        \"\"\"Generate supplementary orders with realistic patterns\"\"\"\n",
    "        orders = []\n",
    "        current_date = self.start_date\n",
    "        \n",
    "        while current_date <= self.end_date:\n",
    "            day_of_year = current_date.dayofyear\n",
    "            years_passed = (current_date - self.start_date).days / 365\n",
    "            \n",
    "            seasonal = self.seasonal_effect(day_of_year)\n",
    "            weekly = self.weekly_effect(current_date.weekday())\n",
    "            trend = self.trend_effect(years_passed)\n",
    "            \n",
    "            target_orders = round(\n",
    "                self.target_daily_orders * \n",
    "                seasonal * weekly * trend\n",
    "            )\n",
    "            \n",
    "            for _ in range(target_orders):\n",
    "                order = {\n",
    "                    'o_orderdate': current_date,\n",
    "                    'o_totalprice': self.generate_order_value(years_passed),\n",
    "                    'o_orderstatus': 'O',\n",
    "                    'o_clerk': self.generate_clerk(),\n",
    "                    'o_custkey': self.generate_customer()\n",
    "                }\n",
    "                orders.append(order)\n",
    "            \n",
    "            current_date += timedelta(days=1)\n",
    "        \n",
    "        df = pd.DataFrame(orders)\n",
    "        df = df.sort_values('o_orderdate')\n",
    "        df['o_orderkey'] = range(len(df))\n",
    "        df['o_orderkey'] = df['o_orderkey'] + 1_500_000  # Offset to avoid conflicts\n",
    "        \n",
    "        return df\n",
    "\n",
    "def generate_and_save_synthetic_data():\n",
    "    \"\"\"Generate orders and save to CSV\"\"\"\n",
    "    # Example: Generate 2 years of data with pronounced patterns\n",
    "    params = {\n",
    "        'start_date': '1992-01-01',\n",
    "        'end_date': '1998-08-02',\n",
    "        'target_daily_total': 100_000_000,\n",
    "        'target_daily_orders': 500,\n",
    "        'holiday_effect_magnitude': 1.2,\n",
    "        'weekend_dip': 0.8,\n",
    "        'annual_growth_rate': 0.15,\n",
    "        'value_noise_stddev': 0.15\n",
    "    }\n",
    "    \n",
    "    generator = OrderGenerator(**params)\n",
    "    df = generator.generate_orders()\n",
    "    #save the synthetic data to a temporary table\n",
    "    filename = 'synthetic_orders'\n",
    "    df.to_csv(filename + '.csv', index=False)\n",
    "    print(f\"Orders saved to CSV {filename}.csv\")\n",
    "    csv_df = pd.read_csv(filename + '.csv')\n",
    "    csv_df['o_orderdate'] = pd.to_datetime(df['o_orderdate'])\n",
    "    table_df = session.create_dataframe(csv_df)\n",
    "    table_df.write.mode(\"overwrite\").save_as_table(filename, table_type=\"temporary\")\n",
    "    print(f\"Order saved to temporary table {filename}\")\n",
    "    return\n",
    "\n",
    "# Generate and save orders\n",
    "generate_and_save_synthetic_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0f2f8f-33ae-4934-9064-f44a3e5ef5c9",
   "metadata": {
    "collapsed": false,
    "name": "growth_accounting_intro",
    "resultHeight": 74
   },
   "source": [
    "# Growth Accounting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10ebdb4-78f3-49f3-ab81-529b0afd662d",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "sql",
    "name": "orders",
    "resultHeight": 510
   },
   "outputs": [],
   "source": [
    "with synthetic as (\n",
    "\n",
    "    select\n",
    "        \"o_custkey\" as id,\n",
    "        to_date(\"o_orderdate\") as o_orderdate,\n",
    "        CAST(\"o_totalprice\" AS NUMERIC) as o_totalprice\n",
    "    from synthetic_orders\n",
    "    --SAMPLE (1000000 rows)\n",
    "\n",
    "),\n",
    "\n",
    "\n",
    "original as (\n",
    "    \n",
    "    select\n",
    "        o_custkey as id,\n",
    "        o_orderdate,\n",
    "        o_totalprice\n",
    "    from SNOWFLAKE_SAMPLE_DATA.TPCH_SF1.ORDERS\n",
    "    --SAMPLE (1000000 rows)\n",
    "\n",
    ")\n",
    "\n",
    "select * from synthetic\n",
    "union all \n",
    "select * from original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b933a301-0086-4682-9a6b-c0d430f62f87",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "annual_customer_orders",
    "resultHeight": 510
   },
   "outputs": [],
   "source": [
    "select\n",
    "    id,\n",
    "    date_trunc(year, o_orderdate) as order_year,\n",
    "    sum(o_totalprice) as total\n",
    "from {{ orders }}\n",
    "group by all\n",
    "order by id, order_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a789790e-47be-4b57-94a1-53832336abb1",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "add_rows_for_years_without_sales",
    "resultHeight": 0
   },
   "outputs": [],
   "source": [
    "annual_customer_orders_df = annual_customer_orders.to_pandas()\n",
    "\n",
    "#pivot data to add row for each id:year with no revenue\n",
    "result = annual_customer_orders_df.pivot_table(\n",
    "    index='ID',\n",
    "    columns='ORDER_YEAR', \n",
    "    values='TOTAL',\n",
    "    fill_value=0\n",
    ").reset_index().melt(\n",
    "    id_vars='ID',\n",
    "    var_name='ORDER_YEAR',\n",
    "    value_name='TOTAL'\n",
    ")\n",
    "\n",
    "# save the dataframe as table for SQL querying \n",
    "df = session.create_dataframe(result)\n",
    "df.write.mode(\"overwrite\").save_as_table(\"annual_customer_orders\", table_type=\"temporary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c25d11-94cb-40f0-985a-89e8d8839d8e",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "sample_annual_customer_orders",
    "resultHeight": 438
   },
   "outputs": [],
   "source": [
    "select * from annual_customer_orders\n",
    "order by id, order_year\n",
    "limit 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d092b952-57aa-4076-b1cd-575279473bab",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "labeled_annual_customer_orders",
    "resultHeight": 510
   },
   "outputs": [],
   "source": [
    "with windowed as (\n",
    "    \n",
    "    select\n",
    "        *,\n",
    "        sum(total) over(partition by id order by order_year asc) as lifetime_spend,\n",
    "        coalesce(lag(total) over(partition by id order by order_year asc), 0) as previous_year_total,\n",
    "    from annual_customer_orders\n",
    "\n",
    ")\n",
    "\n",
    "select *,\n",
    "  case\n",
    "    when total = previous_year_total and total > 0 then 'retained'\n",
    "    when total > 0 and previous_year_total = 0 and lifetime_spend = total then 'new'\n",
    "    when total = 0 and previous_year_total > 0 then 'churned'\n",
    "    when total > previous_year_total and previous_year_total > 0 then 'expanded'\n",
    "    when total < previous_year_total and previous_year_total > 0 then 'contracted'\n",
    "    when total > 0 and previous_year_total = 0 and lifetime_spend > total then 'resurrected'\n",
    "  else 'irrelevant' end as category,\n",
    "  case category\n",
    "    when 'retained' then 0\n",
    "    when 'new' then total\n",
    "    when 'churned' then (-1 * previous_year_total)\n",
    "    when 'expanded' then total - previous_year_total\n",
    "    when 'contracted' then (-1 * (previous_year_total - total))\n",
    "    when 'resurrected' then total\n",
    "  else 0 end as net_change\n",
    "from windowed\n",
    "order by id, order_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa6afc9-934a-40fb-a8ef-f6aedaec3ba0",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "annual_growth_labels",
    "resultHeight": 438
   },
   "outputs": [],
   "source": [
    "with final as (\n",
    "\n",
    "select\n",
    "    date_part(year, order_year) as order_year,\n",
    "    category,\n",
    "    round(sum(total)) as total,\n",
    "    round(sum(net_change)) as net_change\n",
    "from {{ labeled_annual_customer_orders }}\n",
    "group by all\n",
    "\n",
    ")\n",
    "\n",
    "select * from final\n",
    "-- exclude first and last years\n",
    "where order_year not in (1992, 1998)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f67f2b4-9c22-453d-abc0-68e5fbbc2e7f",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "visualize_growth_framework",
    "resultHeight": 772
   },
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "st.bar_chart(annual_growth_labels, x='ORDER_YEAR', y='NET_CHANGE', color='CATEGORY', height=750)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2a6a8c-14e5-47f2-997e-fa53600564f2",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "download_growth_accounting_csv",
    "resultHeight": 96
   },
   "outputs": [],
   "source": [
    "df = labeled_annual_customer_orders.to_pandas()\n",
    "button_csv = df.to_csv().encode(\"utf-8\")\n",
    "st.download_button(label=\"Download\", data=button_csv, file_name=\"growth_accounting.csv\", mime=\"text/csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd5ea2b-6a4f-423e-8e50-ea5d96eb8140",
   "metadata": {
    "collapsed": false,
    "name": "forecasting_intro",
    "resultHeight": 74
   },
   "source": [
    "# Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ec54e1-54cf-468c-a2d9-8bb8bd4abaaa",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "daily_order_data",
    "resultHeight": 438
   },
   "outputs": [],
   "source": [
    "select\n",
    "    date_trunc(day, o_orderdate) as order_date,\n",
    "    sum(o_totalprice) as sum_revenue,\n",
    "    count(*) as num_orders\n",
    "from {{ orders }}\n",
    "group by 1\n",
    "order by order_date asc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1368eea-3b25-46fd-92d9-d890e07dc61e",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "prophet_data_preparation",
    "resultHeight": 372
   },
   "outputs": [],
   "source": [
    "from prophet import Prophet\n",
    "from prophet.plot import plot_plotly, plot_components_plotly\n",
    "\n",
    "df = daily_order_data.to_pandas()\n",
    "prophet_df = df.rename(columns={'ORDER_DATE': 'ds', 'SUM_REVENUE': 'y'})\n",
    "st.line_chart(prophet_df, x='ds', y='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff69396-4c45-477a-a03a-9c173e9e0a02",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "project_future_daily_sales",
    "resultHeight": 981
   },
   "outputs": [],
   "source": [
    "m = Prophet()\n",
    "try:\n",
    "    m.fit(prophet_df)\n",
    "except Exception as err:\n",
    "    print(Exception, err)\n",
    "\n",
    "future = m.make_future_dataframe(periods=365)\n",
    "forecast = m.predict(future)\n",
    "fig1 = m.plot(forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad6456c-376a-409b-a006-a42bfbb005fa",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "inspect_forecasting_components",
    "resultHeight": 1480
   },
   "outputs": [],
   "source": [
    "fig2 = m.plot_components(forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30b1c81-80bf-4571-b971-84443f55630d",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "simplify_forecast_visualization",
    "resultHeight": 372
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'ds': forecast['ds'],\n",
    "    'y': m.history['y'],\n",
    "    # Only show yhat for future dates\n",
    "    'yhat': np.where(forecast['ds'] > m.history['ds'].max(), forecast['yhat'], np.nan)\n",
    "})\n",
    "\n",
    "st.line_chart(df, x='ds', y=['y', 'yhat'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5232d8e1-8ecb-4bb4-94c2-dd7122caaf30",
   "metadata": {
    "collapsed": false,
    "name": "customer_segmentation_introduction",
    "resultHeight": 74
   },
   "source": [
    "# Customer Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a901764-40e1-4607-850c-444ad00450ef",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "sample_company_data",
    "resultHeight": 438
   },
   "outputs": [],
   "source": [
    "select *\n",
    "from ADHOC_ANALYSIS.USER_UPLOADS.SP500_COMPANY_LIST\n",
    "limit 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7acf161-5e2d-4277-89ea-65f1256358e4",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "construct_api_request",
    "resultHeight": 0
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_wiki_extract(title):\n",
    "    # Base URL for Wikipedia's API\n",
    "    url = \"https://en.wikipedia.org/w/api.php\"\n",
    "    \n",
    "    # Parameters for the API request\n",
    "    params = {\n",
    "        \"action\": \"query\",\n",
    "        \"format\": \"json\",\n",
    "        \"titles\": title,\n",
    "        \"prop\": \"extracts\",\n",
    "        \"exintro\": True,  # Only get the intro section\n",
    "        \"explaintext\": True,  # Get plain text instead of HTML\n",
    "    }\n",
    "    \n",
    "    # Make the request\n",
    "    response = requests.get(url, params=params)\n",
    "    \n",
    "    # Check if request was successful\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        # Navigate through the JSON response to get the extract\n",
    "        pages = data[\"query\"][\"pages\"]\n",
    "        # Get the first (and only) page's extract\n",
    "        page = list(pages.values())[0]\n",
    "        return page.get(\"extract\", \"No extract available\")\n",
    "    else:\n",
    "        return f\"Error: {response.status_code}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94963e7c-8d39-46e5-a035-4838ebb3617e",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "extract_wikipedia_descriptions",
    "resultHeight": 508
   },
   "outputs": [],
   "source": [
    "df = sample_company_data.to_pandas()\n",
    "company_names = df['NAME'].tolist()\n",
    "csv_list = []\n",
    "\n",
    "print(\"extracting descriptions\")\n",
    "\n",
    "for name in company_names:\n",
    "    try:\n",
    "        extract = get_wiki_extract(name.replace(\" \", \"_\"))\n",
    "        print(f'extracted description of {name} from Wikipedia')\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting Wikipedia extract for {name}: {str(e)}\")\n",
    "        extract = \"None available\"\n",
    "        \n",
    "    csv_list.append((name, extract))\n",
    "\n",
    "print(\"finished extracting descriptions\")\n",
    "\n",
    "# save the dataframe as table for SQL querying \n",
    "df = pd.DataFrame(csv_list, columns=['name', 'description'])\n",
    "df = session.create_dataframe(df)\n",
    "df.write.mode(\"overwrite\").save_as_table(\"prospects\", table_type=\"temporary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c446dc-5c36-42e3-bb0d-985d397af0ca",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "display_wikipedia_descriptions",
    "resultHeight": 438
   },
   "outputs": [],
   "source": [
    "select \"name\", \"description\" from prospects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b559934-f89d-418e-9a1f-38ef7faa03ad",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "categorize_descriptions_with_LLM",
    "resultHeight": 426
   },
   "outputs": [],
   "source": [
    "select\n",
    "    \"name\",\n",
    "    snowflake.cortex.classify_text(\n",
    "        \"description\",\n",
    "        ['extremely likely', 'somewhat likely', 'unlikely'],\n",
    "        {\n",
    "            'task_description': 'Return the likelihood that this company would be interested in attending a webinar showcasing the GTM utility of Snowflake Notebooks and Anaconda Python Packages.'\n",
    "        }\n",
    "    ):label::STRING as persona_likelihood,\n",
    "    snowflake.cortex.classify_text(\n",
    "        \"description\",\n",
    "        ['healthcare', 'finance', 'retail', 'technology', 'communication', 'other'],\n",
    "        {\n",
    "            'task_description': 'Return the most likely industry of the company based on this description.'\n",
    "        }\n",
    "    ):label::STRING as industry,\n",
    "    snowflake.cortex.classify_text(\n",
    "        \"description\",\n",
    "        ['California', 'South', 'Northeast', 'Midatlantic', 'Midwest', 'Pacific Northwest', 'Outsite the US'],\n",
    "        {\n",
    "            'task_description': 'Return the most likely region the company is headquartered in based on this description.'\n",
    "        }\n",
    "    ):label::STRING as region,\n",
    "    \"description\"\n",
    "from prospects\n",
    "where \"description\" is not null and \"description\" != ''\n",
    "limit 10\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "authorEmail": "wluna@anaconda.com",
   "authorId": "405715820451",
   "authorName": "WLUNA",
   "lastEditTime": 1737744033132,
   "notebookId": "2jcfdffhscjksh5ccsf7",
   "sessionId": "e4e4ef1b-68d9-44f4-b7b9-1d472664a700"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
