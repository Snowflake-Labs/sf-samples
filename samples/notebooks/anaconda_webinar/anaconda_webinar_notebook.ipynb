{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "session_creation",
    "resultHeight": 0,
    "collapsed": false
   },
   "source": "from snowflake.snowpark.context import get_active_session\nsession = get_active_session()\n\nimport logging\nlogging.getLogger(\"cmdstanpy\").setLevel(logging.WARNING)\nimport warnings\nwarnings.filterwarnings('ignore', category=FutureWarning)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "d776341f-464d-4a9b-8c98-ac8e05286559",
   "metadata": {
    "language": "sql",
    "name": "orders_sample",
    "resultHeight": 426,
    "collapsed": false
   },
   "outputs": [],
   "source": "select\n    o_custkey,\n    o_orderdate,\n    o_totalprice\nfrom SNOWFLAKE_SAMPLE_DATA.TPCH_SF1.ORDERS\nlimit 10",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "23297335-ae53-477e-af45-1355957bc24e",
   "metadata": {
    "language": "python",
    "name": "generate_synthetic_data",
    "resultHeight": 60,
    "collapsed": false,
    "codeCollapsed": true
   },
   "outputs": [],
   "source": "import numpy as np\nfrom datetime import datetime, timedelta\nimport pandas as pd\n\nclass OrderGenerator:\n    def __init__(\n        self,\n        # Basic parameters\n        start_date='1992-01-01',\n        end_date='1998-12-31',\n        target_daily_total=100_000_000,\n        target_daily_orders=500,\n        \n        # Trend parameters\n        annual_growth_rate=0.15,        # 15% annual growth\n        order_value_growth_rate=0.05,   # 5% annual growth in order values\n        \n        # Seasonal parameters\n        holiday_peak_day=350,           # Peak shopping day (Dec 16)\n        holiday_effect_magnitude=1.0,   # Strength of holiday effect\n        seasonal_baseline=0.8,          # Minimum seasonal multiplier\n        seasonal_spread=1000,           # Controls how spread out the holiday effect is\n        \n        # Weekly parameters\n        weekend_dip=0.85,              # Weekend order multiplier\n        weekday_boost=1.1,             # Weekday order multiplier\n        \n        # Value distribution parameters\n        pareto_shape=2.0,              # Shape parameter for order values\n        min_value_factor=0.3,          # Minimum order value as fraction of average\n        value_noise_stddev=0.15,       # Standard deviation for order value noise\n        \n        # Random seed for reproducibility\n        random_seed=None\n    ):\n        self.start_date = pd.to_datetime(start_date)\n        self.end_date = pd.to_datetime(end_date)\n        self.target_daily_total = target_daily_total\n        self.target_daily_orders = target_daily_orders\n        \n        # Store all other parameters\n        self.annual_growth_rate = annual_growth_rate\n        self.order_value_growth_rate = order_value_growth_rate\n        self.holiday_peak_day = holiday_peak_day\n        self.holiday_effect_magnitude = holiday_effect_magnitude\n        self.seasonal_baseline = seasonal_baseline\n        self.seasonal_spread = seasonal_spread\n        self.weekend_dip = weekend_dip\n        self.weekday_boost = weekday_boost\n        self.pareto_shape = pareto_shape\n        self.min_value_factor = min_value_factor\n        self.value_noise_stddev = value_noise_stddev\n        \n        # Derived parameters\n        self.avg_order_value = target_daily_total / target_daily_orders\n        self.min_order_value = self.avg_order_value * self.min_value_factor\n        \n        if random_seed is not None:\n            np.random.seed(random_seed)\n    \n    def seasonal_effect(self, day_of_year):\n        \"\"\"Stronger effect during holiday season\"\"\"\n        holiday_effect = np.exp(\n            -((day_of_year - self.holiday_peak_day) ** 2) / \n            self.seasonal_spread\n        ) * self.holiday_effect_magnitude\n        return np.maximum(self.seasonal_baseline + holiday_effect, 0)\n    \n    def weekly_effect(self, day_of_week):\n        \"\"\"Weekend dips in orders\"\"\"\n        return self.weekend_dip if day_of_week in [5, 6] else self.weekday_boost\n    \n    def trend_effect(self, years_passed):\n        \"\"\"Long-term growth trend\"\"\"\n        return np.power(1 + self.annual_growth_rate, years_passed)\n    \n    def generate_order_value(self, years_passed):\n        \"\"\"Generate order values following a Pareto distribution\"\"\"\n        u = np.random.random()\n        value = self.min_order_value / np.power(1 - u, 1/self.pareto_shape)\n        value = value * np.power(1 + self.order_value_growth_rate, years_passed)\n        noise = np.random.normal(1, self.value_noise_stddev)\n        return round(value * noise)\n    \n    def generate_clerk(self):\n        \"\"\"Generate clerk IDs matching TPCH format\"\"\"\n        clerk_id = np.random.randint(1000)\n        return f\"Clerk#{clerk_id:09d}\"\n    \n    def generate_customer(self, num_customers=149999):\n        \"\"\"Generate customer IDs matching TPCH format\"\"\"\n        return np.random.randint(num_customers)\n    \n    def generate_orders(self):\n        \"\"\"Generate supplementary orders with realistic patterns\"\"\"\n        orders = []\n        current_date = self.start_date\n        \n        while current_date <= self.end_date:\n            day_of_year = current_date.dayofyear\n            years_passed = (current_date - self.start_date).days / 365\n            \n            seasonal = self.seasonal_effect(day_of_year)\n            weekly = self.weekly_effect(current_date.weekday())\n            trend = self.trend_effect(years_passed)\n            \n            target_orders = round(\n                self.target_daily_orders * \n                seasonal * weekly * trend\n            )\n            \n            for _ in range(target_orders):\n                order = {\n                    'o_orderdate': current_date,\n                    'o_totalprice': self.generate_order_value(years_passed),\n                    'o_orderstatus': 'O',\n                    'o_clerk': self.generate_clerk(),\n                    'o_custkey': self.generate_customer()\n                }\n                orders.append(order)\n            \n            current_date += timedelta(days=1)\n        \n        df = pd.DataFrame(orders)\n        df = df.sort_values('o_orderdate')\n        df['o_orderkey'] = range(len(df))\n        df['o_orderkey'] = df['o_orderkey'] + 1_500_000  # Offset to avoid conflicts\n        \n        return df\n\ndef generate_and_save_synthetic_data():\n    \"\"\"Generate orders and save to CSV\"\"\"\n    # Example: Generate 2 years of data with pronounced patterns\n    params = {\n        'start_date': '1992-01-01',\n        'end_date': '1998-08-02',\n        'target_daily_total': 100_000_000,\n        'target_daily_orders': 500,\n        'holiday_effect_magnitude': 1.2,\n        'weekend_dip': 0.8,\n        'annual_growth_rate': 0.15,\n        'value_noise_stddev': 0.15\n    }\n    \n    generator = OrderGenerator(**params)\n    df = generator.generate_orders()\n    #save the synthetic data to a temporary table\n    filename = 'synthetic_orders'\n    df.to_csv(filename + '.csv', index=False)\n    print(f\"Orders saved to CSV {filename}.csv\")\n    csv_df = pd.read_csv(filename + '.csv')\n    csv_df['o_orderdate'] = pd.to_datetime(df['o_orderdate'])\n    table_df = session.create_dataframe(csv_df)\n    table_df.write.mode(\"overwrite\").save_as_table(filename, table_type=\"temporary\")\n    print(f\"Order saved to temporary table {filename}\")\n    return\n\n# Generate and save orders\ngenerate_and_save_synthetic_data()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ca0f2f8f-33ae-4934-9064-f44a3e5ef5c9",
   "metadata": {
    "name": "growth_accounting_intro",
    "collapsed": false,
    "resultHeight": 74
   },
   "source": "# Growth Accounting"
  },
  {
   "cell_type": "code",
   "id": "b10ebdb4-78f3-49f3-ab81-529b0afd662d",
   "metadata": {
    "language": "sql",
    "name": "orders",
    "resultHeight": 510,
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "with synthetic as (\n\n    select\n        \"o_custkey\" as id,\n        to_date(\"o_orderdate\") as o_orderdate,\n        CAST(\"o_totalprice\" AS NUMERIC) as o_totalprice\n    from synthetic_orders\n    --SAMPLE (1000000 rows)\n\n),\n\noriginal as (\n    \n    select\n        o_custkey as id,\n        o_orderdate,\n        o_totalprice\n    from SNOWFLAKE_SAMPLE_DATA.TPCH_SF1.ORDERS\n    --SAMPLE (1000000 rows)\n\n)\n\nselect * from synthetic\nunion all \nselect * from original",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b933a301-0086-4682-9a6b-c0d430f62f87",
   "metadata": {
    "language": "sql",
    "name": "annual_customer_orders",
    "resultHeight": 510
   },
   "outputs": [],
   "source": "select\n    id,\n    date_trunc(year, o_orderdate) as order_year,\n    sum(o_totalprice) as total\nfrom {{ orders }}\ngroup by all\norder by id, order_year",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a789790e-47be-4b57-94a1-53832336abb1",
   "metadata": {
    "language": "python",
    "name": "add_rows_for_years_without_sales",
    "resultHeight": 0
   },
   "outputs": [],
   "source": "annual_customer_orders_df = annual_customer_orders.to_pandas()\n\n#pivot data to add row for each id:year with no revenue\nresult = annual_customer_orders_df.pivot_table(\n    index='ID',\n    columns='ORDER_YEAR', \n    values='TOTAL',\n    fill_value=0\n).reset_index().melt(\n    id_vars='ID',\n    var_name='ORDER_YEAR',\n    value_name='TOTAL'\n)\n\n# save the dataframe as table for SQL querying \ndf = session.create_dataframe(result)\ndf.write.mode(\"overwrite\").save_as_table(\"annual_customer_orders\", table_type=\"temporary\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "70c25d11-94cb-40f0-985a-89e8d8839d8e",
   "metadata": {
    "language": "sql",
    "name": "sample_annual_customer_orders",
    "resultHeight": 426
   },
   "outputs": [],
   "source": "select * from annual_customer_orders\norder by id, order_year\nlimit 10",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d092b952-57aa-4076-b1cd-575279473bab",
   "metadata": {
    "language": "sql",
    "name": "labeled_annual_customer_orders",
    "resultHeight": 510
   },
   "outputs": [],
   "source": "with windowed as (\n    \n    select\n        *,\n        sum(total) over(partition by id order by order_year asc) as lifetime_spend,\n        coalesce(lag(total) over(partition by id order by order_year asc), 0) as previous_year_total,\n    from annual_customer_orders\n\n)\n\nselect *,\n  case\n    when total = previous_year_total and total > 0 then 'retained'\n    when total > 0 and previous_year_total = 0 and lifetime_spend = total then 'new'\n    when total = 0 and previous_year_total > 0 then 'churned'\n    when total > previous_year_total and previous_year_total > 0 then 'expanded'\n    when total < previous_year_total and previous_year_total > 0 then 'contracted'\n    when total > 0 and previous_year_total = 0 and lifetime_spend > total then 'resurrected'\n  else 'irrelevant' end as category,\n  case category\n    when 'retained' then 0\n    when 'new' then total\n    when 'churned' then (-1 * previous_year_total)\n    when 'expanded' then total - previous_year_total\n    when 'contracted' then (-1 * (previous_year_total - total))\n    when 'resurrected' then total\n  else 0 end as net_change\nfrom windowed\norder by id, order_year",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4fa6afc9-934a-40fb-a8ef-f6aedaec3ba0",
   "metadata": {
    "language": "sql",
    "name": "annual_growth_labels",
    "resultHeight": 438
   },
   "outputs": [],
   "source": "select\n    date_part(year, order_year) as order_year,\n    category,\n    round(sum(total)) as total,\n    round(sum(net_change)) as net_change\nfrom {{ labeled_annual_customer_orders }}\ngroup by all",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9f67f2b4-9c22-453d-abc0-68e5fbbc2e7f",
   "metadata": {
    "language": "python",
    "name": "visualize_growth_framework",
    "resultHeight": 239
   },
   "outputs": [],
   "source": "import streamlit as st\n# Option to define dictionary to color code each category, may need to use matplotlib\n# Option to use altair for better control of ticks on Y axis\nst.bar_chart(annual_growth_labels, x='ORDER_YEAR', y='NET_CHANGE', color='CATEGORY', height=750)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2e2a6a8c-14e5-47f2-997e-fa53600564f2",
   "metadata": {
    "language": "python",
    "name": "download_growth_accounting_csv",
    "resultHeight": 96
   },
   "outputs": [],
   "source": "df = labeled_annual_customer_orders.to_pandas()\nbutton_csv = df.to_csv().encode(\"utf-8\")\nst.download_button(label=\"Download\", data=button_csv, file_name=\"growth_accounting.csv\", mime=\"text/csv\")",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "fbd5ea2b-6a4f-423e-8e50-ea5d96eb8140",
   "metadata": {
    "name": "forecasting_intro",
    "collapsed": false,
    "resultHeight": 74
   },
   "source": "# Forecasting"
  },
  {
   "cell_type": "code",
   "id": "16ec54e1-54cf-468c-a2d9-8bb8bd4abaaa",
   "metadata": {
    "language": "sql",
    "name": "daily_order_data",
    "resultHeight": 438,
    "collapsed": false
   },
   "outputs": [],
   "source": "select\n    date_trunc(day, o_orderdate) as order_date,\n    sum(o_totalprice) as sum_revenue,\n    count(*) as num_orders\nfrom {{ orders }}\ngroup by 1\norder by order_date asc",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e1368eea-3b25-46fd-92d9-d890e07dc61e",
   "metadata": {
    "language": "python",
    "name": "prophet_data_preparation",
    "resultHeight": 372,
    "collapsed": false
   },
   "outputs": [],
   "source": "from prophet import Prophet\nfrom prophet.plot import plot_plotly, plot_components_plotly\n\ndf = daily_order_data.to_pandas()\nprophet_df = df.rename(columns={'ORDER_DATE': 'ds', 'SUM_REVENUE': 'y'})\nst.line_chart(prophet_df, x='ds', y='y')",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bff69396-4c45-477a-a03a-9c173e9e0a02",
   "metadata": {
    "language": "python",
    "name": "project_future_daily_sales",
    "resultHeight": 41
   },
   "outputs": [],
   "source": "m = Prophet()\ntry:\n    m.fit(prophet_df)\nexcept Exception as err:\n    print(Exception, err)\n\nfuture = m.make_future_dataframe(periods=365)\nforecast = m.predict(future)\nfig1 = m.plot(forecast)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3ad6456c-376a-409b-a006-a42bfbb005fa",
   "metadata": {
    "language": "python",
    "name": "inspect_forecasting_components",
    "resultHeight": 41
   },
   "outputs": [],
   "source": "fig2 = m.plot_components(forecast)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f30b1c81-80bf-4571-b971-84443f55630d",
   "metadata": {
    "language": "python",
    "name": "simplify_forecast_visualization",
    "resultHeight": 372
   },
   "outputs": [],
   "source": "df = pd.DataFrame({\n    'ds': forecast['ds'],\n    'y': m.history['y'],\n    # Only show yhat for future dates\n    'yhat': np.where(forecast['ds'] > m.history['ds'].max(), forecast['yhat'], np.nan)\n})\n\nst.line_chart(df, x='ds', y=['y', 'yhat'])",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5232d8e1-8ecb-4bb4-94c2-dd7122caaf30",
   "metadata": {
    "name": "customer_segmentation_introduction",
    "collapsed": false,
    "resultHeight": 74
   },
   "source": "# Customer Segmentation"
  },
  {
   "cell_type": "code",
   "id": "6a901764-40e1-4607-850c-444ad00450ef",
   "metadata": {
    "language": "sql",
    "name": "sample_company_data",
    "resultHeight": 426,
    "collapsed": false
   },
   "outputs": [],
   "source": "select *\nfrom ADHOC_ANALYSIS.USER_UPLOADS.SP500_COMPANY_LIST\nlimit 10",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e7acf161-5e2d-4277-89ea-65f1256358e4",
   "metadata": {
    "language": "python",
    "name": "construct_api_request",
    "resultHeight": 0,
    "collapsed": false
   },
   "outputs": [],
   "source": "import requests\n\ndef get_wiki_extract(title):\n    # Base URL for Wikipedia's API\n    url = \"https://en.wikipedia.org/w/api.php\"\n    \n    # Parameters for the API request\n    params = {\n        \"action\": \"query\",\n        \"format\": \"json\",\n        \"titles\": title,\n        \"prop\": \"extracts\",\n        \"exintro\": True,  # Only get the intro section\n        \"explaintext\": True,  # Get plain text instead of HTML\n    }\n    \n    # Make the request\n    response = requests.get(url, params=params)\n    \n    # Check if request was successful\n    if response.status_code == 200:\n        data = response.json()\n        # Navigate through the JSON response to get the extract\n        pages = data[\"query\"][\"pages\"]\n        # Get the first (and only) page's extract\n        page = list(pages.values())[0]\n        return page.get(\"extract\", \"No extract available\")\n    else:\n        return f\"Error: {response.status_code}\"",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "94963e7c-8d39-46e5-a035-4838ebb3617e",
   "metadata": {
    "language": "python",
    "name": "extraxt_wikipedia_descriptions",
    "resultHeight": 284,
    "collapsed": false
   },
   "outputs": [],
   "source": "df = sample_company_data.to_pandas()\ncompany_names = df['NAME'].tolist()\ncsv_list = []\n\nprint(\"extracting descriptions\")\n\nfor name in company_names:\n    try:\n        extract = get_wiki_extract(name.replace(\" \", \"_\"))\n        print(f'extracted description of {name} from Wikipedia')\n    except Exception as e:\n        print(f\"Error getting Wikipedia extract for {name}: {str(e)}\")\n        extract = \"None available\"\n        \n    csv_list.append((name, extract))\n\nprint(\"finished extracting descriptions\")\n\n# save the dataframe as table for SQL querying \ndf = pd.DataFrame(csv_list, columns=['name', 'description'])\ndf = session.create_dataframe(df)\ndf.write.mode(\"overwrite\").save_as_table(\"prospects\", table_type=\"temporary\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "81c446dc-5c36-42e3-bb0d-985d397af0ca",
   "metadata": {
    "language": "sql",
    "name": "display_wikipedia_descriptions",
    "resultHeight": 426,
    "collapsed": false
   },
   "outputs": [],
   "source": "select \"name\", \"description\" from prospects",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6b559934-f89d-418e-9a1f-38ef7faa03ad",
   "metadata": {
    "language": "sql",
    "name": "categorize_descriptions_with_LLM",
    "resultHeight": 391,
    "collapsed": false
   },
   "outputs": [],
   "source": "select \n    \"name\",\n    \"description\",\n    snowflake.cortex.classify_text(\n        \"description\",\n        ['extremely likely', 'somewhat likely', 'unlikely'],\n        {\n            'task_description': 'Return the likelihood that this company would be interested in attending a webinar showcasing the GTM utility of Snowflake Notebooks and Anaconda Python Packages.'\n        }\n    ):label::STRING as persona_likelihood,\n    snowflake.cortex.classify_text(\n        \"description\",\n        ['healthcare', 'finance', 'retail', 'technology', 'communication', 'other'],\n        {\n            'task_description': 'Return the most likely industry of the company based on this description.'\n        }\n    ):label::STRING as industry,\n    snowflake.cortex.classify_text(\n        \"description\",\n        ['California', 'South', 'Northeast', 'Midatlantic', 'Midwest', 'Pacific Northwest', 'Outsite the US'],\n        {\n            'task_description': 'Return the most likely region the company is headquartered in based on this description.'\n        }\n    ):label::STRING as region\nfrom prospects\nwhere \"description\" is not null and \"description\" != ''\nlimit 10\n-- other class. ideas: industry, main product, region",
   "execution_count": null
  }
 ]
}