{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "hiqjexgsbvdrnz6gmqmx",
   "authorId": "7457914581117",
   "authorName": "BUILD_ADMIN",
   "authorEmail": "",
   "sessionId": "f383b837-1c12-44c5-9abc-c358df51ca2a",
   "lastEditTime": 1736895003897
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "cell1",
    "resultHeight": 150,
    "collapsed": false
   },
   "source": "# Import python packages\nimport streamlit as st\nimport pandas as pd\n\n# We can also use Snowpark for our analyses!\nfrom snowflake.snowpark.context import get_active_session\nsession = get_active_session()\n\nprint(\"----------------------------------------\")\nsnowflake_environment = session.sql('select current_warehouse(), current_database(), current_schema(), current_version()').collect()\nprint('Warehouse                   : {}'.format(snowflake_environment[0][0]))\nprint('Database                    : {}'.format(snowflake_environment[0][1]))\nprint('Schema                      : {}'.format(snowflake_environment[0][2]))\nprint('Snowflake version           : {}'.format(snowflake_environment[0][3]))\nprint(\"----------------------------------------\")\n\nDATABASE = snowflake_environment[0][1]\nSCHEMA = snowflake_environment[0][2]\nDATA_TABLE = 'TINY_IMAGENET'",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "9e74f0c2-4ada-4572-91c3-51b2ecbf42d3",
   "metadata": {
    "name": "cell5",
    "collapsed": false,
    "resultHeight": 263
   },
   "source": "# Dataset setup\n* Dataset Description\n    * The example uses the Tiny ImageNet dataset, a popular benchmark for image classification tasks.\n    * The dataset contains 100,000 color images, each sized 64×64 pixels, and contains 200 distinct classes.\n    * Each class contains 500 training images.\n* If the Snowflake table is not found, dataset is automatically downloaded fron HuggingFace and save to a Snowflake table.\n    * The images are encoded using Base64 saved in Snowflake tables as Varchar column."
  },
  {
   "cell_type": "code",
   "id": "c695373e-ac74-4b62-a1f1-08206cbd5c81",
   "metadata": {
    "language": "python",
    "name": "cell3",
    "resultHeight": 0,
    "collapsed": false
   },
   "source": "def table_exists(session):\n    query = f\"\"\"\n        SELECT COUNT(*)\n        FROM INFORMATION_SCHEMA.TABLES\n        WHERE TABLE_SCHEMA = '{SCHEMA}'\n        AND TABLE_NAME = '{DATA_TABLE}'\n    \"\"\"\n    result = session.sql(query).collect()\n    return result[0][0] > 0\n\ndef create_dataset_if_not_present(session):\n    from datasets import load_dataset\n    import pandas as pd\n    import base64\n    from io import BytesIO\n\n    if table_exists(session):\n        return\n\n    # Load Mini-ImageNet dataset from Hugging Face\n    dataset = load_dataset(\"zh-plus/tiny-imagenet\", split=\"train\")\n    \n    # Function to encode an image to base64\n    def encode_image_base64(image):\n        buffered = BytesIO()\n        image.save(buffered, format=\"PNG\")  # Save the image to a buffer in PNG format\n        return base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n    \n    # Create a Pandas DataFrame\n    data = {\n        \"label\": [entry[\"label\"] for entry in dataset],\n        \"image_base64\": [encode_image_base64(entry[\"image\"]) for entry in dataset],\n    }\n    \n    df = pd.DataFrame(data)\n\n    session.write_pandas(\n        df=df,\n        table_name=DATA_TABLE,\n        database=DATABASE,\n        schema=SCHEMA,\n        auto_create_table=True,\n        overwrite=True\n    )\ncreate_dataset_if_not_present(session)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "a1bf344e-58eb-4f16-b498-e9cf94b4695b",
   "metadata": {
    "name": "cell11",
    "collapsed": false,
    "resultHeight": 74
   },
   "source": "# Scaling ContainerRuntime Cluster"
  },
  {
   "cell_type": "code",
   "id": "08835258-c9e0-4ea3-ac8d-61f354c1e60f",
   "metadata": {
    "language": "python",
    "name": "cell9",
    "resultHeight": 948,
    "collapsed": false
   },
   "outputs": [],
   "source": "from snowflake.ml.runtime_cluster import scale_cluster, get_nodes\nscale_cluster(\"DISTRIBUTED_PYTORCH_QUICKSTART_2\", 3)\nget_nodes()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e4ad2342-44ba-41e1-8d46-2e484fa90865",
   "metadata": {
    "language": "python",
    "name": "cell15"
   },
   "outputs": [],
   "source": "get_nodes()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6cd9858e-3a00-46da-9bdb-5caf0b8a27c1",
   "metadata": {
    "name": "cell7",
    "collapsed": false,
    "resultHeight": 554
   },
   "source": "# Training\n## Model\n* Finetune a resent18 model by replacing fully connected layer with a new multi layer DNN.\n* More details about resnet18 model: https://pytorch.org/vision/main/models/generated/torchvision.models.resnet18.html#torchvision.models.resnet18 \n* All the base layers of resnet18 model are froze and only newly added fully connected layer is trained in this example to keep it simple.\n\n## Decoding Data\n* The images are stored as Base64-encoded strings in Snowflake tables. To train a CNN model, these encoded strings must be decoded and converted into tensors of shape 3 × 64 × 64 (3 color channels for RGB and 64×64 resolution).\n* DecodedDataset Class: The DecodedDataset class acts as a wrapper around a source [dataset](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset) and transforms each row of the dataset, enabling seamless decoding and preprocessing.\n\n* Similar pattern can be followed to chain together any number of row-level or batch-level transforms to preprocess the data for training efficiently.\n"
  },
  {
   "cell_type": "code",
   "id": "9762dd9e-3950-4a63-bacd-4f343e5a9330",
   "metadata": {
    "language": "python",
    "name": "cell6",
    "resultHeight": 0,
    "collapsed": false
   },
   "outputs": [],
   "source": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision.models import resnet18, ResNet18_Weights\n\ndef get_resent_model():\n    model = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n    \n    # Replace the last layer to fit 200 classes\n    num_features = model.fc.in_features\n    model.fc = nn.Sequential(\n        nn.Linear(num_features, 512),\n        nn.BatchNorm1d(512),\n        nn.LeakyReLU(),\n        nn.Dropout(0.5),\n        nn.Linear(512, 256),\n        nn.BatchNorm1d(256),\n        nn.LeakyReLU(),\n        nn.Dropout(0.5),\n        nn.Linear(256, 200)\n    )\n\n    def initialize_weights(m):\n        if isinstance(m, nn.Linear):\n            nn.init.xavier_uniform_(m.weight)\n            nn.init.zeros_(m.bias)\n    model.fc.apply(initialize_weights)\n    \n\n    for param in model.parameters():\n        param.requires_grad = False\n    for param in model.fc.parameters():\n        param.requires_grad = True\n\n    return model",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ef89c370-c21c-41c9-9eac-a1e0ea74198d",
   "metadata": {
    "language": "python",
    "name": "cell8",
    "resultHeight": 0,
    "collapsed": false
   },
   "outputs": [],
   "source": "import io\nimport base64\nfrom torchvision import transforms\nfrom torch.utils.data import IterableDataset\nfrom PIL import Image\n\nclass DecodedDataset(IterableDataset):\n    def __init__(self, source_dataset):  \n        self.source_dataset = source_dataset\n        self.transforms = transforms.Compose([\n            transforms.ToTensor()\n        ])\n        self.normlize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n\n    def __iter__(self):\n        for row in self.source_dataset:\n            base64_image = row['\"image_base64\"']\n            image = Image.open(io.BytesIO(base64.b64decode(base64_image)))\n            # Convert the image to a tensor\n            image = self.transforms(image)  # Converts PIL image to tensor\n\n            # Skip images with improper dimentions\n            if image.size() != torch.Size([3, 64, 64]):\n                # Check if it is a grey scale image\n                if image.size() == torch.Size([1, 64, 64]):\n                    # Conver to 3 channel image by replacing single channel to 3 channels\n                    image = image.repeat(3, 1, 1)\n                else:\n                    raise RuntimeError(f\"Unsupported image of dimentions {image.size()}\")\n\n            image = self.normlize(image)\n            labels = row['\"label\"']\n            yield image, int(labels)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "203f770c-e6b2-4a5c-87e9-b833ee1eb918",
   "metadata": {
    "language": "python",
    "name": "cell10",
    "collapsed": false,
    "resultHeight": 0
   },
   "outputs": [],
   "source": "def train(model, device, train_loader, optimizer, epoch):\n    model.train()\n    batch_idx = 1\n    for data, target in train_loader:\n        data, target = data.to(device), target.to(device)\n        optimizer.zero_grad()\n        output = model(data)\n        loss = F.cross_entropy(output, target)\n        loss.backward()\n        optimizer.step()\n        if batch_idx % 100 == 0:\n            print('Train Epoch: {} [Processed {} images]\\tLoss: {:.6f}'.format(\n                epoch, batch_idx * len(data), loss.item()))\n        batch_idx += 1\n\ndef test(model, device, test_loader):\n    model.eval()\n    test_loss = 0\n    correct = 0\n    total_images = 0\n    with torch.no_grad():\n        for data, target in test_loader:\n            data, target = data.to(device), target.to(device)\n            output = model(data)\n            test_loss += F.cross_entropy(output, target).item()  # sum up batch loss\n            _, preds = torch.max(output, 1)\n            correct += (preds == target).sum().item()\n            total_images += len(data)\n\n    test_loss /= total_images\n\n    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n        test_loss, correct, total_images,\n        100. * correct / total_images))\n    return (100. * correct / total_images)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b52049c4-23d5-4d1a-ac0f-8b38b5755d81",
   "metadata": {
    "name": "cell13",
    "collapsed": false,
    "resultHeight": 416
   },
   "source": "# Training loop definition\n* The provided example implements a straightforward training loop where the model is trained for a fixed number of epochs (num_epochs).\n    * Users can leverage the HuggingFace Trainer or PyTorch Lightning Trainer to take advantage of fully featured training loops with advanced features like early stopping, checkpointing, and more.\n* This example demonstrates how datasets and hyperparameters can be passed dynamically as arguments:\n    * The dataset_map parameter allows a map of datasets to be passed to the train_func, enabling flexibility to use different datasets without modifying the core logic.\n    * The hyper_params parameter allows variables such as num_epochs, learning_rate, and batch_size to be defined externally and passed during trainer invocation, making it easy to adjust or tune these parameters without hardcoding them in the training function.\n* The training loop also highlights the use of context APIs to retrieve metadata like rank and world_size, which can then be used to customize the training loop."
  },
  {
   "cell_type": "code",
   "id": "73e2f12d-e6b7-4582-a72d-bc468dc38add",
   "metadata": {
    "language": "python",
    "name": "cell4",
    "resultHeight": 0,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "def train_func():\n    import os\n    import time\n    import torch\n    import torch.optim as optim\n    import torch.distributed as dist\n    from torch.nn.parallel import DistributedDataParallel as DDP\n    from torch.optim.lr_scheduler import StepLR\n    from snowflake.ml.modeling.distributors.pytorch import get_context\n\n    start_time = time.time()\n    context = get_context()\n    local_rank = context.get_local_rank()\n    device = f\"cuda:{local_rank}\"\n    is_distributed = context.get_world_size() > 1\n    if is_distributed:\n        dist.init_process_group(backend=\"nccl\")\n    print(\n        f\"rank : {context.get_rank()}, \"\n        f\"world_size: {context.get_world_size()}, \"\n        f\"local_rank : {context.get_local_rank()}, \"\n        f\"local_world_size: {context.get_local_world_size()}, \"\n        f\"node_rank: {context.get_node_rank()}\"\n    )\n\n    dataset_map = context.get_dataset_map()\n    train_dataset = DecodedDataset(dataset_map[\"train\"].get_shard().to_torch_dataset())\n    test_dataset = DecodedDataset(dataset_map[\"test\"].to_torch_dataset())\n\n    batch_size = 64\n    train_loader = torch.utils.data.DataLoader(\n        train_dataset,\n        batch_size=batch_size,\n        pin_memory=True,\n        pin_memory_device=f\"cuda:{local_rank}\"\n    )\n    test_loader = torch.utils.data.DataLoader(\n        test_dataset,\n        batch_size=batch_size,\n        pin_memory=True,\n        pin_memory_device=f\"cuda:{local_rank}\"\n    )\n\n    model = get_resent_model()\n    model = model.to(device)\n\n    if is_distributed:\n        model = DDP(model)\n\n    base_lr = 0.001\n    lr = base_lr * context.get_world_size()\n    optimizer = optim.AdamW(model.parameters(), lr = lr)\n    scheduler = StepLR(optimizer, step_size=10)\n\n    hyper_parms = context.get_hyper_params()\n    num_epochs = int(hyper_parms['num_epochs'])\n\n    accuracy = []\n    for epoch in range(0, num_epochs):\n        train(model, device, train_loader, optimizer, epoch+1)\n        res = test(model, device, test_loader)\n        accuracy.append(res)\n        scheduler.step()\n\n    now = time.time()\n    context.get_metrics_reporter().log_metrics({\n        \"train_func_train_time\": int(now-start_time),\n        \"test_accuracy\": accuracy\n    })\n\n    if local_rank == 0:\n        torch.save(\n            model.module.state_dict(), os.path.join(context.get_model_dir(), \"model.pt\")\n        )\n    ",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c13651c6-4253-41df-a8aa-f623f9295d97",
   "metadata": {
    "name": "cell14",
    "collapsed": false,
    "resultHeight": 119
   },
   "source": "# Training\n* This example shows how to run the training function on 3 nodes, 4 workers on each node (because each node has 4 GPUs)."
  },
  {
   "cell_type": "code",
   "id": "3389a948-0569-4351-90a6-4ae58b6cb71e",
   "metadata": {
    "language": "python",
    "name": "cell2",
    "resultHeight": 258303,
    "collapsed": false
   },
   "outputs": [],
   "source": "# Set up PyTorchDistributor\nfrom snowflake.ml.modeling.distributors.pytorch import PyTorchDistributor, PyTorchScalingConfig, WorkerResourceConfig  \nfrom snowflake.ml.data.sharded_data_connector import ShardedDataConnector\nfrom snowflake.ml.data.data_connector import DataConnector\nfrom snowflake.snowpark.functions import random\n\ndf = session.table(f\"{DATABASE}.{SCHEMA}.{DATA_TABLE}\")\n\nshuffled_df = df.with_column(\"random_order\", random()).sort(\"random_order\").drop(\"random_order\")\n\ntrain_df, test_df = shuffled_df.random_split(weights = [0.95, 0.05], seed = 99)\n# Create sharded data connector.\ntrain_data = ShardedDataConnector.from_dataframe(train_df)\ntest_data = DataConnector.from_dataframe(test_df)\n\npytorch_trainer = PyTorchDistributor(  \n    train_func=train_func,\n    scaling_config=PyTorchScalingConfig(  \n        num_nodes=3,  \n        num_workers_per_node=4,  \n        resource_requirements_per_worker=WorkerResourceConfig(num_cpus=0, num_gpus=1),  \n    )  \n)  \n\n# Run the trainer.\nresults = pytorch_trainer.run(\n    dataset_map={\"train\": train_data, \"test\": test_data},\n    hyper_params={\"num_epochs\": \"10\", \"warm_up_num_epochs\": \"3\"}\n)\nresults.get_metrics()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "11778b47-4f34-4f7f-a4af-4ba251fbc3b7",
   "metadata": {
    "language": "python",
    "name": "cell12",
    "collapsed": false,
    "resultHeight": 439
   },
   "outputs": [],
   "source": "results.get_metrics()",
   "execution_count": null
  }
 ]
}