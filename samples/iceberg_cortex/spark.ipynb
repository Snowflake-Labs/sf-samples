{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1680d4b-49a6-4c8e-9a63-dba8c0d920a2",
   "metadata": {},
   "source": [
    "# Locate Spark in Virtual Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37df6598-a793-4ec1-b5bb-8bd1fc7aaec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prior to executing this code below:\n",
    "# 1. Install Conda\n",
    "# 2. Create an environtment by running this from your command line\n",
    "#        conda env create -f environment.yml\n",
    "# 3. Make sure you're using the 3.11.6 iceberg-demo Python kernel\n",
    "# 4. Export environment variables from spark_env_variables.txt\n",
    "# 5. Activate the environment and open jupyter notebooks by running this from your command line\n",
    "#        conda activate iceberg-lab\n",
    "#        jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2dd9f6-be83-47d2-836c-a077787a3aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import findspark\n",
    "load_dotenv()\n",
    "findspark.init()\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce62921-cc0d-41aa-b3d5-04f640f88f0a",
   "metadata": {},
   "source": [
    "# Run Spark "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc30a594-eaec-47e5-9b37-1420936ee943",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a99ce0-e4a4-4e52-89f3-cb6e3e4665f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SparkSession, for AWS\n",
    "spark = SparkSession.builder.appName('iceberg_lab')\\\n",
    "    .config('spark.jars.packages', os.environ['PACKAGES'])\\\n",
    "    .config('spark.sql.extensions', 'org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions')\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c160774-3d56-4e2f-9102-7b745da4a12f",
   "metadata": {},
   "source": [
    "### Spark configurations\n",
    "Set the following configurations for Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad480e1-8a79-4d81-a5ae-9f6401d5545d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.defaultCatalog\", \"snowflake_catalog\")\n",
    "spark.conf.set(\"spark.sql.catalog.snowflake_catalog\", \"org.apache.iceberg.spark.SparkCatalog\")\n",
    "spark.conf.set(\"spark.sql.catalog.snowflake_catalog.catalog-impl\", \"org.apache.iceberg.snowflake.SnowflakeCatalog\")\n",
    "spark.conf.set(\"spark.sql.catalog.snowflake_catalog.uri\", os.environ['SNOWFLAKE_CATALOG_URI'])\n",
    "spark.conf.set(\"spark.sql.catalog.snowflake_catalog.jdbc.role\", os.environ['SNOWFLAKE_ROLE'])\n",
    "spark.conf.set(\"spark.sql.catalog.snowflake_catalog.jdbc.user\", os.environ['SNOWFLAKE_USERNAME'])\n",
    "spark.conf.set(\"spark.sql.catalog.snowflake_catalog.jdbc.password\", os.environ['SNOWFLAKE_PASSWORD'])\n",
    "spark.conf.set(\"spark.sql.iceberg.vectorization.enabled\", \"false\")\n",
    "spark.conf.set(\"spark.sql.catalog.snowflake_catalog.io-impl\", \"org.apache.iceberg.aws.s3.S3FileIO\")\n",
    "spark.conf.set(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    "spark.conf.set(\"spark.hadoop.fs.s3a.aws.credentials.provider\", \"org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider\")\n",
    "spark.conf.set(\"spark.hadoop.fs.s3a.access.key\", os.environ['AWS_ACCESS_KEY_ID'])\n",
    "spark.conf.set(\"spark.hadoop.fs.s3a.secret.key\", os.environ['AWS_SECRET_ACCESS_KEY'])\n",
    "spark.conf.set(\"spark.hadoop.fs.s3a.endpoint\", \"s3.amazonaws.com\")\n",
    "spark.conf.set(\"spark.hadoop.fs.s3a.endpoint.region\", os.environ['AWS_REGION'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5304667-f991-4004-8385-0a948f1bc007",
   "metadata": {},
   "source": [
    "# Read Snowflake-managed Iceberg Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f02e0a2-eacc-4627-8016-46b45613c3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"USE DEMO.PUBLIC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf6b944-ca4f-4c08-9d0c-56931d951875",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_product_reviews = spark.table(\"demo.public.product_reviews\")\n",
    "df_product_reviews.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd1bc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews_per_day = df_product_reviews.groupBy(\"review_date\") \\\n",
    "                                       .agg(F.countDistinct(\"id\") \\\n",
    "                                       .alias(\"num_reviews\"))\n",
    "df_reviews_per_day.orderBy(\"review_date\", ascenting=False).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193fb82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_product_sentiment = df_product_reviews.groupBy(\"product_name\") \\\n",
    "                                       .agg(F.avg(\"sentiment\") \\\n",
    "                                       .alias(\"avg_sentiment\"))\n",
    "df_product_sentiment.orderBy(\"avg_sentiment\", ascending=False).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10901aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_product_reviews = spark.table(\"demo.public.product_reviews\")\n",
    "df_product_reviews.createOrReplaceTempView(\"product_reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772ceaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "jan_df = spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        product_name,\n",
    "        avg(sentiment) as avg_sentiment\n",
    "    FROM product_reviews\n",
    "    WHERE MONTH(review_date) = 1\n",
    "    GROUP BY product_name\n",
    "    ORDER BY avg_sentiment DESC\n",
    "\"\"\")\n",
    "jan_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bdbf1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "feb_df = spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        product_name,\n",
    "        avg(sentiment) as avg_sentiment\n",
    "    FROM product_reviews\n",
    "    WHERE MONTH(review_date) = 2\n",
    "    GROUP BY product_name\n",
    "    ORDER BY avg_sentiment DESC\n",
    "\"\"\")\n",
    "feb_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64f0650",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = jan_df.alias(\"jan\").join(feb_df.alias(\"feb\"), jan_df.product_name == feb_df.product_name, how=\"full_outer\") \\\n",
    "    .select(\n",
    "        F.coalesce(F.col(\"jan.product_name\"), F.col(\"feb.product_name\")).alias(\"product_name\"),\n",
    "        jan_df.avg_sentiment.alias(\"jan_sentiment\"),\n",
    "        feb_df.avg_sentiment.alias(\"feb_sentiment\")\n",
    "    ) \\\n",
    "    .withColumn(\"sentiment_diff\", F.col(\"feb_sentiment\") - F.col(\"jan_sentiment\")) \\\n",
    "    .orderBy(\"sentiment_diff\", ascending=False)\n",
    "result_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee3f3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When complete, you can deactivate the environment and remove it by running this from command line\n",
    "#       conda deactivate\n",
    "#       conda remove -n iceberg-demo --all"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
