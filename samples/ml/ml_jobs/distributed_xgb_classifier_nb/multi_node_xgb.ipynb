{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a6496bf-b928-4069-adfa-083299a21a13",
   "metadata": {},
   "source": [
    "### Set up Snowpark Session\n",
    "\n",
    "See [Configure Connections](https://docs.snowflake.com/developer-guide/snowflake-cli/connecting/configure-connections#define-connections)\n",
    "for information on how to define default Snowflake connection(s) in a config.toml\n",
    "file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9880be-f3c2-4100-a35c-0e72595f3bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.snowpark import Session, Row\n",
    "\n",
    "# Requires valid ~/.snowflake/config.toml file\n",
    "session = Session.builder.getOrCreate()\n",
    "print(session)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa9a253-38c5-4641-a01a-eaf899d24199",
   "metadata": {},
   "source": [
    "#### Set up Snowflake resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e5fad4-748b-4390-b4fa-748a10547835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: Uncomment below to select a database and schema to use\n",
    "# session.use_database(\"temp\")\n",
    "# session.use_schema(\"public\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb47093-9b23-492d-a135-5722729a0c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create compute pool if not exists\n",
    "def create_compute_pool(name: str, instance_family: str, min_nodes: int = 1, max_nodes: int = 10):\n",
    "    query = f\"\"\"\n",
    "        CREATE COMPUTE POOL IF NOT EXISTS {name}\n",
    "            MIN_NODES = {min_nodes}\n",
    "            MAX_NODES = {max_nodes}\n",
    "            INSTANCE_FAMILY = {instance_family}\n",
    "    \"\"\"\n",
    "    return session.sql(query).collect()\n",
    "\n",
    "compute_pool = \"DEMO_POOL_CPU\"\n",
    "create_compute_pool(compute_pool, \"CPU_X64_S\", 1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f328bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable multi node ML jobs\n",
    "# Note: If the parameter is invisible to you, contact the Snowflake account admin to enable the parameter for your account.\n",
    "session.sql(\"alter session set ENABLE_BATCH_JOB_SERVICES = true\").collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da4833f",
   "metadata": {},
   "source": [
    "### Approach 1: Train with function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84804c16-a359-4e5b-9037-207cc9675b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a arbitary dataset\n",
    "def generate_dataset_sql(db, schema, table_name, num_rows, num_cols) -> str:\n",
    "    sql_script = f\"CREATE TABLE IF NOT EXISTS {db}.{schema}.{table_name} AS \\n\"\n",
    "    sql_script += f\"SELECT \\n\"\n",
    "    for i in range(1, num_cols):\n",
    "        sql_script += f\"uniform(0::FLOAT, 10::FLOAT, random()) AS FEATURE_{i}, \\n\"\n",
    "    sql_script += f\"FEATURE_1 + FEATURE_1 AS TARGET_1, \\n\"\n",
    "    sql_script += f\"FROM TABLE(generator(rowcount=>({num_rows})));\"\n",
    "    return sql_script\n",
    "num_rows = 1000 * 1000\n",
    "num_cols = 100\n",
    "table_name = \"MULTINODE_CPU_TRAIN_DS\"\n",
    "session.sql(generate_dataset_sql(session.get_current_database(), session.get_current_schema(), \n",
    "                                table_name, num_rows, num_cols)).collect()\n",
    "feature_list = [f'FEATURE_{num}' for num in range(1, num_cols)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd72bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.ml.jobs import remote\n",
    "\n",
    "@remote(compute_pool, stage_name=\"payload_stage\", num_instances=3)\n",
    "def xgb(table_name, input_cols, label_col):\n",
    "    from snowflake.snowpark.context import get_active_session\n",
    "    from snowflake.ml.modeling.distributors.xgboost import XGBEstimator, XGBScalingConfig\n",
    "    from snowflake.ml.data.data_connector import DataConnector\n",
    "\n",
    "    session = get_active_session()\n",
    "    cpu_train_df = session.table(table_name)\n",
    "    \n",
    "    params = {\n",
    "        \"tree_method\": \"hist\",\n",
    "        \"objective\": \"reg:pseudohubererror\",\n",
    "        \"eta\": 1e-4,\n",
    "        \"subsample\": 0.5,\n",
    "        \"max_depth\": 50,\n",
    "        \"max_leaves\": 1000,\n",
    "        \"max_bin\":63,\n",
    "    }\n",
    "    scaling_config = XGBScalingConfig(use_gpu=False)\n",
    "    estimator = XGBEstimator(\n",
    "        n_estimators=100,\n",
    "        params=params,\n",
    "        scaling_config=scaling_config,\n",
    "    )\n",
    "    data_connector = DataConnector.from_dataframe(cpu_train_df)\n",
    "    xgb_model = estimator.fit(\n",
    "        data_connector, input_cols=input_cols, label_col=label_col\n",
    "    )\n",
    "    return xgb_model\n",
    "\n",
    "# Function invocation returns a job handle (snowflake.ml.jobs.MLJob)\n",
    "job = xgb(table_name, feature_list, \"TARGET_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb1ad66-851f-4fdb-887c-4dcaaf5bf2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(job.id)\n",
    "print(job.status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1909e552-d289-4bf4-8840-926d99295acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "job.wait()\n",
    "job.show_logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c46b2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "\n",
    "# Retrieve trained model from job execution and use it for prediction\n",
    "xgb_model = job.result()\n",
    "\n",
    "# Predict on a sample of the dataset\n",
    "# Note: This is just a demonstration, in practice you would want to predict on a different dataset\n",
    "dataset = session.table(table_name).drop(\"TARGET_1\").limit(10).to_pandas()\n",
    "xgb_model.predict(xgboost.DMatrix(dataset))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "headless_sample",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
