{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Snowflake Online Feature Store:  Predicting Taxi Trip Durations\n",
    "\n",
    "This notebook demonstrates how to use the Snowflake Online Feature Store and Snowpark ML to build features, register feature views, and train a model to predict taxi trip durations in New York City. It covers entity and feature view registration, feature engineering, online and offline store usage, and real-time inference.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from snowflake.ml.feature_store import CreationMode, FeatureStore, feature_view\n",
    "from snowflake.ml.feature_store.entity import Entity\n",
    "from snowflake.snowpark import Session\n",
    "from snowflake.snowpark.exceptions import SnowparkSQLException\n",
    "from snowflake.snowpark.functions import avg, col, datediff, dayofweek, hour, month, nullifzero, when\n",
    "from snowflake.snowpark.types import DecimalType\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Snowflake connection parameters\n",
    "connection_parameters = {\n",
    "    \"account\": \"<account_name>\",\n",
    "    \"user\": \"<username>\",\n",
    "    \"password\": \"<programmatic_access_token>\",\n",
    "    \"role\": \"<role>\",\n",
    "    \"host\": \"<host - if using private link>\",\n",
    "    \"warehouse\": \"<warehouse>\",\n",
    "    \"database\": \"<database>\",\n",
    "    \"schema\": \"<schema>\"\n",
    "}\n",
    "session = Session.builder.configs(connection_parameters).create()\n",
    "\n",
    "TAXI_DB = session.get_current_database()\n",
    "TAXI_SCHEMA = session.get_current_schema()\n",
    "TAXI_TABLE = \"NYC_YELLOW_TRIPS\"\n",
    "TAXI_TABLE_FULL_NAME = f\"{TAXI_DB}.{TAXI_SCHEMA}.{TAXI_TABLE}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Setup\n",
    "Load a sample dataset of NYC taxi trips. The data includes pickup and dropoff location IDs, timestamps, fare amounts, and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-time setup: load example data\n",
    "try:\n",
    "    session.table(TAXI_TABLE_FULL_NAME).limit(0).collect()\n",
    "    print(\"NYC taxi table already exists\")\n",
    "except SnowparkSQLException as e:\n",
    "    print(\"Loading NYC taxi table\")\n",
    "    from snowflake.ml.feature_store.examples.example_helper import ExampleHelper\n",
    "    example_helper = ExampleHelper(session, session.get_current_database(), session.get_current_schema())\n",
    "    source_tables = example_helper.load_example('new_york_taxi_features')\n",
    "    for table in source_tables:\n",
    "        print(f\"{table}:\")\n",
    "        df = session.table(table).limit(5).to_pandas()\n",
    "        print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering with Snowflake Feature Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Feature Store and context\n",
    "fs = FeatureStore(\n",
    "    session=session,\n",
    "    database=TAXI_DB,\n",
    "    name=TAXI_SCHEMA,\n",
    "    default_warehouse=session.get_current_warehouse(),\n",
    "    creation_mode=CreationMode.CREATE_IF_NOT_EXIST,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register Entities\n",
    "Entities represent the keys used to join features. Here we define entities for location, trip, and route.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and register entities\n",
    "route_entity = Entity(\n",
    "    name=\"route\",\n",
    "    join_keys=[\"PULOCATIONID\", \"DOLOCATIONID\"],\n",
    "    desc=\"A taxi route defined by pickup and dropoff location IDs.\"\n",
    ")\n",
    "pickup_time_entity = Entity(\n",
    "    name=\"pickup_time\",\n",
    "    join_keys=[\"PICKUP_HOUR\", \"PICKUP_DAY_OF_WEEK\"],\n",
    "    desc=\"Pickup time bucketed by hour and day of week\"\n",
    ")\n",
    "\n",
    "fs.register_entity(route_entity)\n",
    "fs.register_entity(pickup_time_entity)\n",
    "print(\"List Entities:\")\n",
    "fs.list_entities().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data and Create Features\n",
    "Read the NYC taxi trip data and engineer features for ETA, speed, rush hour, and more.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = session.table(TAXI_TABLE_FULL_NAME)\n",
    "\n",
    "# Create features\n",
    "df = df.with_column(\"TRIP_DISTANCE_INT\", col(\"TRIP_DISTANCE\").cast(DecimalType(10, 0)))\n",
    "df = df.with_column(\"ETA_MINUTES\", (datediff(\"second\", col(\"TPEP_PICKUP_DATETIME\"), col(\"TPEP_DROPOFF_DATETIME\")) / 60.0))\n",
    "df = df.with_column(\"ETA_MINUTES_INT\", col(\"ETA_MINUTES\").cast(DecimalType(10, 0)))\n",
    "df = df.with_column(\"PICKUP_HOUR\", hour(col(\"TPEP_PICKUP_DATETIME\")))\n",
    "df = df.with_column(\"PICKUP_DAY_OF_WEEK\", dayofweek(col(\"TPEP_PICKUP_DATETIME\")))  # 0=Sunday, 6=Saturday\n",
    "df = df.with_column(\"IS_WEEKEND\", when(col(\"PICKUP_DAY_OF_WEEK\").isin([0, 6]), 1).otherwise(0))\n",
    "df = df.with_column(\"PICKUP_MONTH\", month(col(\"TPEP_PICKUP_DATETIME\")))\n",
    "df = df.with_column(\"SPEED_MPH\", df[\"TRIP_DISTANCE\"] / nullifzero((df[\"ETA_MINUTES\"] / 60)))\n",
    "df = df.with_column(\"SPEED_MPH_INT\", col(\"SPEED_MPH\").cast(DecimalType(10, 0)))\n",
    "df = df.with_column(\"IS_RUSH_HOUR\", when((col(\"PICKUP_HOUR\").isin([7, 8, 9, 16, 17, 18, 19])),1).otherwise(0))\n",
    "df = df.with_column(\"IS_LOOP_ROUTE\", when(col(\"PULOCATIONID\") == col(\"DOLOCATIONID\"), 1).otherwise(0))\n",
    "print(\"Trip Data with Basic Features:\")\n",
    "df.show(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate features by route and pickup time bucket (hour x day-of-week)\n",
    "agg_route_and_time = (\n",
    "    df.group_by(\"PULOCATIONID\", \"DOLOCATIONID\", \"PICKUP_HOUR\", \"PICKUP_DAY_OF_WEEK\")\n",
    "      .agg(\n",
    "          avg(\"ETA_MINUTES_INT\").alias(\"AVG_ETA_ROUTE\"),\n",
    "          avg(\"SPEED_MPH_INT\").alias(\"AVG_SPEED_ROUTE\"),\n",
    "      )\n",
    ")\n",
    "df = df.join(\n",
    "    agg_route_and_time,\n",
    "    on=[\"PULOCATIONID\", \"DOLOCATIONID\", \"PICKUP_HOUR\", \"PICKUP_DAY_OF_WEEK\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "agg_route = (\n",
    "    df.group_by(\"PULOCATIONID\", \"DOLOCATIONID\")\n",
    "      .agg(\n",
    "          avg(\"TRIP_DISTANCE_INT\").alias(\"AVG_DISTANCE_ROUTE\"),\n",
    "      )\n",
    ")\n",
    "df = df.join(agg_route, on=[\"PULOCATIONID\", \"DOLOCATIONID\"], how=\"left\")\n",
    "\n",
    "print(\"Trip Data with Aggregated Features:\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features for the feature view\n",
    "feature_df = df.select(\n",
    "    # Columns direct from table\n",
    "    \"PULOCATIONID\", \"DOLOCATIONID\", \"TRIP_DISTANCE\",\n",
    "    \"VENDORID\", \"FARE_AMOUNT\", \"TOTAL_AMOUNT\", \"TPEP_PICKUP_DATETIME\",\n",
    "    \"TIP_AMOUNT\", \"TOLLS_AMOUNT\",\n",
    "    # Feature columns created from table (exclude final label ETA_MINUTES)\n",
    "    \"PICKUP_HOUR\", \"PICKUP_DAY_OF_WEEK\", \"IS_WEEKEND\", \"PICKUP_MONTH\",\n",
    "    \"SPEED_MPH\", \"IS_RUSH_HOUR\", \"IS_LOOP_ROUTE\",\n",
    "    # Feature columns created from aggregating by column combinations\n",
    "    \"AVG_ETA_ROUTE\", \"AVG_DISTANCE_ROUTE\", \"AVG_SPEED_ROUTE\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register Feature View\n",
    "Create and register a feature view for trip-based features, enabling online serving.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and register the feature view\n",
    "route_fv = feature_view.FeatureView(\n",
    "    name=\"nyc_taxi_trip_fv\",\n",
    "    entities=[route_entity, pickup_time_entity],\n",
    "    feature_df=feature_df,\n",
    "    timestamp_col=\"TPEP_PICKUP_DATETIME\",\n",
    "    refresh_freq=\"60s\", # Dynamic Table refresh minimum\n",
    "    desc=\"Trip-based features for taxi ETA prediction\",\n",
    "    online_config=feature_view.OnlineConfig(enable=True, target_lag=\"10s\"),\n",
    ")\n",
    "\n",
    "registered_route_fv = fs.register_feature_view(route_fv, \"v1\", overwrite=True)\n",
    "\n",
    "print(\"Registered feature view:\", registered_route_fv.name, registered_route_fv.version)\n",
    "print(\"Online feature table:\", registered_route_fv.fully_qualified_online_table_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check refresh history\n",
    "fs.get_refresh_history(registered_route_fv, store_type=feature_view.StoreType.ONLINE).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch features from the online store\n",
    "online_df = fs.read_feature_view(\n",
    "    registered_route_fv,\n",
    "    store_type=feature_view.StoreType.ONLINE,\n",
    ")\n",
    "online_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore online tables\n",
    "fs.list_feature_views().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Split\n",
    "Split the data into training and test sets for ML model development.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train/test split for ML\n",
    "spine_cols = [\n",
    "    \"ETA_MINUTES\",           # label\n",
    "    \"PULOCATIONID\",          # join key\n",
    "    \"DOLOCATIONID\",          # join key\n",
    "    \"PICKUP_HOUR\",           # join key\n",
    "    \"PICKUP_DAY_OF_WEEK\",    # join key\n",
    "    \"TPEP_PICKUP_DATETIME\"   # for point-in-time correctness (as spine_timestamp_col)\n",
    "]\n",
    "train_spine_df, test_spine_df = df.select(spine_cols).random_split([0.85, 0.15], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate training set with features for train and test\n",
    "train_set = fs.generate_training_set(\n",
    "    spine_df=train_spine_df,\n",
    "    features=[registered_route_fv],\n",
    "    spine_label_cols=[\"ETA_MINUTES\"],  # Target column for regression\n",
    "    save_as=\"TAXI_TRAIN_SET\",\n",
    "    spine_timestamp_col=\"TPEP_PICKUP_DATETIME\"\n",
    ")\n",
    "test_set = fs.generate_training_set(\n",
    "    spine_df=test_spine_df,\n",
    "    features=[registered_route_fv],\n",
    "    spine_label_cols=[\"ETA_MINUTES\"],\n",
    "    save_as=\"TAXI_TEST_SET\",\n",
    "    spine_timestamp_col=\"TPEP_PICKUP_DATETIME\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train set sample:\")\n",
    "print(train_set.limit(5).to_pandas())\n",
    "print(\"Test set sample:\")\n",
    "print(test_set.limit(5).to_pandas())\n",
    "print(f\"Train set count: {train_set.count()}\")\n",
    "print(f\"Test set count: {test_set.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train XGBoost Model\n",
    "Train an XGBoost regressor using Snowpark ML on the generated training set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train XGBoost model using Snowpark ML\n",
    "from snowflake.ml.modeling.xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Define feature columns (exclude label and keys)\n",
    "feature_columns = [\n",
    "    col for col in train_set.columns\n",
    "    if col not in [\"ETA_MINUTES\", \"TPEP_PICKUP_DATETIME\"]\n",
    "]\n",
    "label_column = \"ETA_MINUTES\"\n",
    "\n",
    "regressor = XGBRegressor(\n",
    "    input_cols=feature_columns,\n",
    "    label_cols=[label_column],\n",
    "    output_cols=[\"predicted_eta\"]\n",
    ")\n",
    "regressor.fit(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test set\n",
    "predictions = regressor.predict(test_set)\n",
    "predictions_pd = predictions.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "mse = mean_squared_error(predictions_pd[label_column], predictions_pd[\"predicted_eta\"])\n",
    "r2 = r2_score(predictions_pd[label_column], predictions_pd[\"predicted_eta\"])\n",
    "print(f\"Test MSE: {mse}\")\n",
    "print(f\"Test R2: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importances\n",
    "xgb_native = regressor.to_xgboost()\n",
    "\n",
    "if hasattr(xgb_native, \"feature_importances_\"):\n",
    "    importances = xgb_native.feature_importances_\n",
    "    importance_df = pd.DataFrame({\n",
    "        'feature': feature_columns,\n",
    "        'importance': importances\n",
    "    }).sort_values(by='importance', ascending=False)\n",
    "    print(\"Feature importances:\")\n",
    "    print(importance_df)\n",
    "\n",
    "if hasattr(xgb_native, \"get_booster\"):\n",
    "    booster = xgb_native.get_booster()\n",
    "\n",
    "    weights = booster.get_score(importance_type='weight')\n",
    "    weights_df = pd.DataFrame(list(weights.items()), columns=['feature', 'weight']).sort_values(by='weight', ascending=False)\n",
    "    print(\"Booster weights:\")\n",
    "    print(weights_df)\n",
    "\n",
    "    gains = booster.get_score(importance_type='gain')\n",
    "    gains_df = pd.DataFrame(list(gains.items()), columns=['feature', 'gain']).sort_values(by='gain', ascending=False)\n",
    "    print(\"Booster gains:\")\n",
    "    print(gains_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real-time Inference Example\n",
    "Fetch the latest features from the online store and predict duration for a new trip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_trip_duration(pu_location_id, do_location_id, pickup_hour, pickup_day_of_week):\n",
    "    trip = [\n",
    "        [pu_location_id, do_location_id, pickup_hour, pickup_day_of_week],\n",
    "    ]\n",
    "\n",
    "    # Fetch latest features from the online store\n",
    "    features_df = fs.read_feature_view(\n",
    "        registered_route_fv,\n",
    "        keys=trip,\n",
    "        store_type=feature_view.StoreType.ONLINE\n",
    "    )\n",
    "    \n",
    "    features_pd = features_df.to_pandas()\n",
    "    if features_pd.empty:\n",
    "        print(\"No online features found, skipping prediction\")\n",
    "        return None\n",
    "    \n",
    "    print(\"Online features:\")\n",
    "    print(features_pd)\n",
    "\n",
    "    return regressor.predict(features_pd)\n",
    "    \n",
    "\n",
    "prediction = predict_trip_duration(141, 236, 8, 0)\n",
    "if prediction is not None:\n",
    "    print(\"Prediction Trip Duration (minutes):\")\n",
    "    print(prediction['predicted_eta'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Data Arrives\n",
    "Simulate a recently ended trip between the same pickup and dropoff location ids that also occurred on a Sunday between 8am and 9am. In this case, the trip takes longer than normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from snowflake.snowpark.functions import max as sf_max, coalesce, lit\n",
    "\n",
    "# Compute next TRIP_ID\n",
    "next_trip_id = (\n",
    "    session.table(TAXI_TABLE_FULL_NAME)\n",
    "    .select(coalesce(sf_max(\"TRIP_ID\"), lit(0)) + lit(1))\n",
    "    .first()[0]\n",
    ")\n",
    "\n",
    "# Create single-row DataFrame for the new trip\n",
    "new_trip_df = session.create_dataframe(\n",
    "    [\n",
    "        (\n",
    "            1,                 # VENDORID\n",
    "            1,                 # PASSENGER_COUNT\n",
    "            3.8,               # TRIP_DISTANCE\n",
    "            1,                 # RATECODEID\n",
    "            \"N\",               # STORE_AND_FWD_FLAG\n",
    "            141,               # PULOCATIONID\n",
    "            236,               # DOLOCATIONID\n",
    "            1,                 # PAYMENT_TYPE\n",
    "            14.50,             # FARE_AMOUNT\n",
    "            3.00,              # EXTRA\n",
    "            0.50,              # MTA_TAX\n",
    "            3.65,              # TIP_AMOUNT\n",
    "            0.00,              # TOLLS_AMOUNT\n",
    "            0.30,              # IMPROVEMENT_SURCHARGE\n",
    "            29.95,             # TOTAL_AMOUNT\n",
    "            4.5,               # CONGESTION_SURCHARGE\n",
    "            0,                 # AIRPORT_FEE\n",
    "            datetime(2025, 8, 31, 8, 55, 0),  # TPEP_PICKUP_DATETIME\n",
    "            datetime(2025, 8, 31, 9, 15, 0),  # TPEP_DROPOFF_DATETIME\n",
    "            next_trip_id,      # TRIP_ID\n",
    "        )\n",
    "    ],\n",
    "    schema=[\n",
    "        \"VENDORID\",\n",
    "        \"PASSENGER_COUNT\",\n",
    "        \"TRIP_DISTANCE\",\n",
    "        \"RATECODEID\",\n",
    "        \"STORE_AND_FWD_FLAG\",\n",
    "        \"PULOCATIONID\",\n",
    "        \"DOLOCATIONID\",\n",
    "        \"PAYMENT_TYPE\",\n",
    "        \"FARE_AMOUNT\",\n",
    "        \"EXTRA\",\n",
    "        \"MTA_TAX\",\n",
    "        \"TIP_AMOUNT\",\n",
    "        \"TOLLS_AMOUNT\",\n",
    "        \"IMPROVEMENT_SURCHARGE\",\n",
    "        \"TOTAL_AMOUNT\",\n",
    "        \"CONGESTION_SURCHARGE\",\n",
    "        \"AIRPORT_FEE\",\n",
    "        \"TPEP_PICKUP_DATETIME\",\n",
    "        \"TPEP_DROPOFF_DATETIME\",\n",
    "        \"TRIP_ID\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Append to the existing table\n",
    "new_trip_df.write.mode(\"append\").save_as_table(TAXI_TABLE_FULL_NAME)\n",
    "print(\"Inserted 1 new trip row into\", TAXI_TABLE_FULL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Reflects Latest Data\n",
    "After a maximum of 75 seconds (60 seconds of data lag for the Dynamic Table and 15 for the Online Feature Table), the latest data has been transformed into its features and is being used for inference. The predicted ETA has increased since the most recently completed trip took longer than normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = predict_trip_duration(141, 236, 8, 0)\n",
    "if prediction is not None:\n",
    "    print(\"Prediction Trip Duration (minutes):\")\n",
    "    print(prediction['predicted_eta'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "online-feature-table-demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
