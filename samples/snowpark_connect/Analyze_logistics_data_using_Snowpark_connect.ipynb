{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1511f24d-3e54-48ee-84d0-eccab362b41d",
   "metadata": {
    "collapsed": false,
    "name": "spark_session_md"
   },
   "source": [
    "# Analyzing Logistics Data using Snowpark Connect for Apache Spark\n",
    "\n",
    "## Overview\n",
    "This notebook demonstrates how to analyze logistics and supply chain data using Snowpark Connect for Apache Spark‚Ñ¢. We'll work with carrier performance metrics and freight bill data to identify delivery risks and performance patterns.\n",
    "\n",
    "## Key Features\n",
    "- **Zero Migration Overhead**: Bring existing Spark code to Snowflake with minimal changes\n",
    "- **Better Performance**: Leverage Snowflake's cloud data platform for improved analytics performance  \n",
    "- **Native DataFrame APIs**: Use familiar PySpark DataFrame operations on Snowflake data\n",
    "\n",
    "## Dataset Description\n",
    "We'll be analyzing two main datasets:\n",
    "1. **Carrier Performance Metrics**: Historical performance data for different shipping carriers\n",
    "2. **Freight Bills**: Detailed shipping transaction records including costs, routes, and delivery information\n",
    "\n",
    "## Objectives\n",
    "- Load and analyze carrier performance data\n",
    "- Examine freight bill details and delivery confirmations\n",
    "- Identify shipments at risk of delays\n",
    "- Create integrated views for operational insights\n",
    "\n",
    "Let's start by setting up our Spark session and connecting to Snowflake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "spark_session"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from snowflake import snowpark_connect\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "\n",
    "from pyspark.sql.functions import col, avg, sum\n",
    "\n",
    "session = get_active_session()\n",
    "print(session)\n",
    "\n",
    "spark = snowpark_connect.server.init_spark_session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d6251b-4823-458c-bd0c-1584ef60e0e1",
   "metadata": {
    "language": "sql",
    "name": "use_database_and_schema"
   },
   "outputs": [],
   "source": [
    "use schema stratos_dynamics_scm.data;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722098b7-4e61-49de-bde2-ff41747ef38c",
   "metadata": {
    "language": "sql",
    "name": "create_csv_file_format"
   },
   "outputs": [],
   "source": [
    "CREATE OR REPLACE FILE FORMAT csv_format\n",
    "  TYPE = 'CSV'\n",
    "  FIELD_DELIMITER = ','\n",
    "  SKIP_HEADER = 1 -- Assumes the first row is a header\n",
    "  NULL_IF = ('', 'NULL')\n",
    "  EMPTY_FIELD_AS_NULL = TRUE\n",
    "  COMPRESSION = 'AUTO';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2b8c38-0afd-4b09-a802-e1e62e018e20",
   "metadata": {
    "language": "sql",
    "name": "create_s3_stage"
   },
   "outputs": [],
   "source": [
    "CREATE OR REPLACE STAGE stratos_public_s3_stage\n",
    "  URL = 's3://stratos-logistics-operations/'\n",
    "  FILE_FORMAT = csv_format;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b61768-0deb-4f01-b74c-f27aee2fbfa4",
   "metadata": {
    "language": "sql",
    "name": "create_target_table_1"
   },
   "outputs": [],
   "source": [
    "CREATE OR REPLACE TABLE carrier_performance_metrics (\n",
    "    metric_id                     VARCHAR,\n",
    "    carrier_name                  VARCHAR,\n",
    "    reporting_period              VARCHAR,\n",
    "    period_start_date             DATE,\n",
    "    period_end_date               DATE,\n",
    "    total_shipments               INT,\n",
    "    on_time_deliveries            INT,\n",
    "    on_time_percentage            FLOAT,\n",
    "    total_weight_lbs              FLOAT,\n",
    "    damage_claims                 INT,\n",
    "    damage_rate_percentage        FLOAT,\n",
    "    total_damage_cost             NUMERIC(18, 2),  -- Use NUMERIC for currency\n",
    "    average_transit_days          FLOAT,\n",
    "    customer_satisfaction_score   FLOAT,\n",
    "    total_freight_cost            NUMERIC(18, 2),  -- Use NUMERIC for currency\n",
    "    cost_per_shipment             NUMERIC(18, 2),  -- Use NUMERIC for currency\n",
    "    load_timestamp                TIMESTAMP_LTZ DEFAULT CURRENT_TIMESTAMP()\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a72fed5-b077-40e1-b977-b023b37a04d9",
   "metadata": {
    "language": "sql",
    "name": "create_target_table_2"
   },
   "outputs": [],
   "source": [
    "CREATE OR REPLACE TABLE freight_bills (\n",
    "    bill_id                 VARCHAR,\n",
    "    pro_number              VARCHAR,\n",
    "    po_number               VARCHAR,\n",
    "    carrier_name            VARCHAR,\n",
    "    ship_date               DATE,\n",
    "    delivery_date           DATE,\n",
    "    origin_city             VARCHAR,\n",
    "    origin_state            VARCHAR,\n",
    "    origin_country          VARCHAR,\n",
    "    origin_zip              INT,\n",
    "    destination_city        VARCHAR,\n",
    "    destination_state       VARCHAR,\n",
    "    destination_country     VARCHAR,\n",
    "    destination_zip         INT,\n",
    "    destination_facility    VARCHAR,\n",
    "    component_code          VARCHAR,\n",
    "    component_name          VARCHAR,\n",
    "    quantity                INT,\n",
    "    weight_lbs              FLOAT,\n",
    "    declared_value          INT,\n",
    "    freight_class           FLOAT,\n",
    "    base_charge             NUMERIC(18, 2),  -- Use NUMERIC for currency\n",
    "    weight_charge           NUMERIC(18, 2),  -- Use NUMERIC for currency\n",
    "    fuel_surcharge          NUMERIC(18, 2),  -- Use NUMERIC for currency\n",
    "    accessorial_charges     NUMERIC(18, 2),  -- Use NUMERIC for currency\n",
    "    total_charge            NUMERIC(18, 2),  -- Use NUMERIC for currency\n",
    "    payment_terms           VARCHAR,\n",
    "    payment_status          VARCHAR,\n",
    "    invoice_date            DATE,\n",
    "    load_timestamp          TIMESTAMP_LTZ DEFAULT CURRENT_TIMESTAMP()\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5defbf-71c0-489f-9c5e-81ec9525241f",
   "metadata": {
    "language": "sql",
    "name": "copy_data_into_table_1"
   },
   "outputs": [],
   "source": [
    "COPY INTO carrier_performance_metrics\n",
    "FROM @stratos_public_s3_stage/carrier_performance_metrics.csv\n",
    "FILE_FORMAT = (FORMAT_NAME = csv_format)\n",
    "ON_ERROR = 'ABORT_STATEMENT' -- Stops the load if any error is encountered\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8388c985-2d2d-4af9-999f-1fd1bd6b2243",
   "metadata": {
    "language": "sql",
    "name": "copy_data_into_table_2"
   },
   "outputs": [],
   "source": [
    "COPY INTO freight_bills\n",
    "FROM @stratos_public_s3_stage/freight_bills.csv\n",
    "FILE_FORMAT = (FORMAT_NAME = csv_format)\n",
    "ON_ERROR = 'ABORT_STATEMENT' -- Stops the load if any error is encountered\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9436d5c5",
   "metadata": {},
   "source": [
    "## üöÄ Setup Complete\n",
    "\n",
    "**Quick Setup Overview:** The cells above accomplish our initial setup in 4 key steps:\n",
    "1. **Environment**: Initialize Snowpark & Spark sessions for Snowflake execution\n",
    "2. **Data Infrastructure**: Create CSV file format and S3 external stage for data loading  \n",
    "3. **Table Schema**: Define `carrier_performance_metrics` and `freight_bills` tables\n",
    "4. **Data Loading**: Import CSV data from S3 into Snowflake tables\n",
    "\n",
    "Now let's analyze the data using Spark DataFrames!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ee21ac-534e-48a7-bc26-7f27e53449ff",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "variable_definitions"
   },
   "outputs": [],
   "source": [
    "db_name = \"stratos_dynamics_scm\"\n",
    "schema_name = \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c695373e-ac74-4b62-a1f1-08206cbd5c81",
   "metadata": {
    "language": "python",
    "name": "load_carrier_data"
   },
   "outputs": [],
   "source": [
    "carrier_performance = f\"{db_name}.{schema_name}.carrier_performance_metrics\"\n",
    "carrier_performance_df = spark.sql(f\"select * from {carrier_performance}\")\n",
    "carrier_performance_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0f5ed0-1d0a-4632-bfe7-56cc53fd3b3b",
   "metadata": {
    "collapsed": false,
    "name": "shipment_delays_md"
   },
   "source": [
    "### üìä Historic Shipment Analysis by Carrier\n",
    "\n",
    "Let's analyze key performance indicators across carriers to identify patterns in shipment volume, damage rates, costs, and customer satisfaction. This aggregation will help us understand which carriers perform best across different metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8242e5-b3dd-42e9-a58a-65b4ee53e805",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "shipment_delays"
   },
   "outputs": [],
   "source": [
    "carrier_shipment_delays_df = carrier_performance_df.groupBy(\"carrier_name\").agg(\n",
    "    avg(\"total_shipments\").alias(\"total_shipments\"),\n",
    "    avg(\"damage_claims\").alias(\"avg_damage_claims\"),\n",
    "    sum(\"total_damage_cost\").alias(\"total_damage_cost\"),\n",
    "    avg(\"customer_satisfaction_score\").alias(\"avg_customer_satisfaction_score\")\n",
    ")\n",
    "carrier_shipment_delays_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e004a852-db1a-4a8d-9c93-f5728bbcd832",
   "metadata": {
    "collapsed": false,
    "name": "delivery_confirmations_md"
   },
   "source": [
    "### üìã Delivery Confirmations Analysis\n",
    "\n",
    "Now let's examine delivery confirmation data to track actual vs. scheduled delivery dates. This data will help us identify potential delivery delays and at-risk shipments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d57b7d-47bf-4b22-8d07-e9b305961727",
   "metadata": {
    "language": "python",
    "name": "delivery_confirmations"
   },
   "outputs": [],
   "source": [
    "deliveries = \"build25_de_keynote.data.delivery_confirmations\"\n",
    "deliveries_df = spark.sql(f\"select * from {deliveries}\")\n",
    "deliveries_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449cdda7-dd8f-4151-83cf-5b191a1c81fe",
   "metadata": {
    "collapsed": false,
    "name": "freight_bills_md"
   },
   "source": [
    "### üí∞ Freight Bill Details Analysis\n",
    "\n",
    "Let's examine our freight bill data to understand shipping costs, routes, and transaction details. This information will provide insights into cost patterns and shipping logistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f5daf7-8b31-4f9a-a9eb-2d2faab0d8ff",
   "metadata": {
    "language": "python",
    "name": "freight_bills_data"
   },
   "outputs": [],
   "source": [
    "freight_bills = \"build25_de_keynote.data.freight_bills\"\n",
    "freight_bills_df = spark.sql(f\"select * from {freight_bills}\")\n",
    "freight_bills_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0985f1-9b7f-4252-88b2-72522cb112d4",
   "metadata": {
    "collapsed": false,
    "name": "combine_df_md"
   },
   "source": [
    "### üîÑ Joining Freight Bills and Delivery Confirmations\n",
    "\n",
    "This is a crucial step where we combine freight bill data with delivery confirmations to create a comprehensive view of our shipments. The join will help us:\n",
    "\n",
    "1. **Identify At-Risk Deliveries**: Compare scheduled vs. actual delivery dates\n",
    "2. **Cost Analysis**: Associate costs with delivery performance\n",
    "3. **Route Analytics**: Understand shipping patterns and potential bottlenecks\n",
    "4. **Operational Insights**: Create actionable data for logistics optimization\n",
    "\n",
    "The join uses `bill_id` as the common key between both datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1819c297-927e-41c3-9d4c-8d9d2641c96f",
   "metadata": {
    "language": "python",
    "name": "join_df"
   },
   "outputs": [],
   "source": [
    "dc = deliveries_df.alias(\"dc\")\n",
    "fb = freight_bills_df.alias(\"fb\")\n",
    "\n",
    "# Join with aliases\n",
    "deliveries_at_risk = dc.join(fb, on=\"bill_id\", how=\"inner\")\n",
    "\n",
    "# Now you can reference specific columns using aliases\n",
    "deliveries_at_risk = deliveries_at_risk.select(\n",
    "    \"bill_id\",\n",
    "    col(\"dc.pro_number\").alias(\"pro_number\"),\n",
    "    col(\"dc.po_number\").alias(\"po_number\"),\n",
    "    col(\"dc.carrier_name\").alias(\"carrier_name\"),\n",
    "    col(\"dc.scheduled_delivery_date\").alias(\"scheduled_delivery_date\"),\n",
    "    col(\"dc.actual_delivery_date\").alias(\"actual_delivery_date\"),\n",
    "    col(\"fb.destination_city\"),\n",
    "    col(\"fb.destination_state\"),\n",
    "    col(\"fb.destination_country\"),\n",
    "    col(\"fb.destination_zip\"),\n",
    "    col(\"fb.destination_facility\"),\n",
    "    col(\"fb.origin_city\"),\n",
    "    col(\"fb.origin_state\"),\n",
    "    col(\"fb.origin_country\"),\n",
    "    col(\"fb.origin_zip\"),\n",
    "    col(\"fb.component_code\"),\n",
    "    col(\"fb.component_name\"),\n",
    "    col(\"fb.quantity\"),\n",
    "    col(\"fb.weight_lbs\"),\n",
    "    col(\"fb.declared_value\"),\n",
    "    col(\"fb.total_charge\"),\n",
    "    col(\"fb.payment_terms\"),\n",
    "    col(\"fb.payment_status\"),\n",
    "    col(\"fb.invoice_date\"),\n",
    "    col(\"fb.quantity\").alias(\"product_quantity\"),\n",
    "    col(\"fb.freight_class\")\n",
    ")\n",
    "\n",
    "deliveries_at_risk.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef10490b-7728-4af0-9984-ad9517dc2200",
   "metadata": {
    "collapsed": false,
    "name": "write_to_snowflake_md"
   },
   "source": [
    "### ‚ö†Ô∏è Creating Deliveries at Risk Table\n",
    "\n",
    "Now we'll persist our joined and analyzed data as a new Snowflake table called `deliveries_at_risk`. This table will serve as a operational dashboard for logistics teams to monitor and take action on potential delivery issues:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05989f60-a2e6-4af1-bff6-2fac5fd0b34f",
   "metadata": {
    "language": "python",
    "name": "write_to_snowflake"
   },
   "outputs": [],
   "source": [
    "deliveries_at_risk.write.mode(\"append\").saveAsTable(f\"{db_name}.{schema_name}.deliveries_at_risk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8959c477-069d-45e1-aa75-1ecb6f7028a3",
   "metadata": {
    "collapsed": false,
    "name": "end"
   },
   "source": [
    "## üéâ Analysis Complete!\n",
    "\n",
    "**Success!** We've successfully created a comprehensive logistics analytics solution using Snowpark Connect for Apache Spark. \n",
    "\n",
    "### What We Accomplished:\n",
    "\n",
    "1. ‚úÖ **Data Infrastructure**: Set up file formats, external stages, and table schemas in Snowflake\n",
    "2. ‚úÖ **Data Loading**: Imported carrier performance and freight bill data from S3\n",
    "3. ‚úÖ **Spark Analytics**: Used familiar PySpark DataFrames on Snowflake data\n",
    "4. ‚úÖ **Data Integration**: Joined multiple datasets to create operational insights\n",
    "5. ‚úÖ **Actionable Results**: Created a `deliveries_at_risk` table for ongoing monitoring\n",
    "\n",
    "The `deliveries_at_risk` table is now available for business intelligence tools, reporting dashboards, and operational workflows!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "authorEmail": "vino.duraisamy@snowflake.com",
   "authorId": "5740887325800",
   "authorName": "VINOD",
   "lastEditTime": 1765238837569,
   "notebookId": "k4zygvjnooejrrgilf3y",
   "sessionId": "cc536c8d-1aa5-44bf-8fc6-cacb259657a8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
